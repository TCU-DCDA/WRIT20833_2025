{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36141631",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/TCU-DCDA/WRIT20833-2025/blob/main/notebooks/exercises/WRIT20833_Data_Cleaning_Student_Practice_F25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607d4c26",
   "metadata": {},
   "source": [
    "# Data Cleaning & Analysis: Student Practice Notebook\n",
    "## Apply Your Skills to Real Cultural Data\n",
    "\n",
    "**Name:** ________________________________  \n",
    "**Date:** ________________________________\n",
    "\n",
    "This notebook is your space to practice the data cleaning and analysis techniques from the main lesson. Upload your own cultural dataset and work through the cleaning process step by step.\n",
    "\n",
    "### üìã Before You Begin: Dataset Requirements Checklist\n",
    "**‚úÖ Check that your dataset includes:**\n",
    "- [ ] **Rich text data** (names, titles, categories, descriptions)\n",
    "- [ ] **Numeric columns** (counts, ratings, years, measurements)\n",
    "- [ ] **Mixed data types** for comprehensive practice\n",
    "- [ ] **At least 15-20 rows** for meaningful patterns\n",
    "\n",
    "**‚ö†Ô∏è If your dataset is missing certain types:**\n",
    "- **Text-only datasets**: Focus on Parts 1-3 (text cleaning and standardization)\n",
    "- **Mostly numeric datasets**: Focus on Parts 4-5 (grouping and aggregation)\n",
    "- **Very small datasets**: Practice the techniques but note that patterns may not be statistically meaningful\n",
    "\n",
    "### üìÇ Recommended Dataset Sources:\n",
    "- **Kaggle**: Movies, books, music, museums, historical records\n",
    "- **Government data**: Cultural statistics, census data, arts funding\n",
    "- **Academic repositories**: Digital humanities collections\n",
    "- **Cultural institutions**: Museum collections, library catalogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06d071f",
   "metadata": {},
   "source": [
    "## Part 1: Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0af301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set display options for better readability\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2e3c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your cultural dataset\n",
    "# Replace 'your_filename.csv' with your actual file name\n",
    "# For other file types, use: pd.read_excel(), pd.read_json(), etc.\n",
    "\n",
    "my_data = pd.read_csv('your_filename.csv')\n",
    "\n",
    "print(f\"‚úÖ Loaded dataset with {len(my_data)} rows and {len(my_data.columns)} columns\")\n",
    "print(f\"Dataset shape: {my_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df1e8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First look at your data\n",
    "print(\"First 5 rows:\")\n",
    "my_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd7a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get basic information about your dataset\n",
    "print(\"Dataset info:\")\n",
    "my_data.info()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Column names:\")\n",
    "print(list(my_data.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bea1709",
   "metadata": {},
   "source": [
    "### ü§î Reflection: Initial Observations\n",
    "**Write your observations about your dataset:**\n",
    "1. **What cultural topic does this data represent?**\n",
    "\n",
    "2. **What are the main columns and what do they represent?**\n",
    "\n",
    "3. **What data types do you see? (text, numbers, dates, etc.)**\n",
    "\n",
    "4. **What potential data quality issues do you notice?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52626c9",
   "metadata": {},
   "source": [
    "## Part 2: Identifying Data Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0381c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing data\n",
    "print(\"Missing data summary:\")\n",
    "missing_data = my_data.isnull().sum()\n",
    "print(missing_data[missing_data > 0])  # Only show columns with missing data\n",
    "\n",
    "print(f\"\\nTotal missing values: {my_data.isnull().sum().sum()}\")\n",
    "print(f\"Percentage of missing data: {(my_data.isnull().sum().sum() / (len(my_data) * len(my_data.columns))) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27192c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine unique values in text/categorical columns\n",
    "print(\"Unique values in categorical columns:\")\n",
    "print(\"(Look for inconsistencies, duplicates, and formatting issues)\\n\")\n",
    "\n",
    "for col in my_data.select_dtypes(include=['object']).columns:\n",
    "    unique_count = my_data[col].nunique()\n",
    "    print(f\"{col} ({unique_count} unique values):\")\n",
    "    if unique_count <= 20:  # Show all if 20 or fewer\n",
    "        print(f\"  {sorted(my_data[col].dropna().unique())}\")\n",
    "    else:  # Show first 10 if more than 20\n",
    "        print(f\"  First 10: {sorted(my_data[col].dropna().unique())[:10]}\")\n",
    "        print(f\"  ... and {unique_count - 10} more\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd478e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for potential duplicates\n",
    "duplicate_rows = my_data.duplicated().sum()\n",
    "print(f\"Complete duplicate rows: {duplicate_rows}\")\n",
    "\n",
    "if duplicate_rows > 0:\n",
    "    print(\"\\nDuplicate rows:\")\n",
    "    print(my_data[my_data.duplicated()])\n",
    "else:\n",
    "    print(\"‚úÖ No complete duplicate rows found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7457fd",
   "metadata": {},
   "source": [
    "### üìù Data Problems Identified:\n",
    "**List the specific issues you found in your data:**\n",
    "\n",
    "**Missing Data:**\n",
    "- \n",
    "\n",
    "**Text/Formatting Issues:**\n",
    "- \n",
    "\n",
    "**Duplicate Issues:**\n",
    "- \n",
    "\n",
    "**Other Problems:**\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f555ba2",
   "metadata": {},
   "source": [
    "## Part 3: Creating Your Data Cleaning Plan\n",
    "\n",
    "Before cleaning, create a systematic plan based on your data problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17ed982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for cleaning (preserve original)\n",
    "my_data_cleaned = my_data.copy()\n",
    "\n",
    "print(\"‚úÖ Created copy for cleaning\")\n",
    "print(f\"Original data: {len(my_data)} rows\")\n",
    "print(f\"Working copy: {len(my_data_cleaned)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e9fcbd",
   "metadata": {},
   "source": [
    "### üéØ My Cleaning Strategy:\n",
    "**Write your step-by-step plan:**\n",
    "\n",
    "1. **Missing Data Strategy:**\n",
    "   - \n",
    "\n",
    "2. **Text Standardization Tasks:**\n",
    "   - \n",
    "\n",
    "3. **Category Cleaning:**\n",
    "   - \n",
    "\n",
    "4. **Duplicate Handling:**\n",
    "   - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24d2426",
   "metadata": {},
   "source": [
    "## Part 4: Text Cleaning and Standardization\n",
    "\n",
    "Apply pandas string methods to clean and standardize your text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b192b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Standardize capitalization for a text column\n",
    "# Replace 'column_name' with your actual column name\n",
    "\n",
    "# Before cleaning:\n",
    "# print(\"Before standardization:\")\n",
    "# print(my_data_cleaned['column_name'].unique())\n",
    "\n",
    "# Apply title case:\n",
    "# my_data_cleaned['column_name'] = my_data_cleaned['column_name'].str.title()\n",
    "\n",
    "# After cleaning:\n",
    "# print(\"\\nAfter standardization:\")\n",
    "# print(my_data_cleaned['column_name'].unique())\n",
    "\n",
    "print(\"Add your text cleaning code here\")\n",
    "print(\"Use the examples from the main lesson as templates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528402ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create category mappings to standardize similar values\n",
    "# Replace with your actual column and categories\n",
    "\n",
    "# category_mapping = {\n",
    "#     'old_value_1': 'Standard_Value_1',\n",
    "#     'old_value_2': 'Standard_Value_1',  # Multiple old values can map to same new value\n",
    "#     'old_value_3': 'Standard_Value_2'\n",
    "# }\n",
    "\n",
    "# Apply mapping:\n",
    "# my_data_cleaned['column_name_clean'] = my_data_cleaned['column_name'].str.lower()\n",
    "# my_data_cleaned['column_name_clean'] = my_data_cleaned['column_name_clean'].replace(category_mapping)\n",
    "# my_data_cleaned['column_name_clean'] = my_data_cleaned['column_name_clean'].str.title()\n",
    "\n",
    "print(\"Add your category mapping code here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7bf665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing data for text columns\n",
    "# Choose appropriate strategy based on your data\n",
    "\n",
    "# Option 1: Fill with placeholder\n",
    "# my_data_cleaned['column_name'] = my_data_cleaned['column_name'].fillna('Unknown')\n",
    "\n",
    "# Option 2: Drop rows with missing values in critical columns\n",
    "# my_data_cleaned = my_data_cleaned.dropna(subset=['critical_column'])\n",
    "\n",
    "print(\"Add your missing data handling code here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe08e60f",
   "metadata": {},
   "source": [
    "## Part 5: Handling Numeric Data and Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e69d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing numeric data\n",
    "# Choose strategy based on your data and research questions\n",
    "\n",
    "# Option 1: Fill with median (robust to outliers)\n",
    "# numeric_column = 'your_numeric_column'\n",
    "# median_value = my_data_cleaned[numeric_column].median()\n",
    "# my_data_cleaned[numeric_column] = my_data_cleaned[numeric_column].fillna(median_value)\n",
    "# print(f\"Filled missing {numeric_column} with median: {median_value}\")\n",
    "\n",
    "# Option 2: Fill with mean\n",
    "# mean_value = my_data_cleaned[numeric_column].mean()\n",
    "# my_data_cleaned[numeric_column] = my_data_cleaned[numeric_column].fillna(mean_value)\n",
    "\n",
    "# Option 3: Fill based on category groups\n",
    "# my_data_cleaned[numeric_column] = my_data_cleaned.groupby('category_column')[numeric_column].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "print(\"Add your numeric data cleaning code here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d646ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data types if needed\n",
    "# Example: Convert string numbers to numeric\n",
    "# my_data_cleaned['numeric_column'] = pd.to_numeric(my_data_cleaned['numeric_column'], errors='coerce')\n",
    "\n",
    "# Example: Convert string dates to datetime\n",
    "# my_data_cleaned['date_column'] = pd.to_datetime(my_data_cleaned['date_column'], errors='coerce')\n",
    "\n",
    "print(\"Add data type conversion code here if needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7538d803",
   "metadata": {},
   "source": [
    "## Part 6: Checking Your Cleaning Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be10cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare before and after cleaning\n",
    "print(\"CLEANING SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Original dataset: {len(my_data)} rows, {len(my_data.columns)} columns\")\n",
    "print(f\"Cleaned dataset: {len(my_data_cleaned)} rows, {len(my_data_cleaned.columns)} columns\")\n",
    "print(f\"Rows removed: {len(my_data) - len(my_data_cleaned)}\")\n",
    "print(f\"Columns added: {len(my_data_cleaned.columns) - len(my_data.columns)}\")\n",
    "\n",
    "print(\"\\nMissing data comparison:\")\n",
    "print(f\"Original missing values: {my_data.isnull().sum().sum()}\")\n",
    "print(f\"Cleaned missing values: {my_data_cleaned.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c06404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final check of cleaned data\n",
    "print(\"Cleaned data sample:\")\n",
    "my_data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccf5849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check remaining data issues\n",
    "print(\"Remaining missing data:\")\n",
    "remaining_missing = my_data_cleaned.isnull().sum()\n",
    "print(remaining_missing[remaining_missing > 0])\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "print(my_data_cleaned.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8818562",
   "metadata": {},
   "source": [
    "## Part 7: Data Analysis and Exploration\n",
    "\n",
    "Now that your data is clean, perform some exploratory analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51838726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic descriptive statistics for numeric columns\n",
    "print(\"Descriptive statistics:\")\n",
    "my_data_cleaned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d24701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts for categorical columns\n",
    "# Replace 'category_column' with your actual column name\n",
    "\n",
    "# print(\"Distribution of categories:\")\n",
    "# category_counts = my_data_cleaned['category_column'].value_counts()\n",
    "# print(category_counts)\n",
    "\n",
    "print(\"Add your categorical analysis code here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca45ec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby analysis (if you have both categorical and numeric data)\n",
    "# Replace column names with your actual columns\n",
    "\n",
    "# grouped_analysis = my_data_cleaned.groupby('category_column').agg({\n",
    "#     'numeric_column_1': ['mean', 'count'],\n",
    "#     'numeric_column_2': ['sum', 'median']\n",
    "# })\n",
    "# print(\"Analysis by category:\")\n",
    "# print(grouped_analysis)\n",
    "\n",
    "print(\"Add your groupby analysis code here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe5a998",
   "metadata": {},
   "source": [
    "## Part 8: Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b209646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations appropriate for your data\n",
    "# Examples:\n",
    "\n",
    "# Bar chart for categorical data:\n",
    "# category_counts = my_data_cleaned['category_column'].value_counts()\n",
    "# category_counts.plot(kind='bar', title='Distribution of Categories', figsize=(10, 6))\n",
    "# plt.xlabel('Category')\n",
    "# plt.ylabel('Count')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "print(\"Add your visualization code here\")\n",
    "print(\"Consider: bar charts, histograms, scatter plots, or time series plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1795c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second visualization\n",
    "# Example: Histogram for numeric data:\n",
    "# my_data_cleaned['numeric_column'].hist(bins=20, title='Distribution of Numeric Values', figsize=(8, 6))\n",
    "# plt.xlabel('Value')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n",
    "\n",
    "print(\"Add a second visualization here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ab77fc",
   "metadata": {},
   "source": [
    "## Part 9: Save Your Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6e0aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your cleaned dataset\n",
    "output_filename = 'my_cleaned_cultural_data.csv'\n",
    "my_data_cleaned.to_csv(output_filename, index=False)\n",
    "print(f\"‚úÖ Saved cleaned dataset as: {output_filename}\")\n",
    "\n",
    "# Optional: Save analysis results\n",
    "# if 'grouped_analysis' in locals():\n",
    "#     grouped_analysis.to_csv('my_analysis_results.csv')\n",
    "#     print(\"‚úÖ Saved analysis results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dce7a3b",
   "metadata": {},
   "source": [
    "## Part 10: Reflection and Cultural Insights\n",
    "\n",
    "### üéØ Data Cleaning Reflection:\n",
    "**What did you learn about your data through the cleaning process?**\n",
    "\n",
    "\n",
    "**What were the biggest challenges in cleaning your dataset?**\n",
    "\n",
    "\n",
    "**How did cleaning change your understanding of the data quality?**\n",
    "\n",
    "\n",
    "### üìä Cultural Analysis Insights:\n",
    "**What patterns or trends did you discover in your clean data?**\n",
    "\n",
    "\n",
    "**What cultural questions does your analysis raise?**\n",
    "\n",
    "\n",
    "**How might data quality issues have affected historical or cultural research using similar datasets?**\n",
    "\n",
    "\n",
    "### üîç Next Steps:\n",
    "**What additional analysis would you like to perform?**\n",
    "\n",
    "\n",
    "**What other datasets could you combine with this one?**\n",
    "\n",
    "\n",
    "**How could this cleaned data be useful for cultural research or digital humanities projects?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91a3dae",
   "metadata": {},
   "source": [
    "## üìö Summary: Your Data Cleaning Journey\n",
    "\n",
    "Congratulations! You've successfully:\n",
    "\n",
    "### ‚úÖ Technical Skills Practiced:\n",
    "- Identified and documented data quality issues\n",
    "- Applied pandas string methods for text standardization\n",
    "- Handled missing data with appropriate strategies\n",
    "- Created clean, analysis-ready datasets\n",
    "- Performed exploratory data analysis\n",
    "- Created meaningful visualizations\n",
    "\n",
    "### ‚úÖ Cultural Research Skills Developed:\n",
    "- Critical evaluation of data quality and bias\n",
    "- Understanding the impact of data cleaning choices on analysis\n",
    "- Recognition of patterns in cultural datasets\n",
    "- Appreciation for the complexity of real-world cultural data\n",
    "\n",
    "### üéì Next Steps in Your Cultural Data Journey:\n",
    "1. **Practice with different datasets** to encounter various cleaning challenges\n",
    "2. **Learn advanced pandas techniques** like merging multiple datasets\n",
    "3. **Explore specialized tools** for your specific cultural research interests\n",
    "4. **Share your findings** with classmates and the broader academic community\n",
    "\n",
    "Remember: **Clean data is the foundation of trustworthy cultural analysis.** The skills you've practiced here will serve you well in any data-driven cultural research project!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
