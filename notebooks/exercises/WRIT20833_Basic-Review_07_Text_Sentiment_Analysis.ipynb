{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/TCU-DCDA/WRIT20833-2025/blob/main/notebooks/exercises/Review_07_Text_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WRIT 20833 Review 07: Text Analysis & Sentiment Analysis\n",
    "\n",
    "Analyze cultural texts and measure emotional sentiment computationally.\n",
    "\n",
    "**Make a copy:** File > Save a copy in Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Setting Up Text Analysis Tools\n",
    "Install and import libraries for text and sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (only run once in Colab)\n",
    "# !pip install vaderSentiment textstat\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import sentiment analysis tools\n",
    "try:\n",
    "    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "    sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "    print(\" VADER Sentiment Analyzer loaded successfully\")\n",
    "except ImportError:\n",
    "    print(\" VADER not installed. Run: !pip install vaderSentiment\")\n",
    "    # Fallback simple sentiment function\n",
    "    def simple_sentiment(text):\n",
    "        positive_words = ['good', 'great', 'excellent', 'amazing', 'wonderful', 'love', 'beautiful', 'brilliant']\n",
    "        negative_words = ['bad', 'terrible', 'awful', 'horrible', 'hate', 'ugly', 'stupid', 'worst']\n",
    "        \n",
    "        text_lower = text.lower()\n",
    "        pos_count = sum(word in text_lower for word in positive_words)\n",
    "        neg_count = sum(word in text_lower for word in negative_words)\n",
    "        \n",
    "        if pos_count > neg_count:\n",
    "            return {'compound': 0.5, 'sentiment': 'positive'}\n",
    "        elif neg_count > pos_count:\n",
    "            return {'compound': -0.5, 'sentiment': 'negative'}\n",
    "        else:\n",
    "            return {'compound': 0.0, 'sentiment': 'neutral'}\n",
    "\n",
    "# Test sentiment analysis\n",
    "sample_texts = [\n",
    "    \"This book is absolutely wonderful and brilliant!\",\n",
    "    \"I hate this terrible, awful story.\",\n",
    "    \"The weather is nice today.\"\n",
    "]\n",
    "\n",
    "print(\"\\nTesting sentiment analysis:\")\n",
    "for text in sample_texts:\n",
    "    try:\n",
    "        scores = sentiment_analyzer.polarity_scores(text)\n",
    "        sentiment = 'positive' if scores['compound'] > 0.1 else 'negative' if scores['compound'] < -0.1 else 'neutral'\n",
    "        print(f\"Text: \\\"{text}\\\"\")\n",
    "        print(f\"Sentiment: {sentiment} (score: {scores['compound']:.2f})\")\n",
    "        print()\n",
    "    except NameError:\n",
    "        result = simple_sentiment(text)\n",
    "        print(f\"Text: \\\"{text}\\\"\")\n",
    "        print(f\"Sentiment: {result['sentiment']} (score: {result['compound']:.2f})\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Basic Text Analysis Functions\n",
    "Create functions to analyze text characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text analysis functions\n",
    "def analyze_text_basics(text):\n",
    "    \\\"\\\"\\\"Perform basic text analysis\\\"\\\"\\\" \n",
    "    \n",
    "    # Basic counts\n",
    "    char_count = len(text)\n",
    "    word_count = len(text.split())\n",
    "    sentence_count = len([s for s in re.split(r'[.!?]+', text) if s.strip()])\n",
    "    \n",
    "    # Calculate averages\n",
    "    avg_word_length = sum(len(word.strip('.,!?;:')) for word in text.split()) / word_count if word_count > 0 else 0\n",
    "    avg_sentence_length = word_count / sentence_count if sentence_count > 0 else word_count\n",
    "    \n",
    "    # Vocabulary richness\n",
    "    words = [word.lower().strip('.,!?;:\"') for word in text.split()]\n",
    "    unique_words = len(set(words))\n",
    "    lexical_diversity = unique_words / word_count if word_count > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'char_count': char_count,\n",
    "        'word_count': word_count,\n",
    "        'sentence_count': sentence_count,\n",
    "        'avg_word_length': round(avg_word_length, 2),\n",
    "        'avg_sentence_length': round(avg_sentence_length, 2),\n",
    "        'unique_words': unique_words,\n",
    "        'lexical_diversity': round(lexical_diversity, 3)\n",
    "    }\n",
    "\n",
    "def get_word_frequencies(text, top_n=10):\n",
    "    \\\"\\\"\\\"Get most frequent words in text\\\"\\\"\\\" \n",
    "    \n",
    "    # Simple stopwords list\n",
    "    stopwords = {'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', \n",
    "                 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had',\n",
    "                 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might', 'must',\n",
    "                 'i', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them',\n",
    "                 'my', 'your', 'his', 'her', 'its', 'our', 'their', 'this', 'that', 'these', 'those'}\n",
    "    \n",
    "    # Clean and count words\n",
    "    words = [word.lower().strip('.,!?;:\"()') for word in text.split()]\n",
    "    content_words = [word for word in words if word and word not in stopwords and len(word) > 2]\n",
    "    \n",
    "    word_freq = Counter(content_words)\n",
    "    return word_freq.most_common(top_n)\n",
    "\n",
    "# Test with literary examples\n",
    "shakespeare_quote = \\\"\\\"\\\"To be, or not to be, that is the question: \n",
    "Whether 'tis nobler in the mind to suffer \n",
    "The slings and arrows of outrageous fortune, \n",
    "Or to take arms against a sea of troubles \n",
    "And by opposing end them.\\\"\\\"\\\"\n",
    "\n",
    "print(\"Text Analysis of Shakespeare's Hamlet:\")\n",
    "analysis = analyze_text_basics(shakespeare_quote)\n",
    "for key, value in analysis.items():\n",
    "    print(f\"{key.replace('_', ' ').title()}: {value}\")\n",
    "\n",
    "print(\"\\nMost frequent content words:\")\n",
    "freq_words = get_word_frequencies(shakespeare_quote, 5)\n",
    "for word, count in freq_words:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Sentiment Analysis of Cultural Texts\n",
    "Analyze emotional sentiment in various cultural works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze sentiment\n",
    "def analyze_sentiment(text, title=\\\"Text\\\"):\n",
    "    \\\"\\\"\\\"Analyze sentiment of text using VADER or fallback method\\\"\\\"\\\" \n",
    "    \n",
    "    try:\n",
    "        # Use VADER if available\n",
    "        scores = sentiment_analyzer.polarity_scores(text)\n",
    "        \n",
    "        # Determine overall sentiment\n",
    "        if scores['compound'] >= 0.05:\n",
    "            overall = 'Positive'\n",
    "        elif scores['compound'] <= -0.05:\n",
    "            overall = 'Negative'\n",
    "        else:\n",
    "            overall = 'Neutral'\n",
    "        \n",
    "        return {\n",
    "            'title': title,\n",
    "            'positive': scores['pos'],\n",
    "            'neutral': scores['neu'],\n",
    "            'negative': scores['neg'],\n",
    "            'compound': scores['compound'],\n",
    "            'overall': overall\n",
    "        }\n",
    "    \n",
    "    except NameError:\n",
    "        # Fallback method\n",
    "        result = simple_sentiment(text)\n",
    "        return {\n",
    "            'title': title,\n",
    "            'positive': 0.5 if result['sentiment'] == 'positive' else 0.0,\n",
    "            'neutral': 0.5 if result['sentiment'] == 'neutral' else 0.0,\n",
    "            'negative': 0.5 if result['sentiment'] == 'negative' else 0.0,\n",
    "            'compound': result['compound'],\n",
    "            'overall': result['sentiment'].title()\n",
    "        }\n",
    "\n",
    "# Cultural text samples for analysis\n",
    "cultural_texts = {\n",
    "    \\\"MLK Dream\\\": \\\"\\\"\\\"I have a dream that one day this nation will rise up and live out the true meaning of its creed: \n",
    "    We hold these truths to be self-evident, that all men are created equal. I have a dream that one day on the red hills \n",
    "    of Georgia, the sons of former slaves and the sons of former slave owners will be able to sit down together at the \n",
    "    table of brotherhood.\\\"\\\"\\\",\n",
    "    \n",
    "    \\\"Poe Raven\\\": \\\"\\\"\\\"Once upon a midnight dreary, while I pondered, weak and weary, \n",
    "    Over many a quaint and curious volume of forgotten lore While I nodded, nearly napping, \n",
    "    suddenly there came a tapping, As of some one gently rapping, rapping at my chamber door. \n",
    "    'Tis some visitor,' I muttered, 'tapping at my chamber door Only this and nothing more.'\\\"\\\"\\\",\n",
    "    \n",
    "    \\\"Austen Pride\\\": \\\"\\\"\\\"It is a truth universally acknowledged, that a single man in possession of a good fortune, \n",
    "    must be in want of a wife. However little known the feelings or views of such a man may be on his first \n",
    "    entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, \n",
    "    that he is considered the rightful property of some one or other of their daughters.\\\"\\\"\\\",\n",
    "    \n",
    "    \\\"Orwell 1984\\\": \\\"\\\"\\\"It was a bright cold day in April, and the clocks were striking thirteen. \n",
    "    Winston Smith, his chin nuzzled into his breast in an effort to escape the vile wind, \n",
    "    slipped quickly through the glass doors of Victory Mansions, though not quickly enough \n",
    "    to prevent a swirl of gritty dust from entering along with him.\\\"\\\"\\\"\n",
    "}\n",
    "\n",
    "# Analyze sentiment for each text\n",
    "print(\\\"SENTIMENT ANALYSIS OF CULTURAL TEXTS\\\")\n",
    "print(\\\"=\\\" * 50)\n",
    "\n",
    "sentiment_results = []\n",
    "for title, text in cultural_texts.items():\n",
    "    result = analyze_sentiment(text, title)\n",
    "    sentiment_results.append(result)\n",
    "    \n",
    "    print(f\\\"\\n{title}:\")\n",
    "    print(f\\\"  Overall Sentiment: {result['overall']}\\\")\n",
    "    print(f\\\"  Compound Score: {result['compound']:.3f}\\\")\n",
    "    print(f\\\"  Positive: {result['positive']:.2f} | Neutral: {result['neutral']:.2f} | Negative: {result['negative']:.2f}\\\")\n",
    "\n",
    "# Create summary DataFrame\n",
    "sentiment_df = pd.DataFrame(sentiment_results)\n",
    "print(f\\\"\\nSENTIMENT SUMMARY:\\\")\n",
    "print(sentiment_df[['title', 'overall', 'compound']].to_string(index=False))\n",
    "\n",
    "# Sentiment distribution\n",
    "sentiment_counts = sentiment_df['overall'].value_counts()\n",
    "print(f\\\"\\nSentiment Distribution:\\\")\n",
    "for sentiment, count in sentiment_counts.items():\n",
    "    print(f\\\"{sentiment}: {count} texts\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Comparative Text Analysis\n",
    "Compare multiple texts across different dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for comprehensive text comparison\n",
    "def comprehensive_text_analysis(texts_dict):\n",
    "    \\\"\\\"\\\"Perform comprehensive analysis on multiple texts\\\"\\\"\\\" \n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for title, text in texts_dict.items():\n",
    "        # Basic text analysis\n",
    "        basic_stats = analyze_text_basics(text)\n",
    "        \n",
    "        # Sentiment analysis\n",
    "        sentiment = analyze_sentiment(text, title)\n",
    "        \n",
    "        # Word frequency analysis\n",
    "        top_words = get_word_frequencies(text, 3)\n",
    "        \n",
    "        # Combine all analysis\n",
    "        result = {\n",
    "            'title': title,\n",
    "            'word_count': basic_stats['word_count'],\n",
    "            'sentence_count': basic_stats['sentence_count'],\n",
    "            'avg_word_length': basic_stats['avg_word_length'],\n",
    "            'lexical_diversity': basic_stats['lexical_diversity'],\n",
    "            'sentiment_overall': sentiment['overall'],\n",
    "            'sentiment_score': sentiment['compound'],\n",
    "            'top_words': [word for word, count in top_words]\n",
    "        }\n",
    "        \n",
    "        results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Perform comprehensive analysis\n",
    "comprehensive_results = comprehensive_text_analysis(cultural_texts)\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "analysis_df = pd.DataFrame(comprehensive_results)\n",
    "\n",
    "print(\\\"COMPREHENSIVE TEXT ANALYSIS\\\")\n",
    "print(\\\"=\\\" * 50)\n",
    "print(analysis_df[['title', 'word_count', 'avg_word_length', 'lexical_diversity', 'sentiment_overall']].to_string(index=False))\n",
    "\n",
    "print(f\\\"\\nSTATISTICAL SUMMARY:\\\")\n",
    "print(f\\\"Average word count: {analysis_df['word_count'].mean():.1f}\\\")\n",
    "print(f\\\"Average word length: {analysis_df['avg_word_length'].mean():.2f} characters\\\")\n",
    "print(f\\\"Average lexical diversity: {analysis_df['lexical_diversity'].mean():.3f}\\\")\n",
    "print(f\\\"Average sentiment score: {analysis_df['sentiment_score'].mean():.3f}\\\")\n",
    "\n",
    "# Find extremes\n",
    "print(f\\\"\\nEXTREME VALUES:\\\")\n",
    "most_words = analysis_df.loc[analysis_df['word_count'].idxmax()]\n",
    "print(f\\\"Most words: {most_words['title']} ({most_words['word_count']} words)\\\")\n",
    "\n",
    "most_diverse = analysis_df.loc[analysis_df['lexical_diversity'].idxmax()]\n",
    "print(f\\\"Most lexically diverse: {most_diverse['title']} ({most_diverse['lexical_diversity']:.3f})\\\")\n",
    "\n",
    "most_positive = analysis_df.loc[analysis_df['sentiment_score'].idxmax()]\n",
    "print(f\\\"Most positive: {most_positive['title']} (score: {most_positive['sentiment_score']:.3f})\\\")\n",
    "\n",
    "most_negative = analysis_df.loc[analysis_df['sentiment_score'].idxmin()]\n",
    "print(f\\\"Most negative: {most_negative['title']} (score: {most_negative['sentiment_score']:.3f})\\\")\n",
    "\n",
    "# Group by sentiment\n",
    "print(f\\\"\\nGROUPED BY SENTIMENT:\\\")\n",
    "sentiment_groups = analysis_df.groupby('sentiment_overall').agg({\n",
    "    'word_count': 'mean',\n",
    "    'avg_word_length': 'mean',\n",
    "    'lexical_diversity': 'mean'\n",
    "})\n",
    "print(sentiment_groups.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Emotional Word Analysis\n",
    "Identify and categorize emotional language in texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion word dictionaries (simplified)\n",
    "emotion_words = {\n",
    "    'joy': ['happy', 'joy', 'delight', 'cheerful', 'glad', 'pleased', 'elated', 'ecstatic', 'blissful', 'radiant'],\n",
    "    'sadness': ['sad', 'sorrow', 'grief', 'melancholy', 'despair', 'gloom', 'misery', 'anguish', 'heartbreak'],\n",
    "    'anger': ['angry', 'rage', 'fury', 'wrath', 'irritated', 'annoyed', 'furious', 'livid', 'incensed'],\n",
    "    'fear': ['fear', 'afraid', 'scared', 'terrified', 'anxious', 'worried', 'nervous', 'frightened', 'alarmed'],\n",
    "    'love': ['love', 'adore', 'cherish', 'affection', 'devotion', 'passion', 'romance', 'tender', 'beloved'],\n",
    "    'hope': ['hope', 'optimism', 'faith', 'trust', 'confidence', 'aspiration', 'dream', 'wish', 'believe']\n",
    "}\n",
    "\n",
    "def analyze_emotions(text, title=\\\"Text\\\"):\n",
    "    \\\"\\\"\\\"Analyze emotional content in text\\\"\\\"\\\" \n",
    "    \n",
    "    # Clean text for analysis\n",
    "    words = re.findall(r'\\\\b\\\\w+\\\\b', text.lower())\n",
    "    \n",
    "    # Count emotional words\n",
    "    emotion_counts = {}\n",
    "    emotion_matches = {}\n",
    "    \n",
    "    for emotion, word_list in emotion_words.items():\n",
    "        matches = [word for word in words if word in word_list]\n",
    "        emotion_counts[emotion] = len(matches)\n",
    "        emotion_matches[emotion] = matches\n",
    "    \n",
    "    # Calculate emotional intensity\n",
    "    total_emotion_words = sum(emotion_counts.values())\n",
    "    total_words = len(words)\n",
    "    emotional_density = total_emotion_words / total_words if total_words > 0 else 0\n",
    "    \n",
    "    # Find dominant emotion\n",
    "    dominant_emotion = max(emotion_counts, key=emotion_counts.get) if total_emotion_words > 0 else 'neutral'\n",
    "    \n",
    "    return {\n",
    "        'title': title,\n",
    "        'emotion_counts': emotion_counts,\n",
    "        'emotion_matches': emotion_matches,\n",
    "        'emotional_density': round(emotional_density, 4),\n",
    "        'dominant_emotion': dominant_emotion,\n",
    "        'total_emotion_words': total_emotion_words\n",
    "    }\n",
    "\n",
    "# Analyze emotions in cultural texts\n",
    "print(\\\"EMOTIONAL WORD ANALYSIS\\\")\n",
    "print(\\\"=\\\" * 40)\n",
    "\n",
    "emotion_results = []\n",
    "for title, text in cultural_texts.items():\n",
    "    emotion_analysis = analyze_emotions(text, title)\n",
    "    emotion_results.append(emotion_analysis)\n",
    "    \n",
    "    print(f\\\"\\n{title}:\\\")\n",
    "    print(f\\\"  Dominant emotion: {emotion_analysis['dominant_emotion']}\\\")\n",
    "    print(f\\\"  Emotional density: {emotion_analysis['emotional_density']:.1%}\\\")\n",
    "    print(f\\\"  Total emotion words: {emotion_analysis['total_emotion_words']}\\\")\n",
    "    \n",
    "    # Show emotion breakdown\n",
    "    print(f\\\"  Emotion breakdown:\\\")\n",
    "    for emotion, count in emotion_analysis['emotion_counts'].items():\n",
    "        if count > 0:\n",
    "            matches = emotion_analysis['emotion_matches'][emotion]\n",
    "            print(f\\\"    {emotion.title()}: {count} ({', '.join(matches)})\\\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\\\"\\n\\nEMOTIONAL SUMMARY:\\\")\n",
    "print(\\\"=\\\" * 20)\n",
    "\n",
    "# Aggregate emotion counts across all texts\n",
    "total_emotions = {emotion: 0 for emotion in emotion_words.keys()}\n",
    "for result in emotion_results:\n",
    "    for emotion, count in result['emotion_counts'].items():\n",
    "        total_emotions[emotion] += count\n",
    "\n",
    "print(\\\"Total emotional words across all texts:\\\")\n",
    "for emotion, total in sorted(total_emotions.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\\\"{emotion.title()}: {total}\\\")\n",
    "\n",
    "# Most emotionally dense text\n",
    "most_emotional = max(emotion_results, key=lambda x: x['emotional_density'])\n",
    "print(f\\\"\\nMost emotionally dense text: {most_emotional['title']} ({most_emotional['emotional_density']:.1%})\\\")\n",
    "\n",
    "least_emotional = min(emotion_results, key=lambda x: x['emotional_density'])\n",
    "print(f\\\"Least emotionally dense text: {least_emotional['title']} ({least_emotional['emotional_density']:.1%})\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Creating Your Own Text Analysis\n",
    "Apply text analysis to your own cultural texts of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add your own texts for analysis\n",
    "# Consider: Song lyrics, poems, speeches, book excerpts, movie quotes, etc.\n",
    "\n",
    "your_texts = {\n",
    "    # TODO: Replace these with texts that interest you\n",
    "    \\\"Sample Text 1\\\": \\\"\\\"\\\"Replace this with a text you want to analyze. \n",
    "    This could be song lyrics, a poem, a speech excerpt, or any cultural text \n",
    "    that interests you. Make sure it's long enough for meaningful analysis.\\\"\\\"\\\",\n",
    "    \n",
    "    \\\"Sample Text 2\\\": \\\"\\\"\\\"Add another text here for comparison. \n",
    "    Consider choosing texts from different genres, time periods, or cultural contexts \n",
    "    to see how they differ in sentiment and emotional content.\\\"\\\"\\\",\n",
    "    \n",
    "    \\\"Sample Text 3\\\": \\\"\\\"\\\"A third text allows for richer comparison. \n",
    "    You might want to include texts that you hypothesize will have different \n",
    "    emotional tones or writing styles.\\\"\\\"\\\"\n",
    "}\n",
    "\n",
    "# TODO: Perform your analysis\n",
    "print(\\\"YOUR TEXT ANALYSIS PROJECT\\\")\n",
    "print(\\\"=\\\" * 40)\n",
    "\n",
    "if len(your_texts) > 0 and list(your_texts.values())[0] != \\\"\\\"\\\"Replace this with a text you want to analyze. \n",
    "    This could be song lyrics, a poem, a speech excerpt, or any cultural text \n",
    "    that interests you. Make sure it's long enough for meaningful analysis.\\\"\\\"\\\":\n",
    "    \n",
    "    # Perform comprehensive analysis on your texts\n",
    "    your_results = comprehensive_text_analysis(your_texts)\n",
    "    your_df = pd.DataFrame(your_results)\n",
    "    \n",
    "    print(\\\"Basic Analysis Results:\\\")\n",
    "    print(your_df[['title', 'word_count', 'sentiment_overall', 'sentiment_score']].to_string(index=False))\n",
    "    \n",
    "    print(f\\\"\\nYour Analysis Summary:\\\")\n",
    "    print(f\\\"Most positive text: {your_df.loc[your_df['sentiment_score'].idxmax(), 'title']}\\\")\n",
    "    print(f\\\"Most negative text: {your_df.loc[your_df['sentiment_score'].idxmin(), 'title']}\\\")\n",
    "    print(f\\\"Longest text: {your_df.loc[your_df['word_count'].idxmax(), 'title']}\\\")\n",
    "    print(f\\\"Most diverse vocabulary: {your_df.loc[your_df['lexical_diversity'].idxmax(), 'title']}\\\")\n",
    "    \n",
    "    # Emotional analysis of your texts\n",
    "    print(f\\\"\\nEmotional Analysis of Your Texts:\\\")\n",
    "    for title, text in your_texts.items():\n",
    "        emotion_result = analyze_emotions(text, title)\n",
    "        print(f\\\"\\n{title}:\\\")\n",
    "        print(f\\\"  Dominant emotion: {emotion_result['dominant_emotion']}\\\")\n",
    "        print(f\\\"  Emotional density: {emotion_result['emotional_density']:.1%}\\\")\n",
    "        \n",
    "        # Show top emotions\n",
    "        sorted_emotions = sorted(emotion_result['emotion_counts'].items(), \n",
    "                                key=lambda x: x[1], reverse=True)[:3]\n",
    "        for emotion, count in sorted_emotions:\n",
    "            if count > 0:\n",
    "                print(f\\\"    {emotion.title()}: {count}\\\")\n",
    "else:\n",
    "    print(\\\"Please customize the 'your_texts' dictionary above with your own cultural texts!\\\")\n",
    "    print(\\\"Consider analyzing:\\\")\n",
    "    print(\\\"- Song lyrics from different genres\\\")\n",
    "    print(\\\"- Poems from different time periods\\\")\n",
    "    print(\\\"- Political speeches\\\")\n",
    "    print(\\\"- Movie or book quotes\\\")\n",
    "    print(\\\"- Social media posts\\\")\n",
    "    print(\\\"- Historical documents\\\")\n",
    "\n",
    "# Research questions to explore\n",
    "print(f\\\"\\n\\\" + \\\"=\\\"*50)\n",
    "print(\\\"RESEARCH QUESTIONS TO EXPLORE:\\\")\n",
    "print(\\\"- How does sentiment vary across different cultural genres?\\\")\n",
    "print(\\\"- What emotional patterns distinguish different historical periods?\\\")\n",
    "print(\\\"- How do authors use emotional language to achieve different effects?\\\")\n",
    "print(\\\"- What can computational analysis reveal about cultural texts that traditional analysis might miss?\\\")\n",
    "print(\\\"- What are the limitations of automated sentiment analysis for cultural interpretation?\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You explored:\n",
    "- Setting up and using sentiment analysis tools (VADER)\n",
    "- Creating functions for basic text analysis (word counts, lexical diversity)\n",
    "- Analyzing sentiment in classic cultural texts\n",
    "- Comparing multiple texts across various dimensions\n",
    "- Identifying emotional language patterns\n",
    "- Applying analysis to your own texts of interest\n",
    "- Critical evaluation of computational text analysis\n",
    "\n",
    "**Key Skills:**\n",
    "- Text preprocessing and cleaning\n",
    "- Sentiment analysis with compound scores\n",
    "- Word frequency analysis and stopword removal\n",
    "- Emotional content categorization\n",
    "- Comparative text analysis\n",
    "- Statistical summary of text features\n",
    "\n",
    "**Key Insights:**\n",
    "- Computational tools provide quantitative perspectives on cultural texts\n",
    "- Sentiment analysis can reveal patterns across large collections\n",
    "- Emotional language density varies significantly between genres and authors\n",
    "- Automated analysis complements but doesn't replace careful human interpretation\n",
    "- Cultural context and literary devices require careful consideration\n",
    "\n",
    "**Next:** Review 08 will cover data visualization for cultural analysis.\n",
    "\n",
    "---\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
