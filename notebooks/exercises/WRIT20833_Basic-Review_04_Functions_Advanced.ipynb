{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/TCU-DCDA/WRIT20833-2025/blob/main/notebooks/exercises/Review_04_Functions_Advanced.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WRIT 20833 Review 04: Functions & Advanced Processing\n",
    "\n",
    "Practice writing functions and processing complex cultural datasets.\n",
    "\n",
    "**Make a copy:** File > Save a copy in Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Basic Functions\n",
    "Write simple functions for text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze a quote\n",
    "def analyze_quote(text, author=\"Unknown\"):\n",
    "    word_count = len(text.split())\n",
    "    char_count = len(text)\n",
    "    \n",
    "    print(\"Quote by \" + author + \":\")\n",
    "    print(\"Text: \\\"\" + text + \"\\\"\")\n",
    "    print(\"Words: \" + str(word_count) + \", Characters: \" + str(char_count))\n",
    "    \n",
    "    return word_count  # Return for further processing\n",
    "\n",
    "# Test the function\n",
    "analyze_quote(\"To be or not to be, that is the question\", \"Shakespeare\")\n",
    "print()\n",
    "analyze_quote(\"I have a dream\", \"Martin Luther King Jr.\")\n",
    "print()\n",
    "analyze_quote(\"Hello world\")  # No author provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Functions with Return Values\n",
    "Create functions that calculate and return results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate reading time\n",
    "def calculate_reading_time(word_count, words_per_minute=200):\n",
    "    \"\"\"Calculate reading time in minutes\"\"\" \n",
    "    minutes = word_count / words_per_minute\n",
    "    return round(minutes, 1)\n",
    "\n",
    "# Function to categorize text length\n",
    "def categorize_length(word_count):\n",
    "    if word_count < 10:\n",
    "        return \"Very Short\"\n",
    "    elif word_count < 100:\n",
    "        return \"Short\"\n",
    "    elif word_count < 1000:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Long\"\n",
    "\n",
    "# Function to analyze difficulty (simplified)\n",
    "def analyze_difficulty(text):\n",
    "    words = text.split()\n",
    "    long_words = 0\n",
    "    for word in words:\n",
    "        if len(word) > 6:\n",
    "            long_words = long_words + 1\n",
    "    \n",
    "    if len(words) > 0:\n",
    "        percentage = (long_words / len(words)) * 100\n",
    "    else:\n",
    "        percentage = 0\n",
    "    \n",
    "    if percentage > 30:\n",
    "        return \"Difficult\"\n",
    "    elif percentage > 15:\n",
    "        return \"Moderate\"\n",
    "    else:\n",
    "        return \"Easy\"\n",
    "\n",
    "# Test with different texts\n",
    "texts = [\n",
    "    \"The cat sat on the mat\",\n",
    "    \"Understanding requires examination of phenomena\",\n",
    "    \"We hold these truths to be self-evident\"\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    word_count = len(text.split())\n",
    "    reading_time = calculate_reading_time(word_count)\n",
    "    category = categorize_length(word_count)\n",
    "    difficulty = analyze_difficulty(text)\n",
    "    \n",
    "    print(\"Text: \\\"\" + text + \"\\\"\")\n",
    "    print(\"Length: \" + category + \" (\" + str(word_count) + \" words)\")\n",
    "    print(\"Reading time: \" + str(reading_time) + \" minutes\")\n",
    "    print(\"Difficulty: \" + difficulty)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Processing Lists of Data\n",
    "Use functions to process cultural datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a book collection (simplified)\n",
    "def process_book_collection(books):\n",
    "    \"\"\"Analyze a collection of book dictionaries\"\"\" \n",
    "    total_books = len(books)\n",
    "    \n",
    "    # Calculate total pages\n",
    "    total_pages = 0\n",
    "    for book in books:\n",
    "        total_pages = total_pages + book[\"pages\"]\n",
    "    \n",
    "    if total_books > 0:\n",
    "        avg_pages = total_pages / total_books\n",
    "    else:\n",
    "        avg_pages = 0\n",
    "    \n",
    "    # Find oldest and newest books\n",
    "    oldest_year = books[0][\"year\"]\n",
    "    newest_year = books[0][\"year\"]\n",
    "    oldest_book = books[0]\n",
    "    newest_book = books[0]\n",
    "    \n",
    "    for book in books:\n",
    "        if book[\"year\"] < oldest_year:\n",
    "            oldest_year = book[\"year\"]\n",
    "            oldest_book = book\n",
    "        if book[\"year\"] > newest_year:\n",
    "            newest_year = book[\"year\"]\n",
    "            newest_book = book\n",
    "    \n",
    "    print(\"Collection Analysis:\")\n",
    "    print(\"Total books: \" + str(total_books))\n",
    "    print(\"Total pages: \" + str(total_pages))\n",
    "    print(\"Average pages: \" + str(int(avg_pages)))\n",
    "    print(\"Oldest: \" + oldest_book[\"title\"] + \" (\" + str(oldest_book[\"year\"]) + \")\")\n",
    "    print(\"Newest: \" + newest_book[\"title\"] + \" (\" + str(newest_book[\"year\"]) + \")\")\n",
    "    \n",
    "    return {\n",
    "        \"total_books\": total_books,\n",
    "        \"avg_pages\": avg_pages,\n",
    "        \"year_range\": newest_book[\"year\"] - oldest_book[\"year\"]\n",
    "    }\n",
    "\n",
    "# Sample book collection\n",
    "books = [\n",
    "    {\"title\": \"1984\", \"author\": \"George Orwell\", \"year\": 1949, \"pages\": 328},\n",
    "    {\"title\": \"Pride and Prejudice\", \"author\": \"Jane Austen\", \"year\": 1813, \"pages\": 432},\n",
    "    {\"title\": \"The Handmaid's Tale\", \"author\": \"Margaret Atwood\", \"year\": 1985, \"pages\": 311}\n",
    "]\n",
    "\n",
    "stats = process_book_collection(books)\n",
    "print(\"\\nYear span: \" + str(stats[\"year_range\"]) + \" years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Text Comparison Functions\n",
    "Compare and analyze multiple texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find common words (simplified)\n",
    "def find_common_words(text1, text2):\n",
    "    \"\"\"Find words that appear in both texts\"\"\" \n",
    "    words1 = text1.lower().split()\n",
    "    words2 = text2.lower().split()\n",
    "    \n",
    "    common = []\n",
    "    for word in words1:\n",
    "        if word in words2 and word not in common and len(word) >= 4:\n",
    "            common.append(word)\n",
    "    \n",
    "    return common\n",
    "\n",
    "# Function to calculate basic similarity\n",
    "def calculate_similarity(text1, text2):\n",
    "    \"\"\"Calculate basic similarity between texts\"\"\" \n",
    "    words1 = text1.lower().split()\n",
    "    words2 = text2.lower().split()\n",
    "    \n",
    "    # Count common words\n",
    "    common_count = 0\n",
    "    for word in words1:\n",
    "        if word in words2:\n",
    "            common_count = common_count + 1\n",
    "    \n",
    "    # Basic similarity calculation\n",
    "    total_words = len(words1) + len(words2)\n",
    "    if total_words > 0:\n",
    "        similarity = (common_count * 2) / total_words * 100\n",
    "    else:\n",
    "        similarity = 0\n",
    "    \n",
    "    return round(similarity, 1)\n",
    "\n",
    "# Function to compare writing styles (simplified)\n",
    "def compare_styles(text1, text2, title1=\"Text 1\", title2=\"Text 2\"):\n",
    "    \"\"\"Compare basic style metrics\"\"\" \n",
    "    \n",
    "    # Get stats for text 1\n",
    "    words1 = text1.split()\n",
    "    sentences1 = text1.count('.') + text1.count('!') + text1.count('?')\n",
    "    if sentences1 == 0:\n",
    "        sentences1 = 1\n",
    "    \n",
    "    # Get stats for text 2\n",
    "    words2 = text2.split()\n",
    "    sentences2 = text2.count('.') + text2.count('!') + text2.count('?')\n",
    "    if sentences2 == 0:\n",
    "        sentences2 = 1\n",
    "    \n",
    "    print(\"Style Comparison:\")\n",
    "    print(title1 + \": \" + str(len(words1)) + \" words, \" + str(sentences1) + \" sentences\")\n",
    "    print(title2 + \": \" + str(len(words2)) + \" words, \" + str(sentences2) + \" sentences\")\n",
    "\n",
    "# Test with historical texts\n",
    "declaration = \"We hold these truths to be self-evident, that all men are created equal.\"\n",
    "gettysburg = \"Four score and seven years ago our fathers brought forth a new nation.\"\n",
    "\n",
    "common_words = find_common_words(declaration, gettysburg)\n",
    "similarity = calculate_similarity(declaration, gettysburg)\n",
    "\n",
    "print(\"Common words: \" + str(common_words))\n",
    "print(\"Similarity: \" + str(similarity) + \"%\")\n",
    "print()\n",
    "compare_styles(declaration, gettysburg, \"Declaration\", \"Gettysburg Address\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Your Turn - Custom Functions\n",
    "Write functions for your research interests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a function relevant to your field of study\n",
    "# Examples: analyze_poem(), categorize_artwork(), process_historical_event()\n",
    "\n",
    "def analyze_my_data(item, category=\"general\"):\n",
    "    \"\"\"Customize this function for your research needs\"\"\" \n",
    "    \n",
    "    # TODO: Add your analysis logic here\n",
    "    # Consider: What would you want to measure or categorize?\n",
    "    \n",
    "    result = {\n",
    "        \"item\": item,\n",
    "        \"category\": category,\n",
    "        \"analysis\": \"Complete your analysis here\"\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "# TODO: Write a function that processes a list of your items\n",
    "def process_my_collection(items):\n",
    "    \"\"\"Process a collection of items from your field\"\"\" \n",
    "    \n",
    "    # TODO: Implement collection-level analysis\n",
    "    total_items = len(items)\n",
    "    \n",
    "    print(\"Processing \" + str(total_items) + \" items...\")\n",
    "    \n",
    "    for item in items:\n",
    "        # Process each item\n",
    "        result = analyze_my_data(item)\n",
    "        print(\"- \" + result[\"item\"] + \": \" + result[\"analysis\"])\n",
    "    \n",
    "    return \"Processed \" + str(total_items) + \" items\"\n",
    "\n",
    "# TODO: Test your functions\n",
    "sample_items = [\"Item 1\", \"Item 2\", \"Item 3\"]  # Replace with your data\n",
    "\n",
    "# Test individual function\n",
    "result = analyze_my_data(\"Sample Item\", \"test category\")\n",
    "print(\"Individual analysis:\", result)\n",
    "print()\n",
    "\n",
    "# Test collection function\n",
    "summary = process_my_collection(sample_items)\n",
    "print(\"\\nSummary:\", summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Advanced Data Processing\n",
    "Combine multiple functions for complex analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete analysis pipeline for cultural texts (simplified)\n",
    "def full_text_analysis(texts_with_info):\n",
    "    \"\"\"Complete analysis of multiple texts with metadata\"\"\" \n",
    "    \n",
    "    def analyze_single_text(text_info):\n",
    "        text = text_info[\"text\"]\n",
    "        title = text_info[\"title\"]\n",
    "        author = text_info[\"author\"]\n",
    "        \n",
    "        # Basic metrics\n",
    "        words = text.split()\n",
    "        word_count = len(words)\n",
    "        char_count = len(text)\n",
    "        sentence_count = text.count('.') + text.count('!') + text.count('?')\n",
    "        \n",
    "        # Calculate average word length\n",
    "        total_chars = 0\n",
    "        for word in words:\n",
    "            clean_word = word.strip(\".,!?;:\")\n",
    "            total_chars = total_chars + len(clean_word)\n",
    "        \n",
    "        if len(words) > 0:\n",
    "            avg_word_length = total_chars / len(words)\n",
    "        else:\n",
    "            avg_word_length = 0\n",
    "        \n",
    "        return {\n",
    "            \"title\": title,\n",
    "            \"author\": author,\n",
    "            \"word_count\": word_count,\n",
    "            \"sentence_count\": sentence_count,\n",
    "            \"avg_word_length\": round(avg_word_length, 2),\n",
    "            \"reading_time\": calculate_reading_time(word_count)\n",
    "        }\n",
    "    \n",
    "    # Process all texts\n",
    "    results = []\n",
    "    for text_info in texts_with_info:\n",
    "        analysis = analyze_single_text(text_info)\n",
    "        results.append(analysis)\n",
    "    \n",
    "    # Collection statistics\n",
    "    total_words = 0\n",
    "    for r in results:\n",
    "        total_words = total_words + r[\"word_count\"]\n",
    "    \n",
    "    if len(results) > 0:\n",
    "        avg_words = total_words / len(results)\n",
    "    else:\n",
    "        avg_words = 0\n",
    "    \n",
    "    # Display results\n",
    "    print(\"COMPLETE TEXT ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for result in results:\n",
    "        print(result[\"title\"] + \" by \" + result[\"author\"])\n",
    "        print(\"  Words: \" + str(result[\"word_count\"]) + \", Sentences: \" + str(result[\"sentence_count\"]))\n",
    "        print(\"  Avg word length: \" + str(result[\"avg_word_length\"]))\n",
    "        print(\"  Reading time: \" + str(result[\"reading_time\"]) + \" minutes\")\n",
    "        print()\n",
    "    \n",
    "    print(\"Collection Summary:\")\n",
    "    print(\"Total texts: \" + str(len(results)))\n",
    "    print(\"Average words per text: \" + str(round(avg_words, 0)))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Sample data for testing\n",
    "sample_texts = [\n",
    "    {\n",
    "        \"title\": \"Sample Poem\",\n",
    "        \"author\": \"Test Author\",\n",
    "        \"text\": \"This is a sample text for analysis. It has multiple sentences.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Another Text\",\n",
    "        \"author\": \"Another Author\", \n",
    "        \"text\": \"Here is another sample. We can compare them.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Run the complete analysis\n",
    "analysis_results = full_text_analysis(sample_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You practiced:\n",
    "- Writing functions with parameters and return values\n",
    "- Processing collections of cultural data\n",
    "- Comparing and analyzing multiple texts\n",
    "- Building complex analysis pipelines\n",
    "- Creating reusable code for research tasks\n",
    "\n",
    "**Next:** Review 05 will cover data ethics and collection methods.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
