{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/TCU-DCDA/WRIT20833-2025/blob/main/notebooks/exercises/Review_04_Functions_Advanced.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WRIT 20833 Review 04: Functions & Advanced Processing\n",
    "\n",
    "Practice writing functions and processing complex cultural datasets.\n",
    "\n",
    "**Make a copy:** File > Save a copy in Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Basic Functions\n",
    "Write simple functions for text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze a quote\n",
    "def analyze_quote(text, author=\"Unknown\"):\n",
    "    word_count = len(text.split())\n",
    "    char_count = len(text)\n",
    "    has_punctuation = any(p in text for p in \".,!?;:\")\n",
    "    \n",
    "    print(f\"Quote by {author}:\")\n",
    "    print(f\"Text: \\\"{text}\\\"\")\n",
    "    print(f\"Words: {word_count}, Characters: {char_count}\")\n",
    "    print(f\"Has punctuation: {has_punctuation}\")\n",
    "    \n",
    "    return word_count  # Return for further processing\n",
    "\n",
    "# Test the function\n",
    "analyze_quote(\"To be or not to be, that is the question\", \"Shakespeare\")\n",
    "print()\n",
    "analyze_quote(\"I have a dream\", \"Martin Luther King Jr.\")\n",
    "print()\n",
    "analyze_quote(\"Hello world\")  # No author provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Functions with Return Values\n",
    "Create functions that calculate and return results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate reading time\n",
    "def calculate_reading_time(word_count, words_per_minute=200):\n",
    "    \\\"\\\"\\\"Calculate reading time in minutes\\\"\\\"\\\" \n",
    "    minutes = word_count / words_per_minute\n",
    "    return round(minutes, 1)\n",
    "\n",
    "# Function to categorize text length\n",
    "def categorize_length(word_count):\n",
    "    if word_count < 10:\n",
    "        return \"Very Short\"\n",
    "    elif word_count < 100:\n",
    "        return \"Short\"\n",
    "    elif word_count < 1000:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Long\"\n",
    "\n",
    "# Function to analyze difficulty\n",
    "def analyze_difficulty(text):\n",
    "    words = text.split()\n",
    "    long_words = sum(1 for word in words if len(word) > 6)\n",
    "    percentage = (long_words / len(words)) * 100 if words else 0\n",
    "    \n",
    "    if percentage > 30:\n",
    "        return \"Difficult\"\n",
    "    elif percentage > 15:\n",
    "        return \"Moderate\"\n",
    "    else:\n",
    "        return \"Easy\"\n",
    "\n",
    "# Test with different texts\n",
    "texts = [\n",
    "    \"The cat sat on the mat\",\n",
    "    \"Comprehensive understanding requires methodical examination of multifaceted phenomena\",\n",
    "    \"We hold these truths to be self-evident, that all men are created equal\"\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    word_count = len(text.split())\n",
    "    reading_time = calculate_reading_time(word_count)\n",
    "    category = categorize_length(word_count)\n",
    "    difficulty = analyze_difficulty(text)\n",
    "    \n",
    "    print(f\"Text: \\\"{text}\\\"\")\n",
    "    print(f\"Length: {category} ({word_count} words)\")\n",
    "    print(f\"Reading time: {reading_time} minutes\")\n",
    "    print(f\"Difficulty: {difficulty}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Processing Lists of Data\n",
    "Use functions to process cultural datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a book collection\n",
    "def process_book_collection(books):\n",
    "    \\\"\\\"\\\"Analyze a collection of book dictionaries\\\"\\\"\\\" \n",
    "    total_books = len(books)\n",
    "    total_pages = sum(book[\"pages\"] for book in books)\n",
    "    avg_pages = total_pages / total_books if total_books > 0 else 0\n",
    "    \n",
    "    # Find oldest and newest books\n",
    "    oldest = min(books, key=lambda x: x[\"year\"])\n",
    "    newest = max(books, key=lambda x: x[\"year\"])\n",
    "    \n",
    "    print(f\"Collection Analysis:\")\n",
    "    print(f\"Total books: {total_books}\")\n",
    "    print(f\"Total pages: {total_pages:,}\")\n",
    "    print(f\"Average pages: {avg_pages:.0f}\")\n",
    "    print(f\"Oldest: {oldest['title']} ({oldest['year']})\")\n",
    "    print(f\"Newest: {newest['title']} ({newest['year']})\")\n",
    "    \n",
    "    return {\n",
    "        \"total_books\": total_books,\n",
    "        \"avg_pages\": avg_pages,\n",
    "        \"year_range\": newest[\"year\"] - oldest[\"year\"]\n",
    "    }\n",
    "\n",
    "# Sample book collection\n",
    "books = [\n",
    "    {\"title\": \"1984\", \"author\": \"George Orwell\", \"year\": 1949, \"pages\": 328},\n",
    "    {\"title\": \"Pride and Prejudice\", \"author\": \"Jane Austen\", \"year\": 1813, \"pages\": 432},\n",
    "    {\"title\": \"The Handmaid's Tale\", \"author\": \"Margaret Atwood\", \"year\": 1985, \"pages\": 311},\n",
    "    {\"title\": \"Beloved\", \"author\": \"Toni Morrison\", \"year\": 1987, \"pages\": 275}\n",
    "]\n",
    "\n",
    "stats = process_book_collection(books)\n",
    "print(f\"\\nYear span: {stats['year_range']} years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Text Comparison Functions\n",
    "Compare and analyze multiple texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find common words\n",
    "def find_common_words(text1, text2, min_length=4):\n",
    "    \\\"\\\"\\\"Find words that appear in both texts\\\"\\\"\\\" \n",
    "    words1 = set(word.lower().strip(\".,!?;:\") for word in text1.split() if len(word) >= min_length)\n",
    "    words2 = set(word.lower().strip(\".,!?;:\") for word in text2.split() if len(word) >= min_length)\n",
    "    \n",
    "    common = words1.intersection(words2)\n",
    "    return sorted(list(common))\n",
    "\n",
    "# Function to calculate similarity\n",
    "def calculate_similarity(text1, text2):\n",
    "    \\\"\\\"\\\"Calculate basic similarity between texts\\\"\\\"\\\" \n",
    "    words1 = set(text1.lower().split())\n",
    "    words2 = set(text2.lower().split())\n",
    "    \n",
    "    intersection = words1.intersection(words2)\n",
    "    union = words1.union(words2)\n",
    "    \n",
    "    similarity = len(intersection) / len(union) if union else 0\n",
    "    return round(similarity * 100, 1)\n",
    "\n",
    "# Function to compare writing styles\n",
    "def compare_styles(text1, text2, title1=\"Text 1\", title2=\"Text 2\"):\n",
    "    \\\"\\\"\\\"Compare basic style metrics\\\"\\\"\\\" \n",
    "    def get_stats(text):\n",
    "        words = text.split()\n",
    "        sentences = text.count('.') + text.count('!') + text.count('?')\n",
    "        avg_word_length = sum(len(word.strip(\".,!?;:\")) for word in words) / len(words) if words else 0\n",
    "        avg_sentence_length = len(words) / sentences if sentences > 0 else len(words)\n",
    "        \n",
    "        return {\n",
    "            \"words\": len(words),\n",
    "            \"sentences\": sentences,\n",
    "            \"avg_word_length\": round(avg_word_length, 1),\n",
    "            \"avg_sentence_length\": round(avg_sentence_length, 1)\n",
    "        }\n",
    "    \n",
    "    stats1 = get_stats(text1)\n",
    "    stats2 = get_stats(text2)\n",
    "    \n",
    "    print(f\"Style Comparison:\")\n",
    "    print(f\"{title1}: {stats1['words']} words, {stats1['sentences']} sentences\")\n",
    "    print(f\"  Avg word length: {stats1['avg_word_length']} chars\")\n",
    "    print(f\"  Avg sentence length: {stats1['avg_sentence_length']} words\")\n",
    "    print()\n",
    "    print(f\"{title2}: {stats2['words']} words, {stats2['sentences']} sentences\")\n",
    "    print(f\"  Avg word length: {stats2['avg_word_length']} chars\")\n",
    "    print(f\"  Avg sentence length: {stats2['avg_sentence_length']} words\")\n",
    "\n",
    "# Test with historical texts\n",
    "declaration = \"We hold these truths to be self-evident, that all men are created equal, that they are endowed by their Creator with certain unalienable Rights, that among these are Life, Liberty and the pursuit of Happiness.\"\n",
    "\n",
    "gettysburg = \"Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal.\"\n",
    "\n",
    "common_words = find_common_words(declaration, gettysburg)\n",
    "similarity = calculate_similarity(declaration, gettysburg)\n",
    "\n",
    "print(f\"Common words: {common_words}\")\n",
    "print(f\"Similarity: {similarity}%\")\n",
    "print()\n",
    "compare_styles(declaration, gettysburg, \"Declaration\", \"Gettysburg Address\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Your Turn - Custom Functions\n",
    "Write functions for your research interests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a function relevant to your field of study\n",
    "# Examples: analyze_poem(), categorize_artwork(), process_historical_event()\n",
    "\n",
    "def analyze_my_data(item, category=\"general\"):\n",
    "    \\\"\\\"\\\"Customize this function for your research needs\\\"\\\"\\\" \n",
    "    \n",
    "    # TODO: Add your analysis logic here\n",
    "    # Consider: What would you want to measure or categorize?\n",
    "    \n",
    "    result = {\n",
    "        \"item\": item,\n",
    "        \"category\": category,\n",
    "        \"analysis\": \"Complete your analysis here\"\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "# TODO: Write a function that processes a list of your items\n",
    "def process_my_collection(items):\n",
    "    \\\"\\\"\\\"Process a collection of items from your field\\\"\\\"\\\" \n",
    "    \n",
    "    # TODO: Implement collection-level analysis\n",
    "    total_items = len(items)\n",
    "    \n",
    "    print(f\"Processing {total_items} items...\")\n",
    "    \n",
    "    for item in items:\n",
    "        # Process each item\n",
    "        result = analyze_my_data(item)\n",
    "        print(f\"- {result['item']}: {result['analysis']}\")\n",
    "    \n",
    "    return f\"Processed {total_items} items\"\n",
    "\n",
    "# TODO: Test your functions\n",
    "sample_items = [\"Item 1\", \"Item 2\", \"Item 3\"]  # Replace with your data\n",
    "\n",
    "# Test individual function\n",
    "result = analyze_my_data(\"Sample Item\", \"test category\")\n",
    "print(\"Individual analysis:\", result)\n",
    "print()\n",
    "\n",
    "# Test collection function\n",
    "summary = process_my_collection(sample_items)\n",
    "print(\"\\nSummary:\", summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Advanced Data Processing\n",
    "Combine multiple functions for complex analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete analysis pipeline for cultural texts\n",
    "def full_text_analysis(texts_with_info):\n",
    "    \\\"\\\"\\\"Complete analysis of multiple texts with metadata\\\"\\\"\\\" \n",
    "    \n",
    "    def analyze_single_text(text_info):\n",
    "        text = text_info[\"text\"]\n",
    "        title = text_info[\"title\"]\n",
    "        author = text_info[\"author\"]\n",
    "        \n",
    "        # Basic metrics\n",
    "        words = text.split()\n",
    "        word_count = len(words)\n",
    "        char_count = len(text)\n",
    "        sentence_count = text.count('.') + text.count('!') + text.count('?')\n",
    "        \n",
    "        # Advanced metrics\n",
    "        avg_word_length = sum(len(word.strip(\".,!?;:\")) for word in words) / len(words) if words else 0\n",
    "        unique_words = len(set(word.lower().strip(\".,!?;:\") for word in words))\n",
    "        lexical_diversity = unique_words / word_count if word_count > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            \"title\": title,\n",
    "            \"author\": author,\n",
    "            \"word_count\": word_count,\n",
    "            \"sentence_count\": sentence_count,\n",
    "            \"avg_word_length\": round(avg_word_length, 2),\n",
    "            \"lexical_diversity\": round(lexical_diversity, 3),\n",
    "            \"reading_time\": calculate_reading_time(word_count)\n",
    "        }\n",
    "    \n",
    "    # Process all texts\n",
    "    results = []\n",
    "    for text_info in texts_with_info:\n",
    "        analysis = analyze_single_text(text_info)\n",
    "        results.append(analysis)\n",
    "    \n",
    "    # Collection statistics\n",
    "    total_words = sum(r[\"word_count\"] for r in results)\n",
    "    avg_words = total_words / len(results) if results else 0\n",
    "    most_complex = max(results, key=lambda x: x[\"avg_word_length\"])\n",
    "    most_diverse = max(results, key=lambda x: x[\"lexical_diversity\"])\n",
    "    \n",
    "    # Display results\n",
    "    print(\"COMPLETE TEXT ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for result in results:\n",
    "        print(f\"{result['title']} by {result['author']}\")\n",
    "        print(f\"  Words: {result['word_count']}, Sentences: {result['sentence_count']}\")\n",
    "        print(f\"  Avg word length: {result['avg_word_length']}\")\n",
    "        print(f\"  Lexical diversity: {result['lexical_diversity']}\")\n",
    "        print(f\"  Reading time: {result['reading_time']} minutes\")\n",
    "        print()\n",
    "    \n",
    "    print(f\"COLLECTION SUMMARY:\")\n",
    "    print(f\"Total texts: {len(results)}\")\n",
    "    print(f\"Total words: {total_words:,}\")\n",
    "    print(f\"Average words per text: {avg_words:.0f}\")\n",
    "    print(f\"Most complex language: {most_complex['title']}\")\n",
    "    print(f\"Most diverse vocabulary: {most_diverse['title']}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Sample texts for analysis\n",
    "sample_texts = [\n",
    "    {\n",
    "        \"title\": \"Hamlet Soliloquy\",\n",
    "        \"author\": \"Shakespeare\",\n",
    "        \"text\": \"To be, or not to be, that is the question: Whether 'tis nobler in the mind to suffer the slings and arrows of outrageous fortune, or to take arms against a sea of troubles and by opposing end them.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"I Have a Dream\",\n",
    "        \"author\": \"Martin Luther King Jr.\",\n",
    "        \"text\": \"I have a dream that one day this nation will rise up and live out the true meaning of its creed: We hold these truths to be self-evident, that all men are created equal.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "analysis_results = full_text_analysis(sample_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You practiced:\n",
    "- Writing functions with parameters and return values\n",
    "- Processing collections of cultural data\n",
    "- Comparing and analyzing multiple texts\n",
    "- Building complex analysis pipelines\n",
    "- Creating reusable code for research tasks\n",
    "\n",
    "**Next:** Review 05 will cover data ethics and collection methods.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
