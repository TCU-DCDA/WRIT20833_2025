{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/TCU-DCDA/WRIT20833-2025/blob/main/notebooks/exercises/Review_05_Data_Ethics_Collection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WRIT 20833 Review 05: Data Ethics & Collection Methods\n",
    "\n",
    "**Student Name:** ___________________  \n",
    "**Date:** ___________________  \n",
    "\n",
    "Explore ethical data collection and responsible research practices.\n",
    "\n",
    "**Make a copy:** File > Save a copy in Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Understanding Data Sources\n",
    "Analyze different types of cultural data and their origins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different types of cultural data sources\n",
    "data_sources = {\n",
    "    \"social_media\": {\n",
    "        \"type\": \"User-generated content\",\n",
    "        \"examples\": [\"Twitter posts\", \"Instagram captions\", \"TikTok comments\"],\n",
    "        \"ethical_concerns\": [\"Privacy\", \"Consent\", \"Context collapse\"],\n",
    "        \"access_method\": \"APIs or scraping\"\n",
    "    },\n",
    "    \"historical_archives\": {\n",
    "        \"type\": \"Digitized materials\",\n",
    "        \"examples\": [\"Letters\", \"Newspapers\", \"Government records\"],\n",
    "        \"ethical_concerns\": [\"Copyright\", \"Representation\", \"Missing voices\"],\n",
    "        \"access_method\": \"Digital libraries\"\n",
    "    },\n",
    "    \"interviews\": {\n",
    "        \"type\": \"Collected testimony\",\n",
    "        \"examples\": [\"Oral histories\", \"Surveys\", \"Focus groups\"],\n",
    "        \"ethical_concerns\": [\"Informed consent\", \"Anonymity\", \"Power dynamics\"],\n",
    "        \"access_method\": \"Direct collection\"\n",
    "    },\n",
    "    \"public_records\": {\n",
    "        \"type\": \"Official documents\",\n",
    "        \"examples\": [\"Census data\", \"Court records\", \"Legislative proceedings\"],\n",
    "        \"ethical_concerns\": [\"Individual privacy\", \"Contextual accuracy\"],\n",
    "        \"access_method\": \"Government databases\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Analyze each source type\n",
    "print(\"CULTURAL DATA SOURCE ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for source_name, details in data_sources.items():\n",
    "    print(f\"\\n{source_name.replace('_', ' ').title()}:\")\n",
    "    print(f\"  Type: {details['type']}\")\n",
    "    print(f\"  Examples: {', '.join(details['examples'])}\")\n",
    "    print(f\"  Access: {details['access_method']}\")\n",
    "    print(f\"  Key ethical concerns: {', '.join(details['ethical_concerns'])}\")\n",
    "\n",
    "# Count ethical concerns\n",
    "all_concerns = []\n",
    "for details in data_sources.values():\n",
    "    all_concerns.extend(details['ethical_concerns'])\n",
    "\n",
    "print(f\"\\nTotal unique ethical concerns identified: {len(set(all_concerns))}\")\n",
    "print(f\"Most common concerns: {set(all_concerns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Evaluating Data Collection Methods\n",
    "Practice assessing the ethics of different collection approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate data collection ethics\n",
    "def evaluate_collection_method(method_name, description, consent_level, privacy_impact, potential_harm):\n",
    "    \\\"\\\"\\\"Evaluate the ethical implications of a data collection method\\\"\\\"\\\" \n",
    "    \n",
    "    # Calculate ethics score (higher = more ethical)\n",
    "    consent_score = {\"explicit\": 3, \"implied\": 2, \"none\": 0}[consent_level]\n",
    "    privacy_score = {\"low\": 3, \"medium\": 2, \"high\": 0}[privacy_impact]  # Lower impact = higher score\n",
    "    harm_score = {\"minimal\": 3, \"moderate\": 2, \"significant\": 0}[potential_harm]\n",
    "    \n",
    "    total_score = consent_score + privacy_score + harm_score\n",
    "    max_score = 9\n",
    "    \n",
    "    # Determine ethics rating\n",
    "    if total_score >= 8:\n",
    "        rating = \"Highly Ethical\"\n",
    "    elif total_score >= 6:\n",
    "        rating = \"Moderately Ethical\"\n",
    "    elif total_score >= 4:\n",
    "        rating = \"Ethically Questionable\"\n",
    "    else:\n",
    "        rating = \"Ethically Problematic\"\n",
    "    \n",
    "    print(f\"Method: {method_name}\")\n",
    "    print(f\"Description: {description}\")\n",
    "    print(f\"Consent Level: {consent_level}\")\n",
    "    print(f\"Privacy Impact: {privacy_impact}\")\n",
    "    print(f\"Potential Harm: {potential_harm}\")\n",
    "    print(f\"Ethics Score: {total_score}/{max_score}\")\n",
    "    print(f\"Rating: {rating}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    return {\"method\": method_name, \"score\": total_score, \"rating\": rating}\n",
    "\n",
    "# Evaluate different collection methods\n",
    "methods = [\n",
    "    {\n",
    "        \"name\": \"Voluntary Survey\",\n",
    "        \"description\": \"Participants voluntarily complete a survey about their cultural practices\",\n",
    "        \"consent\": \"explicit\",\n",
    "        \"privacy\": \"low\",\n",
    "        \"harm\": \"minimal\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Public Social Media Scraping\",\n",
    "        \"description\": \"Collecting public posts from social media without notification\",\n",
    "        \"consent\": \"none\",\n",
    "        \"privacy\": \"medium\",\n",
    "        \"harm\": \"moderate\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Historical Archive Digitization\",\n",
    "        \"description\": \"Digitizing letters and documents from historical archives\",\n",
    "        \"consent\": \"implied\",\n",
    "        \"privacy\": \"low\",\n",
    "        \"harm\": \"minimal\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Covert Observation\",\n",
    "        \"description\": \"Secretly recording conversations in public spaces\",\n",
    "        \"consent\": \"none\",\n",
    "        \"privacy\": \"high\",\n",
    "        \"harm\": \"significant\"\n",
    "    }\n",
    "]\n",
    "\n",
    "results = []\n",
    "for method in methods:\n",
    "    result = evaluate_collection_method(\n",
    "        method[\"name\"], \n",
    "        method[\"description\"], \n",
    "        method[\"consent\"], \n",
    "        method[\"privacy\"], \n",
    "        method[\"harm\"]\n",
    "    )\n",
    "    results.append(result)\n",
    "\n",
    "# Summary of results\n",
    "print(\"\\nSUMMARY OF ETHICAL EVALUATIONS:\")\n",
    "for result in sorted(results, key=lambda x: x[\"score\"], reverse=True):\n",
    "    print(f\"{result['method']}: {result['rating']} (Score: {result['score']}/9)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Consent and Privacy Analysis\n",
    "Examine consent models and privacy considerations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different models of consent\n",
    "consent_models = {\n",
    "    \"opt_in\": {\n",
    "        \"description\": \"Users must actively choose to participate\",\n",
    "        \"advantages\": [\"Clear consent\", \"Informed participation\", \"Higher ethical standard\"],\n",
    "        \"disadvantages\": [\"Lower participation rates\", \"Selection bias\", \"More complex logistics\"],\n",
    "        \"best_for\": [\"Sensitive topics\", \"Vulnerable populations\", \"Long-term studies\"]\n",
    "    },\n",
    "    \"opt_out\": {\n",
    "        \"description\": \"Users are included by default but can choose to leave\",\n",
    "        \"advantages\": [\"Higher participation\", \"More representative samples\", \"Easier logistics\"],\n",
    "        \"disadvantages\": [\"Questionable consent\", \"May include unwilling participants\", \"Ethical concerns\"],\n",
    "        \"best_for\": [\"Low-risk research\", \"Public data analysis\", \"Administrative studies\"]\n",
    "    },\n",
    "    \"public_domain\": {\n",
    "        \"description\": \"Data is already publicly available\",\n",
    "        \"advantages\": [\"No consent needed\", \"Large datasets\", \"Historical continuity\"],\n",
    "        \"disadvantages\": [\"Context collapse\", \"Unintended use\", \"Privacy erosion\"],\n",
    "        \"best_for\": [\"Historical analysis\", \"Public discourse studies\", \"Large-scale patterns\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to analyze consent appropriateness\n",
    "def analyze_consent_model(research_context, data_sensitivity, population_vulnerability):\n",
    "    \\\"\\\"\\\"Recommend appropriate consent model based on research parameters\\\"\\\"\\\" \n",
    "    \n",
    "    # Decision logic\n",
    "    if data_sensitivity == \"high\" or population_vulnerability == \"high\":\n",
    "        recommendation = \"opt_in\"\n",
    "        reason = \"High sensitivity or vulnerable population requires explicit consent\"\n",
    "    elif data_sensitivity == \"medium\" and population_vulnerability == \"medium\":\n",
    "        recommendation = \"opt_in\"  # Err on side of caution\n",
    "        reason = \"Moderate risk factors suggest need for explicit consent\"\n",
    "    elif research_context == \"historical\" and data_sensitivity == \"low\":\n",
    "        recommendation = \"public_domain\"\n",
    "        reason = \"Historical public data with low sensitivity\"\n",
    "    else:\n",
    "        recommendation = \"opt_out\"\n",
    "        reason = \"Low risk factors allow for opt-out model with safeguards\"\n",
    "    \n",
    "    return recommendation, reason\n",
    "\n",
    "# Test different research scenarios\n",
    "scenarios = [\n",
    "    {\"context\": \"social_media\", \"sensitivity\": \"medium\", \"vulnerability\": \"low\", \"description\": \"Analyzing public tweets about movies\"},\n",
    "    {\"context\": \"interviews\", \"sensitivity\": \"high\", \"vulnerability\": \"high\", \"description\": \"Interviewing trauma survivors\"},\n",
    "    {\"context\": \"historical\", \"sensitivity\": \"low\", \"vulnerability\": \"low\", \"description\": \"Analyzing 19th century newspapers\"},\n",
    "    {\"context\": \"survey\", \"sensitivity\": \"medium\", \"vulnerability\": \"medium\", \"description\": \"Student academic experiences\"}\n",
    "]\n",
    "\n",
    "print(\"CONSENT MODEL RECOMMENDATIONS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for scenario in scenarios:\n",
    "    recommendation, reason = analyze_consent_model(\n",
    "        scenario[\"context\"], \n",
    "        scenario[\"sensitivity\"], \n",
    "        scenario[\"vulnerability\"]\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nScenario: {scenario['description']}\")\n",
    "    print(f\"Context: {scenario['context']} | Sensitivity: {scenario['sensitivity']} | Vulnerability: {scenario['vulnerability']}\")\n",
    "    print(f\"Recommended Model: {recommendation.replace('_', '-').title()}\")\n",
    "    print(f\"Reason: {reason}\")\n",
    "    \n",
    "    # Show model details\n",
    "    model_info = consent_models[recommendation]\n",
    "    print(f\"Model Description: {model_info['description']}\")\n",
    "    print(f\"Key Advantages: {', '.join(model_info['advantages'][:2])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Bias and Representation\n",
    "Identify potential biases in cultural datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze dataset representation\n",
    "def analyze_dataset_bias(dataset_name, collection_method, source_demographics, missing_groups):\n",
    "    \\\"\\\"\\\"Analyze potential biases in cultural datasets\\\"\\\"\\\" \n",
    "    \n",
    "    # Identify bias types\n",
    "    bias_types = []\n",
    "    \n",
    "    if \"online\" in collection_method.lower():\n",
    "        bias_types.append(\"Digital divide bias\")\n",
    "    \n",
    "    if \"english\" in source_demographics.lower():\n",
    "        bias_types.append(\"Language bias\")\n",
    "    \n",
    "    if \"urban\" in source_demographics.lower():\n",
    "        bias_types.append(\"Geographic bias\")\n",
    "    \n",
    "    if \"college\" in source_demographics.lower() or \"university\" in source_demographics.lower():\n",
    "        bias_types.append(\"Educational bias\")\n",
    "    \n",
    "    if missing_groups:\n",
    "        bias_types.append(\"Systematic exclusion bias\")\n",
    "    \n",
    "    # Calculate bias risk\n",
    "    risk_level = \"Low\" if len(bias_types) <= 1 else \"Medium\" if len(bias_types) <= 3 else \"High\"\n",
    "    \n",
    "    print(f\"Dataset: {dataset_name}\")\n",
    "    print(f\"Collection Method: {collection_method}\")\n",
    "    print(f\"Source Demographics: {source_demographics}\")\n",
    "    print(f\"Missing Groups: {missing_groups if missing_groups else 'None identified'}\")\n",
    "    print(f\"Identified Bias Types: {bias_types if bias_types else ['None identified']}\")\n",
    "    print(f\"Bias Risk Level: {risk_level}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    return {\"dataset\": dataset_name, \"bias_count\": len(bias_types), \"risk\": risk_level}\n",
    "\n",
    "# Sample datasets to analyze\n",
    "datasets = [\n",
    "    {\n",
    "        \"name\": \"Twitter Literature Discussions\",\n",
    "        \"method\": \"Online social media scraping\",\n",
    "        \"demographics\": \"Primarily English-speaking, urban, college-educated users\",\n",
    "        \"missing\": \"Rural communities, non-English speakers, older adults\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Historical Newspaper Archive\",\n",
    "        \"method\": \"Digital archive access\",\n",
    "        \"demographics\": \"Major city newspapers, English language, 1900-2000\",\n",
    "        \"missing\": \"Community papers, minority-owned publications, non-English press\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Community Survey on Cultural Practices\",\n",
    "        \"method\": \"Door-to-door interviews in multiple languages\",\n",
    "        \"demographics\": \"Representative sample across age, income, ethnicity, geography\",\n",
    "        \"missing\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"University Student Blogs\",\n",
    "        \"method\": \"Web scraping of student publications\",\n",
    "        \"demographics\": \"University students, primarily traditional college age, English\",\n",
    "        \"missing\": \"Non-students, working adults, community college perspectives\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"DATASET BIAS ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "results = []\n",
    "for dataset in datasets:\n",
    "    result = analyze_dataset_bias(\n",
    "        dataset[\"name\"],\n",
    "        dataset[\"method\"],\n",
    "        dataset[\"demographics\"],\n",
    "        dataset[\"missing\"]\n",
    "    )\n",
    "    results.append(result)\n",
    "\n",
    "# Summary statistics\n",
    "high_risk = sum(1 for r in results if r[\"risk\"] == \"High\")\n",
    "medium_risk = sum(1 for r in results if r[\"risk\"] == \"Medium\")\n",
    "low_risk = sum(1 for r in results if r[\"risk\"] == \"Low\")\n",
    "\n",
    "print(f\"\\nBIAS RISK SUMMARY:\")\n",
    "print(f\"High Risk: {high_risk} datasets\")\n",
    "print(f\"Medium Risk: {medium_risk} datasets\")\n",
    "print(f\"Low Risk: {low_risk} datasets\")\n",
    "print(f\"\\nRecommendation: Focus mitigation efforts on {high_risk + medium_risk} datasets with elevated bias risk.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Ethical Decision Framework\n",
    "Practice making ethical decisions about data use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ethical decision-making framework\n",
    "def ethical_decision_framework(research_question, data_source, potential_benefits, potential_harms, alternatives):\n",
    "    \\\"\\\"\\\"Guide ethical decision-making about data use\\\"\\\"\\\" \n",
    "    \n",
    "    print(f\"ETHICAL DECISION FRAMEWORK\")\n",
    "    print(f\"Research Question: {research_question}\")\n",
    "    print(f\"Proposed Data Source: {data_source}\")\n",
    "    print()\n",
    "    \n",
    "    # Step 1: Benefits analysis\n",
    "    print(\"STEP 1: Benefits Analysis\")\n",
    "    for i, benefit in enumerate(potential_benefits, 1):\n",
    "        print(f\"  {i}. {benefit}\")\n",
    "    \n",
    "    # Step 2: Harm assessment\n",
    "    print(\"\\nSTEP 2: Potential Harms\")\n",
    "    for i, harm in enumerate(potential_harms, 1):\n",
    "        print(f\"  {i}. {harm}\")\n",
    "    \n",
    "    # Step 3: Alternative approaches\n",
    "    print(\"\\nSTEP 3: Alternative Approaches\")\n",
    "    for i, alt in enumerate(alternatives, 1):\n",
    "        print(f\"  {i}. {alt}\")\n",
    "    \n",
    "    # Step 4: Decision guidance\n",
    "    print(\"\\nSTEP 4: Decision Guidance Questions\")\n",
    "    questions = [\n",
    "        \"Do the benefits clearly outweigh the harms?\",\n",
    "        \"Have you minimized potential harms through design choices?\",\n",
    "        \"Are there less harmful alternatives that could answer your question?\",\n",
    "        \"Would the people whose data you're using consent if they knew?\",\n",
    "        \"Does your research serve the interests of the communities studied?\"\n",
    "    ]\n",
    "    \n",
    "    for i, question in enumerate(questions, 1):\n",
    "        print(f\"  {i}. {question}\")\n",
    "    \n",
    "    # Simple recommendation logic\n",
    "    harm_count = len(potential_harms)\n",
    "    alt_count = len(alternatives)\n",
    "    \n",
    "    if harm_count <= 1 and alt_count >= 2:\n",
    "        recommendation = \"Consider alternatives first\"\n",
    "    elif harm_count >= 3:\n",
    "        recommendation = \"High risk - requires strong justification\"\n",
    "    else:\n",
    "        recommendation = \"Proceed with careful safeguards\"\n",
    "    \n",
    "    print(f\"\\nINITIAL RECOMMENDATION: {recommendation}\")\n",
    "    print(f\"\\nNext Steps: Consult with IRB, advisors, and community stakeholders.\")\n",
    "    \n",
    "    return recommendation\n",
    "\n",
    "# Test case: Social media research\n",
    "recommendation = ethical_decision_framework(\n",
    "    research_question=\"How do young people discuss mental health on social media?\",\n",
    "    data_source=\"Public Twitter posts containing mental health keywords\",\n",
    "    potential_benefits=[\n",
    "        \"Better understanding of youth mental health discourse\",\n",
    "        \"Inform mental health support programs\",\n",
    "        \"Identify patterns that could help early intervention\"\n",
    "    ],\n",
    "    potential_harms=[\n",
    "        \"Privacy violation for vulnerable individuals\",\n",
    "        \"Risk of re-identification despite public posts\", \n",
    "        \"Potential stigmatization of communities\",\n",
    "        \"Taking posts out of original context\"\n",
    "    ],\n",
    "    alternatives=[\n",
    "        \"Partner with mental health organizations for voluntary participation\",\n",
    "        \"Use synthetic data based on patterns rather than actual posts\",\n",
    "        \"Focus on aggregate trends rather than individual posts\",\n",
    "        \"Conduct interviews with explicit informed consent\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Your Research Ethics Plan\n",
    "Develop an ethics plan for your own research interests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your research area and data needs\n",
    "your_research = {\n",
    "    \"field\": \"Your field of study (e.g., literature, history, art, etc.)\",\n",
    "    \"question\": \"Your specific research question\",\n",
    "    \"data_needed\": \"What kind of data would help answer your question?\",\n",
    "    \"population\": \"Who/what would you be studying?\",\n",
    "    \"timeframe\": \"Historical period or contemporary?\"\n",
    "}\n",
    "\n",
    "# TODO: Identify potential data sources for your research\n",
    "potential_sources = [\n",
    "    # Add your potential data sources here\n",
    "    # Examples: \"Digital archives\", \"Social media posts\", \"Interviews\", etc.\n",
    "]\n",
    "\n",
    "# TODO: Consider ethical implications\n",
    "ethical_considerations = {\n",
    "    \"consent_challenges\": [],  # What makes consent difficult in your field?\n",
    "    \"privacy_risks\": [],       # What privacy risks exist?\n",
    "    \"representation_gaps\": [], # Who might be excluded from your data?\n",
    "    \"potential_harms\": [],     # How could your research cause harm?\n",
    "    \"community_benefits\": []   # How does your research serve the communities studied?\n",
    "}\n",
    "\n",
    "# TODO: Develop mitigation strategies\n",
    "mitigation_strategies = [\n",
    "    # Add your strategies for addressing ethical concerns\n",
    "    # Examples: \"Partner with community organizations\", \"Use anonymization\", etc.\n",
    "]\n",
    "\n",
    "# Function to display your ethics plan\n",
    "def display_ethics_plan(research_info, sources, considerations, mitigations):\n",
    "    print(\"YOUR RESEARCH ETHICS PLAN\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    print(\"RESEARCH OVERVIEW:\")\n",
    "    for key, value in research_info.items():\n",
    "        print(f\"  {key.replace('_', ' ').title()}: {value}\")\n",
    "    \n",
    "    print(f\"\\nPOTENTIAL DATA SOURCES:\")\n",
    "    for i, source in enumerate(sources, 1):\n",
    "        print(f\"  {i}. {source}\")\n",
    "    \n",
    "    print(f\"\\nETHICAL CONSIDERATIONS:\")\n",
    "    for category, items in considerations.items():\n",
    "        if items:  # Only show categories that have items\n",
    "            print(f\"  {category.replace('_', ' ').title()}:\")\n",
    "            for item in items:\n",
    "                print(f\"    - {item}\")\n",
    "    \n",
    "    print(f\"\\nMITIGATION STRATEGIES:\")\n",
    "    for i, strategy in enumerate(mitigations, 1):\n",
    "        print(f\"  {i}. {strategy}\")\n",
    "    \n",
    "    print(f\"\\nNEXT STEPS:\")\n",
    "    print(f\"  1. Consult with faculty advisor about ethical considerations\")\n",
    "    print(f\"  2. Research IRB requirements for your institution\")\n",
    "    print(f\"  3. Identify relevant community stakeholders to consult\")\n",
    "    print(f\"  4. Develop detailed data management and privacy protocols\")\n",
    "\n",
    "# Display your plan (will show placeholder text until you customize it)\n",
    "display_ethics_plan(your_research, potential_sources, ethical_considerations, mitigation_strategies)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"REFLECTION: Customize the variables above with your specific research interests and ethical considerations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You explored:\n",
    "- Different types of cultural data sources and their ethical implications\n",
    "- Methods for evaluating data collection approaches\n",
    "- Consent models and privacy considerations\n",
    "- Identifying and addressing bias in datasets\n",
    "- Frameworks for ethical decision-making\n",
    "- Developing ethics plans for your own research\n",
    "\n",
    "**Key Principles:**\n",
    "- Prioritize consent and transparency\n",
    "- Consider potential harms and benefits\n",
    "- Address representation and bias\n",
    "- Serve the communities you study\n",
    "- Consult with stakeholders and ethics boards\n",
    "\n",
    "**Next:** Review 06 will cover Pandas for data analysis.\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
