{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/TCU-DCDA/WRIT20833-2025/blob/main/notebooks/exercises/Review_09_Integration_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WRIT 20833 Review 09: Integration  \n",
    "\n",
    "\n",
    "\n",
    "Integrate all Python skills to date.\n",
    "\n",
    "**Make a copy:** File > Save a copy in Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview: Cultural Data Analysis Portfolio\n",
    "\n",
    "Create a complete cultural data analysis project that demonstrates mastery of:\n",
    "- Data collection and ethics (Review 05)\n",
    "- Data processing with Pandas (Review 06) \n",
    "- Text analysis and sentiment (Review 07)\n",
    "- Data visualization (Review 08)\n",
    "- All foundational Python skills (Reviews 01-04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Project Setup and Data Collection\n",
    "Choose your cultural domain and set up your analysis framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries (only what was covered in CodeAlongs)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# VADER for sentiment analysis (from CodeAlongs)\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "print(\"VADER sentiment analysis ready\")\n",
    "\n",
    "# PROJECT CHOICE: Select your cultural domain\n",
    "# Options: books, movies, music, art, theater, digital_culture, etc.\n",
    "\n",
    "project_domain = \"books\"  # TODO: Change to your chosen domain\n",
    "\n",
    "print(\"CULTURAL ANALYSIS PROJECT: \" + project_domain.upper())\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Sample dataset - replace with your own data!\n",
    "cultural_data = {\n",
    "    'title': ['1984', 'Pride and Prejudice', 'The Handmaid\\'s Tale', 'Beloved', 'The Great Gatsby'],\n",
    "    'creator': ['George Orwell', 'Jane Austen', 'Margaret Atwood', 'Toni Morrison', 'F. Scott Fitzgerald'],\n",
    "    'year': [1949, 1813, 1985, 1987, 1925],\n",
    "    'genre': ['Dystopian', 'Romance', 'Dystopian', 'Historical Fiction', 'Modernist'],\n",
    "    'description': [\n",
    "        'A totalitarian society under constant surveillance where independent thinking is a crime.',\n",
    "        'A witty exploration of love, marriage, and social class in Regency England.',\n",
    "        'A dystopian tale of women\\'s rights and reproductive freedom in a theocratic society.',\n",
    "        'A powerful story of slavery, trauma, and the lasting effects of historical injustice.',\n",
    "        'The decline of the American Dream through the eyes of the mysterious Jay Gatsby.'\n",
    "    ],\n",
    "    'themes': [\n",
    "        'surveillance, totalitarianism, truth, freedom, oppression',\n",
    "        'love, marriage, social class, wit, independence', \n",
    "        'feminism, reproductive rights, religious extremism, resistance',\n",
    "        'slavery, trauma, memory, motherhood, healing',\n",
    "        'American Dream, wealth, love, illusion, moral decay'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(cultural_data)\n",
    "print(\"Dataset loaded: \" + str(len(df)) + \" items\")\n",
    "print()\n",
    "print(\"First few items:\")\n",
    "print(df[['title', 'creator', 'year', 'genre']].head())\n",
    "\n",
    "# Data validation and cleaning\n",
    "print()\n",
    "print(\"DATA QUALITY CHECK:\")\n",
    "print(\"Missing values: \" + str(df.isnull().sum().sum()))\n",
    "print(\"Duplicates: \" + str(df.duplicated().sum()))\n",
    "print(\"Year range: \" + str(df['year'].min()) + \" - \" + str(df['year'].max()))\n",
    "print(\"Unique creators: \" + str(df['creator'].nunique()))\n",
    "print(\"Genres: \" + str(list(df['genre'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Text Analysis and Theme Extraction\n",
    "Analyze textual content using string methods and sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text processing functions (using patterns from CodeAlongs)\n",
    "\n",
    "# Simple text cleaning function\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean text by removing common punctuation\"\"\"\n",
    "    text = str(text).lower()\n",
    "    # Remove common punctuation\n",
    "    text = text.replace(',', '').replace('.', '').replace('!', '').replace('?', '').replace(';', '').replace(':', '')\n",
    "    return text.strip()\n",
    "\n",
    "# Sentiment analysis function (using VADER from CodeAlongs)\n",
    "def analyze_sentiment(text):\n",
    "    \"\"\"Analyze sentiment of text descriptions using VADER\"\"\"\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    return scores['compound']\n",
    "\n",
    "# Theme extraction function (using basic string methods from CodeAlongs)\n",
    "def extract_themes(themes_string):\n",
    "    \"\"\"Convert theme string to list\"\"\"\n",
    "    if pd.isna(themes_string):\n",
    "        return []\n",
    "    themes = themes_string.split(',')\n",
    "    clean_themes = []\n",
    "    for theme in themes:\n",
    "        clean_themes.append(theme.strip())\n",
    "    return clean_themes\n",
    "\n",
    "# Apply text analysis\n",
    "print(\"TEXT ANALYSIS RESULTS:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Clean text data\n",
    "df['description_clean'] = df['description'].apply(clean_text)\n",
    "\n",
    "# Sentiment analysis\n",
    "df['sentiment_score'] = df['description'].apply(analyze_sentiment)\n",
    "\n",
    "# Categorize sentiment\n",
    "sentiment_categories = []\n",
    "for score in df['sentiment_score']:\n",
    "    if score > 0.1:\n",
    "        sentiment_categories.append('Positive')\n",
    "    elif score < -0.1:\n",
    "        sentiment_categories.append('Negative')\n",
    "    else:\n",
    "        sentiment_categories.append('Neutral')\n",
    "\n",
    "df['sentiment_category'] = sentiment_categories\n",
    "\n",
    "# Theme extraction\n",
    "df['theme_list'] = df['themes'].apply(extract_themes)\n",
    "\n",
    "# Count themes\n",
    "theme_counts = []\n",
    "for theme_list in df['theme_list']:\n",
    "    theme_counts.append(len(theme_list))\n",
    "df['theme_count'] = theme_counts\n",
    "\n",
    "# Display results\n",
    "print(\"Sentiment Analysis Results:\")\n",
    "for idx, row in df.iterrows():\n",
    "    title_short = row['title'][:25]\n",
    "    if len(row['title']) > 25:\n",
    "        title_short = title_short + \"...\"\n",
    "    print(title_short + \" | Sentiment: \" + row['sentiment_category'] + \" (\" + str(round(row['sentiment_score'], 2)) + \")\")\n",
    "\n",
    "print()\n",
    "print(\"Overall sentiment distribution:\")\n",
    "sentiment_counts = df['sentiment_category'].value_counts()\n",
    "for category in sentiment_counts.index:\n",
    "    count = sentiment_counts[category]\n",
    "    percentage = count / len(df) * 100\n",
    "    print(category + \": \" + str(count) + \" items (\" + str(round(percentage, 1)) + \"%)\")\n",
    "\n",
    "# Theme frequency analysis (simplified)\n",
    "all_themes = []\n",
    "for theme_list in df['theme_list']:\n",
    "    for theme in theme_list:\n",
    "        all_themes.append(theme)\n",
    "\n",
    "# Count themes manually\n",
    "theme_frequency = {}\n",
    "for theme in all_themes:\n",
    "    if theme in theme_frequency:\n",
    "        theme_frequency[theme] = theme_frequency[theme] + 1\n",
    "    else:\n",
    "        theme_frequency[theme] = 1\n",
    "\n",
    "print()\n",
    "print(\"Most common themes:\")\n",
    "# Get top 5 themes\n",
    "sorted_themes = sorted(theme_frequency.items(), key=lambda x: x[1], reverse=True)\n",
    "for i in range(min(5, len(sorted_themes))):\n",
    "    theme, count = sorted_themes[i]\n",
    "    print(theme + \": \" + str(count) + \" occurrences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Statistical Analysis and Patterns\n",
    "Use Pandas for data analysis and pattern discovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical analysis (using pandas patterns from CodeAlongs)\n",
    "print(\"STATISTICAL ANALYSIS:\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Basic statistics\n",
    "print(\"Basic Dataset Statistics:\")\n",
    "print(\"Average year: \" + str(round(df['year'].mean(), 1)))\n",
    "print(\"Average sentiment score: \" + str(round(df['sentiment_score'].mean(), 3)))\n",
    "print(\"Average theme count: \" + str(round(df['theme_count'].mean(), 1)))\n",
    "print()\n",
    "\n",
    "# Genre analysis\n",
    "print(\"Genre Analysis:\")\n",
    "genre_counts = df['genre'].value_counts()\n",
    "print(\"Most common genre: \" + genre_counts.index[0] + \" (\" + str(genre_counts.iloc[0]) + \" items)\")\n",
    "print(\"Total genres: \" + str(len(genre_counts)))\n",
    "print()\n",
    "\n",
    "# Year range analysis\n",
    "print(\"Time Period Analysis:\")\n",
    "print(\"Earliest work: \" + str(df['year'].min()))\n",
    "print(\"Latest work: \" + str(df['year'].max()))\n",
    "print(\"Time span: \" + str(df['year'].max() - df['year'].min()) + \" years\")\n",
    "print()\n",
    "\n",
    "# Sentiment analysis by genre\n",
    "print(\"Sentiment by Genre:\")\n",
    "for genre in df['genre'].unique():\n",
    "    genre_data = df[df['genre'] == genre]\n",
    "    avg_sentiment = genre_data['sentiment_score'].mean()\n",
    "    print(genre + \": \" + str(round(avg_sentiment, 3)))\n",
    "print()\n",
    "\n",
    "# Creator analysis\n",
    "print(\"Creator Analysis:\")\n",
    "creator_counts = df['creator'].value_counts()\n",
    "print(\"Total creators: \" + str(len(creator_counts)))\n",
    "print(\"Most works by one creator: \" + str(creator_counts.max()))\n",
    "print()\n",
    "\n",
    "# Simple correlations\n",
    "correlation_year_sentiment = df['year'].corr(df['sentiment_score'])\n",
    "correlation_year_themes = df['year'].corr(df['theme_count'])\n",
    "print(\"Simple Correlations:\")\n",
    "print(\"Year vs Sentiment: \" + str(round(correlation_year_sentiment, 3)))\n",
    "print(\"Year vs Theme Count: \" + str(round(correlation_year_themes, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Data Visualization Dashboard\n",
    "Create compelling visualizations to communicate your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization (using basic matplotlib patterns from CodeAlongs)\n",
    "print(\"DATA VISUALIZATION:\")\n",
    "print(\"=\" * 20)\n",
    "\n",
    "# 1. Timeline scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['year'], df['sentiment_score'])\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.title('Sentiment Over Time')\n",
    "plt.show()\n",
    "\n",
    "# 2. Genre distribution pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "genre_counts = df['genre'].value_counts()\n",
    "plt.pie(genre_counts.values, labels=genre_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Genre Distribution')\n",
    "plt.show()\n",
    "\n",
    "# 3. Sentiment by genre bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "unique_genres = df['genre'].unique()\n",
    "genre_sentiments = []\n",
    "\n",
    "for genre in unique_genres:\n",
    "    genre_data = df[df['genre'] == genre]\n",
    "    avg_sentiment = genre_data['sentiment_score'].mean()\n",
    "    genre_sentiments.append(avg_sentiment)\n",
    "\n",
    "plt.bar(unique_genres, genre_sentiments)\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Average Sentiment Score')\n",
    "plt.title('Sentiment by Genre')\n",
    "plt.show()\n",
    "\n",
    "# 4. Theme count histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['theme_count'], bins=5)\n",
    "plt.xlabel('Number of Themes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Theme Counts')\n",
    "plt.show()\n",
    "\n",
    "# Insights\n",
    "print(\"VISUALIZATION INSIGHTS:\")\n",
    "\n",
    "# Find most positive genre\n",
    "max_sentiment_idx = 0\n",
    "for i in range(len(genre_sentiments)):\n",
    "    if genre_sentiments[i] > genre_sentiments[max_sentiment_idx]:\n",
    "        max_sentiment_idx = i\n",
    "\n",
    "# Find most negative genre\n",
    "min_sentiment_idx = 0\n",
    "for i in range(len(genre_sentiments)):\n",
    "    if genre_sentiments[i] < genre_sentiments[min_sentiment_idx]:\n",
    "        min_sentiment_idx = i\n",
    "\n",
    "print(\"Most positive genre: \" + unique_genres[max_sentiment_idx] + \" (\" + str(round(genre_sentiments[max_sentiment_idx], 2)) + \")\")\n",
    "print(\"Most negative genre: \" + unique_genres[min_sentiment_idx] + \" (\" + str(round(genre_sentiments[min_sentiment_idx], 2)) + \")\")\n",
    "print(\"Most common genre: \" + genre_counts.index[0])\n",
    "print(\"Average theme count: \" + str(round(df['theme_count'].mean(), 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Final Project Presentation\n",
    "Synthesize your analysis into key findings and conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Analysis and Insights\n",
    "print(\"COMPREHENSIVE ANALYSIS SUMMARY:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(\"DATASET OVERVIEW:\")\n",
    "print(\"Total Items: \" + str(len(df)))\n",
    "print(\"Time Span: \" + str(df['year'].max() - df['year'].min()) + \" years (\" + str(df['year'].min()) + \"-\" + str(df['year'].max()) + \")\")\n",
    "print(\"Unique Creators: \" + str(df['creator'].nunique()))\n",
    "print(\"Genres Analyzed: \" + str(df['genre'].nunique()))\n",
    "\n",
    "print()\n",
    "print(\"KEY FINDINGS:\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# Finding 1: Sentiment trends\n",
    "overall_sentiment = df['sentiment_score'].mean()\n",
    "if overall_sentiment > 0.1:\n",
    "    sentiment_trend = \"positive\"\n",
    "elif overall_sentiment < -0.1:\n",
    "    sentiment_trend = \"negative\"\n",
    "else:\n",
    "    sentiment_trend = \"neutral\"\n",
    "print(\"1. Overall sentiment is \" + sentiment_trend + \" (avg: \" + str(round(overall_sentiment, 2)) + \")\")\n",
    "\n",
    "# Finding 2: Genre insights\n",
    "dominant_genre = df['genre'].value_counts().index[0]\n",
    "genre_percentage = (df['genre'].value_counts().iloc[0] / len(df)) * 100\n",
    "print(\"2. \" + dominant_genre + \" is the dominant genre (\" + str(round(genre_percentage, 1)) + \"% of works)\")\n",
    "\n",
    "# Finding 3: Temporal patterns\n",
    "modern_works = 0\n",
    "historical_works = 0\n",
    "for year in df['year']:\n",
    "    if year >= 1950:\n",
    "        modern_works = modern_works + 1\n",
    "    else:\n",
    "        historical_works = historical_works + 1\n",
    "\n",
    "if modern_works > historical_works:\n",
    "    temporal_focus = \"modern\"\n",
    "else:\n",
    "    temporal_focus = \"historical\"\n",
    "print(\"3. Dataset focuses on \" + temporal_focus + \" works (\" + str(modern_works) + \" modern vs \" + str(historical_works) + \" historical)\")\n",
    "\n",
    "# Finding 4: Thematic complexity\n",
    "avg_themes = df['theme_count'].mean()\n",
    "max_themes_idx = df['theme_count'].idxmax()\n",
    "most_complex = df.loc[max_themes_idx, 'title']\n",
    "print(\"4. Average thematic complexity: \" + str(round(avg_themes, 1)) + \" themes per work\")\n",
    "print(\"   Most complex: '\" + most_complex + \"' (\" + str(df['theme_count'].max()) + \" themes)\")\n",
    "\n",
    "# Finding 5: Creator patterns\n",
    "creator_counts = df['creator'].value_counts()\n",
    "if creator_counts.iloc[0] > 1:\n",
    "    prolific_creator = creator_counts.index[0]\n",
    "    creator_count = creator_counts.iloc[0]\n",
    "    print(\"5. Most prolific creator: \" + prolific_creator + \" (\" + str(creator_count) + \" works)\")\n",
    "else:\n",
    "    print(\"5. All creators represented equally (1 work each)\")\n",
    "\n",
    "print()\n",
    "print(\"RESEARCH QUESTIONS RAISED:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"1. How do cultural and historical contexts influence thematic content?\")\n",
    "print(\"2. What factors contribute to sentiment patterns in cultural works?\")\n",
    "print(\"3. How has thematic complexity evolved over time?\")\n",
    "print(\"4. What role does genre play in cultural expression and reception?\")\n",
    "print(\"5. How might computational analysis complement traditional cultural criticism?\")\n",
    "\n",
    "print()\n",
    "print(\"SKILLS DEMONSTRATED:\")\n",
    "print(\"-\" * 25)\n",
    "print(\"✓ Data collection and validation\")\n",
    "print(\"✓ Text processing and cleaning\") \n",
    "print(\"✓ Sentiment analysis implementation\")\n",
    "print(\"✓ Statistical analysis with Pandas\")\n",
    "print(\"✓ Data visualization\")\n",
    "print(\"✓ Pattern recognition and interpretation\")\n",
    "print(\"✓ Research question formulation\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 40)\n",
    "print(\"CONGRATULATIONS!\")\n",
    "print(\"You've completed a comprehensive cultural data analysis project!\")\n",
    "print(\"This demonstrates mastery of Python for digital humanities research.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Python for Digital Humanities\n",
    "\n",
    "**Skills Mastered Across All Reviews:**\n",
    "\n",
    "**Reviews 01-04: Python Foundations**\n",
    "- Variables, data types, and basic operations\n",
    "- String methods and text processing\n",
    "- Conditional logic and loops\n",
    "- Lists, dictionaries, and data structures\n",
    "- Functions and modular programming\n",
    "\n",
    "**Review 05: Research Ethics**\n",
    "- Ethical data collection principles\n",
    "- Bias recognition and mitigation\n",
    "- Cultural sensitivity in computational analysis\n",
    "- Responsible research practices\n",
    "\n",
    "**Review 06: Data Analysis with Pandas**\n",
    "- DataFrame creation and manipulation\n",
    "- Data cleaning and validation\n",
    "- Statistical analysis and aggregation\n",
    "- Pattern recognition in cultural datasets\n",
    "\n",
    "**Review 07: Text Analysis**\n",
    "- Computational text processing\n",
    "- Sentiment analysis implementation\n",
    "- Thematic analysis and categorization\n",
    "- Cultural text interpretation\n",
    "\n",
    "**Review 08: Data Visualization**\n",
    "- Chart selection and design principles\n",
    "- Multi-panel dashboard creation\n",
    "- Visual storytelling with cultural data\n",
    "- Accessibility and ethical visualization\n",
    "\n",
    "**Review 09: Integration Project**\n",
    "- End-to-end cultural analysis workflow\n",
    "- Research question formulation\n",
    "- Comprehensive project documentation\n",
    "- Ethical reflection and methodology\n",
    "\n",
    "**Applications in Digital Humanities:**\n",
    "- Literary analysis and distant reading\n",
    "- Historical trend identification\n",
    "- Cross-cultural comparative studies\n",
    "- Cultural heritage digitization projects\n",
    "- Social media and digital culture analysis\n",
    "- Museum and archive data analysis\n",
    "\n",
    "**Congratulations on completing the WRIT 20833 Python Review Series!**\n",
    "\n",
    "---\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
