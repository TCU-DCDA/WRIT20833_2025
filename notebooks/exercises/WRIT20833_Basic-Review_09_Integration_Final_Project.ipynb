{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/TCU-DCDA/WRIT20833-2025/blob/main/notebooks/exercises/Review_09_Integration_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WRIT 20833 Review 09: Integration  \n",
    "\n",
    "\n",
    "\n",
    "Integrate all Python skills to date.\n",
    "\n",
    "**Make a copy:** File > Save a copy in Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview: Cultural Data Analysis Portfolio\n",
    "\n",
    "Create a complete cultural data analysis project that demonstrates mastery of:\n",
    "- Data collection and ethics (Review 05)\n",
    "- Data processing with Pandas (Review 06) \n",
    "- Text analysis and sentiment (Review 07)\n",
    "- Data visualization (Review 08)\n",
    "- All foundational Python skills (Reviews 01-04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Project Setup and Data Collection\n",
    "Choose your cultural domain and set up your analysis framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# VADER for sentiment analysis\n",
    "try:\n",
    "    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    print(\" VADER sentiment analysis ready\")\n",
    "except ImportError:\n",
    "    print(\" VADER not available, using basic sentiment analysis\")\n",
    "    analyzer = None\n",
    "\n",
    "# PROJECT CHOICE: Select your cultural domain\n",
    "# Options: books, movies, music, art, theater, digital_culture, etc.\n",
    "\n",
    "project_domain = \"books\"  # TODO: Change to your chosen domain\n",
    "\n",
    "print(f\" CULTURAL ANALYSIS PROJECT: {project_domain.upper()}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Sample dataset - replace with your own data!\n",
    "cultural_data = {\n",
    "    'title': ['1984', 'Pride and Prejudice', 'The Handmaid\\'s Tale', 'Beloved', 'The Great Gatsby'],\n",
    "    'creator': ['George Orwell', 'Jane Austen', 'Margaret Atwood', 'Toni Morrison', 'F. Scott Fitzgerald'],\n",
    "    'year': [1949, 1813, 1985, 1987, 1925],\n",
    "    'genre': ['Dystopian', 'Romance', 'Dystopian', 'Historical Fiction', 'Modernist'],\n",
    "    'description': [\n",
    "        'A totalitarian society under constant surveillance where independent thinking is a crime.',\n",
    "        'A witty exploration of love, marriage, and social class in Regency England.',\n",
    "        'A dystopian tale of women\\'s rights and reproductive freedom in a theocratic society.',\n",
    "        'A powerful story of slavery, trauma, and the lasting effects of historical injustice.',\n",
    "        'The decline of the American Dream through the eyes of the mysterious Jay Gatsby.'\n",
    "    ],\n",
    "    'themes': [\n",
    "        'surveillance, totalitarianism, truth, freedom, oppression',\n",
    "        'love, marriage, social class, wit, independence', \n",
    "        'feminism, reproductive rights, religious extremism, resistance',\n",
    "        'slavery, trauma, memory, motherhood, healing',\n",
    "        'American Dream, wealth, love, illusion, moral decay'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(cultural_data)\n",
    "print(f\"Dataset loaded: {len(df)} items\")\n",
    "print(\"\\nFirst few items:\")\n",
    "print(df[['title', 'creator', 'year', 'genre']].head())\n",
    "\n",
    "# Data validation and cleaning\n",
    "print(\"\\n DATA QUALITY CHECK:\")\n",
    "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"Duplicates: {df.duplicated().sum()}\")\n",
    "print(f\"Year range: {df['year'].min()} - {df['year'].max()}\")\n",
    "print(f\"Unique creators: {df['creator'].nunique()}\")\n",
    "print(f\"Genres: {', '.join(df['genre'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Text Analysis and Theme Extraction\n",
    "Analyze textual content using string methods and sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing function (Review 02 skills)\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean and standardize text data\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "# Sentiment analysis function (Review 07 skills)\n",
    "def analyze_sentiment(text):\n",
    "    \"\"\"Analyze sentiment of text descriptions\"\"\"\n",
    "    if analyzer:\n",
    "        scores = analyzer.polarity_scores(text)\n",
    "        return scores['compound']\n",
    "    else:\n",
    "        # Basic sentiment using word lists\n",
    "        positive_words = ['love', 'beautiful', 'amazing', 'wonderful', 'great', 'excellent', 'brilliant']\n",
    "        negative_words = ['death', 'war', 'tragic', 'terrible', 'awful', 'horrible', 'dystopian', 'oppression']\n",
    "        \n",
    "        text_lower = text.lower()\n",
    "        pos_count = sum(1 for word in positive_words if word in text_lower)\n",
    "        neg_count = sum(1 for word in negative_words if word in text_lower)\n",
    "        \n",
    "        if pos_count > neg_count:\n",
    "            return 0.5\n",
    "        elif neg_count > pos_count:\n",
    "            return -0.5\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "# Theme extraction function (Review 03 & 04 skills)\n",
    "def extract_themes(themes_string):\n",
    "    \"\"\"Convert theme string to list and count occurrences\"\"\"\n",
    "    if pd.isna(themes_string):\n",
    "        return []\n",
    "    return [theme.strip() for theme in themes_string.split(',')]\n",
    "\n",
    "# Apply text analysis\n",
    "print(\" TEXT ANALYSIS RESULTS:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Clean text data\n",
    "df['description_clean'] = df['description'].apply(clean_text)\n",
    "\n",
    "# Sentiment analysis\n",
    "df['sentiment_score'] = df['description'].apply(analyze_sentiment)\n",
    "df['sentiment_category'] = df['sentiment_score'].apply(\n",
    "    lambda x: 'Positive' if x > 0.1 else 'Negative' if x < -0.1 else 'Neutral'\n",
    ")\n",
    "\n",
    "# Theme extraction\n",
    "df['theme_list'] = df['themes'].apply(extract_themes)\n",
    "df['theme_count'] = df['theme_list'].apply(len)\n",
    "\n",
    "# Display results\n",
    "print(\"Sentiment Analysis Results:\")\n",
    "for idx, row in df.iterrows():\n",
    "    print(f\"{row['title'][:25]:<25} | Sentiment: {row['sentiment_category']:<8} ({row['sentiment_score']:.2f})\")\n",
    "\n",
    "print(f\"\\nOverall sentiment distribution:\")\n",
    "sentiment_counts = df['sentiment_category'].value_counts()\n",
    "for category, count in sentiment_counts.items():\n",
    "    print(f\"{category}: {count} items ({count/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Theme frequency analysis\n",
    "all_themes = []\n",
    "for theme_list in df['theme_list']:\n",
    "    all_themes.extend(theme_list)\n",
    "\n",
    "theme_frequency = Counter(all_themes)\n",
    "print(f\"\\nMost common themes:\")\n",
    "for theme, count in theme_frequency.most_common(5):\n",
    "    print(f\"{theme}: {count} occurrences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Statistical Analysis and Patterns\n",
    "Use Pandas for data analysis and pattern discovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical analysis (Review 06 skills)\n",
    "print(\" STATISTICAL ANALYSIS:\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Time period analysis\n",
    "df['century'] = ((df['year'] - 1) // 100 + 1) * 100\n",
    "df['decade'] = (df['year'] // 10) * 10\n",
    "df['era'] = df['year'].apply(\n",
    "    lambda x: 'Pre-1900' if x < 1900 else '20th Century' if x < 2000 else '21st Century'\n",
    ")\n",
    "\n",
    "# Genre analysis\n",
    "genre_stats = df.groupby('genre').agg({\n",
    "    'year': ['min', 'max', 'mean'],\n",
    "    'sentiment_score': 'mean',\n",
    "    'theme_count': 'mean',\n",
    "    'title': 'count'\n",
    "}).round(2)\n",
    "\n",
    "print(\"Genre Statistics:\")\n",
    "print(genre_stats)\n",
    "\n",
    "# Era analysis \n",
    "era_stats = df.groupby('era').agg({\n",
    "    'sentiment_score': 'mean',\n",
    "    'theme_count': 'mean',\n",
    "    'title': 'count'\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\nEra Analysis:\")\n",
    "print(era_stats)\n",
    "\n",
    "# Creator productivity\n",
    "creator_analysis = df['creator'].value_counts()\n",
    "print(f\"\\nMost prolific creators:\")\n",
    "for creator, count in creator_analysis.head(3).items():\n",
    "    avg_sentiment = df[df['creator'] == creator]['sentiment_score'].mean()\n",
    "    print(f\"{creator}: {count} work(s), avg sentiment: {avg_sentiment:.2f}\")\n",
    "\n",
    "# Correlation analysis\n",
    "numeric_cols = ['year', 'sentiment_score', 'theme_count']\n",
    "correlations = df[numeric_cols].corr()\n",
    "print(f\"\\nCorrelations:\")\n",
    "print(correlations.round(3))\n",
    "\n",
    "# Advanced filtering and analysis\n",
    "print(f\"\\n ADVANCED INSIGHTS:\")\n",
    "\n",
    "# Most thematically complex works\n",
    "complex_works = df.nlargest(2, 'theme_count')\n",
    "print(f\"Most thematically complex works:\")\n",
    "for _, work in complex_works.iterrows():\n",
    "    print(f\"- {work['title']} ({work['theme_count']} themes)\")\n",
    "\n",
    "# Sentiment by era\n",
    "print(f\"\\nSentiment trends by era:\")\n",
    "for era in df['era'].unique():\n",
    "    era_sentiment = df[df['era'] == era]['sentiment_score'].mean()\n",
    "    era_count = len(df[df['era'] == era])\n",
    "    print(f\"{era}: {era_sentiment:.2f} average sentiment ({era_count} works)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Data Visualization Dashboard\n",
    "Create compelling visualizations to communicate your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive visualization dashboard (Review 08 skills)\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle(f'{project_domain.title()} Cultural Analysis Dashboard', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Timeline visualization\n",
    "ax1.scatter(df['year'], df['sentiment_score'], c=df['theme_count'], \n",
    "           cmap='viridis', s=100, alpha=0.7, edgecolors='black')\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('Sentiment Score')\n",
    "ax1.set_title('Sentiment Over Time (size = theme complexity)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "# 2. Genre distribution\n",
    "genre_counts = df['genre'].value_counts()\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(genre_counts)))\n",
    "ax2.pie(genre_counts.values, labels=genre_counts.index, autopct='%1.1f%%', \n",
    "        colors=colors, startangle=90)\n",
    "ax2.set_title('Genre Distribution')\n",
    "\n",
    "# 3. Sentiment by genre\n",
    "sentiment_by_genre = df.groupby('genre')['sentiment_score'].mean().sort_values()\n",
    "bars = ax3.barh(sentiment_by_genre.index, sentiment_by_genre.values, \n",
    "                color=['red' if x < 0 else 'green' if x > 0 else 'gray' \n",
    "                       for x in sentiment_by_genre.values], alpha=0.7)\n",
    "ax3.set_xlabel('Average Sentiment Score')\n",
    "ax3.set_title('Sentiment by Genre')\n",
    "ax3.axvline(x=0, color='black', linestyle='-', alpha=0.5)\n",
    "\n",
    "# 4. Theme complexity over time\n",
    "decade_themes = df.groupby('decade')['theme_count'].mean()\n",
    "ax4.plot(decade_themes.index, decade_themes.values, 'o-', linewidth=2, markersize=8)\n",
    "ax4.set_xlabel('Decade')\n",
    "ax4.set_ylabel('Average Theme Count')\n",
    "ax4.set_title('Thematic Complexity Trends')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional focused visualizations\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Theme frequency bar chart\n",
    "top_themes = theme_frequency.most_common(8)\n",
    "themes, counts = zip(*top_themes)\n",
    "ax1.bar(themes, counts, color='skyblue', alpha=0.8)\n",
    "ax1.set_xlabel('Themes')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Most Common Themes')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Era comparison\n",
    "era_sentiment = df.groupby('era')['sentiment_score'].mean()\n",
    "ax2.bar(era_sentiment.index, era_sentiment.values, \n",
    "        color=['lightcoral', 'lightgreen', 'lightblue'][:len(era_sentiment)], alpha=0.8)\n",
    "ax2.set_xlabel('Era')\n",
    "ax2.set_ylabel('Average Sentiment')\n",
    "ax2.set_title('Sentiment Across Eras')\n",
    "ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\" VISUALIZATION INSIGHTS:\")\n",
    "print(f\" Most positive genre: {sentiment_by_genre.index[-1]} ({sentiment_by_genre.iloc[-1]:.2f})\")\n",
    "print(f\" Most negative genre: {sentiment_by_genre.index[0]} ({sentiment_by_genre.iloc[0]:.2f})\")\n",
    "print(f\" Most complex themes appear in: {df.loc[df['theme_count'].idxmax(), 'title']}\")\n",
    "print(f\" Era with highest sentiment: {era_sentiment.idxmax()} ({era_sentiment.max():.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Final Project Presentation\n",
    "Synthesize your analysis into key findings and conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive project summary\n",
    "print(\" FINAL PROJECT SUMMARY\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Cultural Domain: {project_domain.title()}\")\n",
    "print(f\"Dataset Size: {len(df)} items\")\n",
    "print(f\"Time Span: {df['year'].max() - df['year'].min()} years ({df['year'].min()}-{df['year'].max()})\")\n",
    "print(f\"Unique Creators: {df['creator'].nunique()}\")\n",
    "print(f\"Genres Analyzed: {df['genre'].nunique()}\")\n",
    "\n",
    "print(\"\\n KEY FINDINGS:\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# Finding 1: Sentiment trends\n",
    "overall_sentiment = df['sentiment_score'].mean()\n",
    "sentiment_trend = \"positive\" if overall_sentiment > 0.1 else \"negative\" if overall_sentiment < -0.1 else \"neutral\"\n",
    "print(f\"1. Overall sentiment is {sentiment_trend} (avg: {overall_sentiment:.2f})\")\n",
    "\n",
    "# Finding 2: Genre insights\n",
    "dominant_genre = df['genre'].value_counts().index[0]\n",
    "genre_percentage = (df['genre'].value_counts().iloc[0] / len(df)) * 100\n",
    "print(f\"2. {dominant_genre} is the dominant genre ({genre_percentage:.1f}% of works)\")\n",
    "\n",
    "# Finding 3: Temporal patterns\n",
    "modern_works = len(df[df['year'] >= 1950])\n",
    "historical_works = len(df[df['year'] < 1950])\n",
    "if modern_works > historical_works:\n",
    "    temporal_focus = \"modern\"\n",
    "else:\n",
    "    temporal_focus = \"historical\"\n",
    "print(f\"3. Dataset focuses on {temporal_focus} works ({modern_works} modern vs {historical_works} historical)\")\n",
    "\n",
    "# Finding 4: Thematic complexity\n",
    "avg_themes = df['theme_count'].mean()\n",
    "most_complex = df.loc[df['theme_count'].idxmax(), 'title']\n",
    "print(f\"4. Average thematic complexity: {avg_themes:.1f} themes per work\")\n",
    "print(f\"   Most complex: '{most_complex}' ({df['theme_count'].max()} themes)\")\n",
    "\n",
    "# Finding 5: Creator patterns\n",
    "if df['creator'].value_counts().iloc[0] > 1:\n",
    "    prolific_creator = df['creator'].value_counts().index[0]\n",
    "    creator_count = df['creator'].value_counts().iloc[0]\n",
    "    print(f\"5. Most prolific creator: {prolific_creator} ({creator_count} works)\")\n",
    "else:\n",
    "    print(f\"5. All creators represented equally (1 work each)\")\n",
    "\n",
    "print(\"\\n RESEARCH QUESTIONS RAISED:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"1. How do cultural and historical contexts influence thematic content?\")\n",
    "print(\"2. What factors contribute to sentiment patterns in cultural works?\")\n",
    "print(\"3. How has thematic complexity evolved over time?\")\n",
    "print(\"4. What role does genre play in cultural expression and reception?\")\n",
    "print(\"5. How might computational analysis complement traditional cultural criticism?\")\n",
    "\n",
    "print(\"\\n SKILLS DEMONSTRATED:\")\n",
    "print(\"-\" * 25)\n",
    "skills_checklist = [\n",
    "    \" Data collection and validation\",\n",
    "    \" Text processing and cleaning\", \n",
    "    \" Sentiment analysis implementation\",\n",
    "    \" Statistical analysis with Pandas\",\n",
    "    \" Data visualization and dashboards\",\n",
    "    \" Ethical consideration of cultural data\",\n",
    "    \" Pattern recognition and interpretation\",\n",
    "    \" Research question formulation\"\n",
    "]\n",
    "\n",
    "for skill in skills_checklist:\n",
    "    print(skill)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\" CONGRATULATIONS!\")\n",
    "print(\"You've completed a comprehensive cultural data analysis project!\")\n",
    "print(\"This demonstrates mastery of Python for digital humanities research.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Python for Digital Humanities\n",
    "\n",
    "**Skills Mastered Across All Reviews:**\n",
    "\n",
    "**Reviews 01-04: Python Foundations**\n",
    "- Variables, data types, and basic operations\n",
    "- String methods and text processing\n",
    "- Conditional logic and loops\n",
    "- Lists, dictionaries, and data structures\n",
    "- Functions and modular programming\n",
    "\n",
    "**Review 05: Research Ethics**\n",
    "- Ethical data collection principles\n",
    "- Bias recognition and mitigation\n",
    "- Cultural sensitivity in computational analysis\n",
    "- Responsible research practices\n",
    "\n",
    "**Review 06: Data Analysis with Pandas**\n",
    "- DataFrame creation and manipulation\n",
    "- Data cleaning and validation\n",
    "- Statistical analysis and aggregation\n",
    "- Pattern recognition in cultural datasets\n",
    "\n",
    "**Review 07: Text Analysis**\n",
    "- Computational text processing\n",
    "- Sentiment analysis implementation\n",
    "- Thematic analysis and categorization\n",
    "- Cultural text interpretation\n",
    "\n",
    "**Review 08: Data Visualization**\n",
    "- Chart selection and design principles\n",
    "- Multi-panel dashboard creation\n",
    "- Visual storytelling with cultural data\n",
    "- Accessibility and ethical visualization\n",
    "\n",
    "**Review 09: Integration Project**\n",
    "- End-to-end cultural analysis workflow\n",
    "- Research question formulation\n",
    "- Comprehensive project documentation\n",
    "- Ethical reflection and methodology\n",
    "\n",
    "**Applications in Digital Humanities:**\n",
    "- Literary analysis and distant reading\n",
    "- Historical trend identification\n",
    "- Cross-cultural comparative studies\n",
    "- Cultural heritage digitization projects\n",
    "- Social media and digital culture analysis\n",
    "- Museum and archive data analysis\n",
    "\n",
    "**Congratulations on completing the WRIT 20833 Python Review Series!**\n",
    "\n",
    "---\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
