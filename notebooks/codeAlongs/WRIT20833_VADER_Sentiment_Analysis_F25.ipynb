{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3WHoMorY2er"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/TCU-DCDA/WRIT20833-2025/blob/main/notebooks/codeAlongs/WRIT20833_VADER_Sentiment_Analysis_F25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45aEs36TY2es"
   },
   "source": [
    "# Sentiment Analysis with VADER\n",
    "## From Words to Emotions in Cultural Data\n",
    "\n",
    "Welcome to sentiment analysis! Today we'll learn to analyze the **emotional tone** of cultural texts using VADER, a tool designed for social media and informal language.\n",
    "\n",
    "### üéØ What You'll Learn:\n",
    "- **Install and use VADER** for sentiment analysis\n",
    "- **Apply sentiment analysis** to your scraped cultural data\n",
    "- **Interpret and visualize** emotional patterns in texts\n",
    "- **Think critically** about automated emotion detection\n",
    "\n",
    "### üîó Connection to Your Work:\n",
    "This prepares you for **HW4-1**, where you'll analyze term frequency AND sentiment in your own dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCnF4yXxY2es"
   },
   "source": [
    "## Part 1: From Word Counting to Emotion Analysis\n",
    "\n",
    "### Quick HW1 Refresher\n",
    "In HW1, you counted frequent words and formed **first impressions** about different text types:\n",
    "- Political documents had words like \"shall,\" \"constitution,\" \"rights\"\n",
    "- Novels had character names and descriptive language\n",
    "- You made predictions, then tested them by counting\n",
    "\n",
    "### Today's Evolution\n",
    "**Same prediction-testing process, new question:**\n",
    "- HW1: \"What words appear most often?\"\n",
    "- Today: \"What emotions do these words express?\"\n",
    "\n",
    "Let's start with examples from cultural data like **YouTube comments** and **reviews**."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### üìñ Close Reading vs. Distant Reading\n",
    "\n",
    "**Close Reading** (careful human interpretation):\n",
    "- Reading individual texts carefully\n",
    "- Noticing specific words, phrases, emotional nuances\n",
    "- Making interpretive claims about meaning and tone\n",
    "\n",
    "**Distant Reading** (computational pattern detection):\n",
    "- Using tools like VADER to analyze many texts at once\n",
    "- Detecting emotional patterns across large collections\n",
    "- Asking questions impossible to answer by reading alone\n",
    "\n",
    "**The Critical Connection**:\n",
    "You need close reading skills to **validate** distant reading results!\n",
    "- VADER gives you a score (0.772), but YOU must read the text to decide if that score makes sense\n",
    "- When VADER fails on irony or sarcasm, only close reading can catch it\n",
    "- Part 5 of this notebook specifically asks you to compare VADER's scores to your human judgment\n",
    "\n",
    "**The Workflow**: Close read (predict) ‚Üí Distant read (compute) ‚Üí Close read again (validate)"
   ],
   "metadata": {
    "id": "37uTQJS8qf5d"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kiecERzEY2es"
   },
   "outputs": [],
   "source": [
    "# Setup: Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# We'll install VADER in the next cell\n",
    "print(\"üìö Libraries imported - ready for sentiment analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q_XGLzwDY2et"
   },
   "outputs": [],
   "source": [
    "# Install and import VADER\n",
    "!pip install vaderSentiment\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "print(\"‚úÖ VADER installed and ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXkswxPSY2et"
   },
   "source": [
    "## Part 2: VADER Basics with Cultural Examples\n",
    "\n",
    "Let's test VADER with the kind of informal cultural texts you might find online:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OxkIW8azY2et"
   },
   "outputs": [],
   "source": [
    "# Cultural text examples - predict the sentiment first!\n",
    "cultural_texts = [\n",
    "    \"This museum exhibition was absolutely AMAZING!!!\",\n",
    "    \"worst movie ever made, complete waste of time\",\n",
    "    \"The book was okay, nothing special but not terrible either\",\n",
    "    \"I love love LOVE this artist's work! So inspiring ‚ù§Ô∏è\",\n",
    "    \"The concert was good but the sound quality sucked\"\n",
    "]\n",
    "\n",
    "print(\"ü§î Before we run VADER, predict:\")\n",
    "print(\"Which texts are positive? Negative? Neutral?\")\n",
    "print(\"Which will have the STRONGEST emotion?\")\n",
    "print(\"\\nNow let's test your predictions...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5QHNw4eOY2et"
   },
   "outputs": [],
   "source": [
    "# Test VADER on our cultural examples\n",
    "print(\"VADER Sentiment Analysis Results:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, text in enumerate(cultural_texts, 1):\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    compound = scores['compound']  # This is our main score (-1 to 1)\n",
    "\n",
    "    print(f\"{i}. Text: {text}\")\n",
    "    print(f\"   Compound Score: {compound:.3f}\")\n",
    "    print(f\"   Breakdown: {scores}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### üîë Key Concept: Quantifying Connotation\n\n**Sentiment analysis is essentially quantifying connotation:**\n\n- **Denotation** = literal dictionary meaning\n- **Connotation** = emotional associations and cultural implications\n\n**Example:**\n- \"inexpensive\" and \"cheap\" both denote low cost\n- But \"inexpensive\" has positive connotation (+), \"cheap\" has negative (-)\n- VADER assigns: \"inexpensive\" ‚âà +1.5, \"cheap\" ‚âà -1.0\n\n**The Critical Question:**\nIf connotation varies by culture, time period, and context, can an algorithm with fixed scores truly capture it? This is why you must **validate VADER's scores with your own close reading** (Part 5).",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### üîç How Does VADER Know What's Positive or Negative?\n",
    "\n",
    "VADER uses a **sentiment lexicon** - a dictionary of ~7,500 words with pre-assigned emotion scores:\n",
    "- \"amazing\" = +3.1 (very positive)\n",
    "- \"okay\" = +0.9 (mildly positive)  \n",
    "- \"terrible\" = -2.3 (very negative)\n",
    "\n",
    "**See the lexicon yourself**: [VADER Lexicon on GitHub](https://github.com/cjhutto/vaderSentiment/blob/master/vaderSentiment/vader_lexicon.txt)\n",
    "\n",
    "**VADER also adjusts for**:\n",
    "- Capitalization (\"AMAZING\" scores higher than \"amazing\")\n",
    "- Punctuation (\"good!!!\" scores higher than \"good\")\n",
    "- Emoticons and emojis (üòç, ‚ù§Ô∏è)\n",
    "- Context clues (\"not good\" reverses the score)\n",
    "\n",
    "**Critical question**: What cultural assumptions are built into this lexicon? Who decided these scores?"
   ],
   "metadata": {
    "id": "wNcpVt4rqf5f"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbG2TmZ9Y2et"
   },
   "source": [
    "### üéØ Quick Check: Understanding VADER Scores\n",
    "\n",
    "**Compound Score** (your main number):\n",
    "- **+1.0** = extremely positive\n",
    "- **0.0** = neutral  \n",
    "- **-1.0** = extremely negative\n",
    "\n",
    "**Individual Scores** (show how VADER thinks):\n",
    "- **pos**: percentage of positive words\n",
    "- **neg**: percentage of negative words  \n",
    "- **neu**: percentage of neutral words\n",
    "\n",
    "**Notice**: VADER catches intensity (\"AMAZING!!!\") and mixed emotions (\"good but sucked\")!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZW7QmQPnY2eu"
   },
   "source": [
    "### VADER vs. TextBlob: Quick Comparison\n",
    "\n",
    "Let's see how different tools can give different results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "szAE7HbGY2eu"
   },
   "outputs": [],
   "source": [
    "# Install TextBlob for comparison\n",
    "!pip install textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Compare on a tricky example\n",
    "test_text = \"This movie is SO good!!! I can't even üòç\"\n",
    "\n",
    "# VADER analysis\n",
    "vader_score = analyzer.polarity_scores(test_text)['compound']\n",
    "\n",
    "# TextBlob analysis\n",
    "blob = TextBlob(test_text)\n",
    "textblob_score = blob.sentiment.polarity\n",
    "\n",
    "print(f\"Text: {test_text}\")\n",
    "print(f\"VADER score: {vader_score:.3f}\")\n",
    "print(f\"TextBlob score: {textblob_score:.3f}\")\n",
    "print(\"\\nüí° VADER is better with informal language, caps, and emoticons!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srzuVqZ6Y2eu"
   },
   "source": [
    "## Part 3: Applying VADER to Your Cultural Dataset\n",
    "\n",
    "Now let's work with the kind of data you collected in the Instant Data Scraper lesson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rEyHvXQ0Y2eu"
   },
   "outputs": [],
   "source": [
    "# Create sample cultural data (like what you scraped)\n",
    "sample_reviews = {\n",
    "    'title': ['Hamilton', 'Cats', 'The Lion King', 'Phantom of the Opera', 'Chicago',\n",
    "              'Wicked', 'Les Mis√©rables', 'Mamma Mia!', 'Book of Mormon', 'Dear Evan Hansen'],\n",
    "    'review_text': [\n",
    "        \"Absolutely brilliant musical! The hip-hop history was incredible and the cast was amazing.\",\n",
    "        \"I really didn't understand what was happening. Weird costumes and confusing plot.\",\n",
    "        \"Beautiful production with stunning visuals. The Circle of Life scene gave me chills!\",\n",
    "        \"Classic for a reason. The phantom's voice was haunting and the staging was magnificent.\",\n",
    "        \"Great dancing and catchy songs. Entertaining but not life-changing.\",\n",
    "        \"Mind-blowing! Defying Gravity made me cry. Elphaba was perfect.\",\n",
    "        \"Long but worth it. The barricade scene was emotionally devastating in the best way.\",\n",
    "        \"Fun and energetic! ABBA songs are so catchy, left feeling happy and uplifted.\",\n",
    "        \"Hilarious and inappropriate. Not for everyone but I laughed until my sides hurt.\",\n",
    "        \"Heartbreaking and beautiful. Dealt with mental health in such a thoughtful way.\"\n",
    "    ],\n",
    "    'rating': [5, 2, 4, 5, 3, 5, 4, 4, 4, 5],\n",
    "    'category': ['Historical', 'Fantasy', 'Family', 'Classic', 'Musical',\n",
    "                'Fantasy', 'Historical', 'Musical', 'Comedy', 'Contemporary']\n",
    "}\n",
    "\n",
    "# Convert to DataFrame (like loading your CSV)\n",
    "df = pd.DataFrame(sample_reviews)\n",
    "\n",
    "print(\"üé≠ Sample Broadway Reviews Dataset Loaded\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bC5euv2Y2eu"
   },
   "source": [
    "### üìù Text Preparation (Building on HW1)\n",
    "\n",
    "Just like in HW1, we need to prepare our text. But this time, we keep it simple since VADER handles informal language well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zzPjoEHxY2eu"
   },
   "outputs": [],
   "source": [
    "# Simple text cleaning (less aggressive than HW1 word counting)\n",
    "def clean_for_sentiment(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    # Keep punctuation and capitalization - VADER needs them!\n",
    "    return str(text).strip()\n",
    "\n",
    "# Clean the text column\n",
    "df['clean_text'] = df['review_text'].apply(clean_for_sentiment)\n",
    "\n",
    "print(\"‚úÖ Text cleaning complete - kept punctuation for VADER\")\n",
    "print(\"\\nSample cleaned text:\")\n",
    "print(df['clean_text'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMR8jc9vY2eu"
   },
   "source": [
    "### Individual Analysis ‚Üí Batch Processing\n",
    "\n",
    "Let's start with one review, then scale up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X5QWVKoZY2eu"
   },
   "outputs": [],
   "source": [
    "# Analyze one review first\n",
    "sample_review = df['clean_text'].iloc[0]\n",
    "sample_scores = analyzer.polarity_scores(sample_review)\n",
    "\n",
    "print(\"Individual Review Analysis:\")\n",
    "print(f\"Review: {sample_review}\")\n",
    "print(f\"Compound score: {sample_scores['compound']:.3f}\")\n",
    "print(f\"Full breakdown: {sample_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2MKU_MTY2eu"
   },
   "outputs": [],
   "source": [
    "# Now process the entire dataset (batch processing)\n",
    "def get_sentiment_score(text):\n",
    "    \"\"\"Get compound sentiment score for a text\"\"\"\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    return scores['compound']\n",
    "\n",
    "# Apply to entire dataset\n",
    "df['sentiment_score'] = df['clean_text'].apply(get_sentiment_score)\n",
    "\n",
    "print(\"‚úÖ Sentiment analysis complete for entire dataset!\")\n",
    "print(\"\\nFirst few results:\")\n",
    "print(df[['title', 'sentiment_score', 'rating']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFzjBUeDY2eu"
   },
   "source": [
    "## Part 4: Interpreting and Visualizing Results\n",
    "\n",
    "Let's explore what our sentiment analysis reveals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "woPbE9wuY2eu"
   },
   "outputs": [],
   "source": [
    "# Basic sentiment statistics\n",
    "print(\"SENTIMENT ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Average sentiment: {df['sentiment_score'].mean():.3f}\")\n",
    "print(f\"Most positive review: {df['sentiment_score'].max():.3f}\")\n",
    "print(f\"Most negative review: {df['sentiment_score'].min():.3f}\")\n",
    "print(f\"Standard deviation: {df['sentiment_score'].std():.3f}\")\n",
    "\n",
    "# Find the most positive and negative reviews\n",
    "most_positive = df.loc[df['sentiment_score'].idxmax()]\n",
    "most_negative = df.loc[df['sentiment_score'].idxmin()]\n",
    "\n",
    "print(f\"\\nMost positive review ({most_positive['sentiment_score']:.3f}):\")\n",
    "print(f\"'{most_positive['title']}': {most_positive['review_text']}\")\n",
    "\n",
    "print(f\"\\nMost negative review ({most_negative['sentiment_score']:.3f}):\")\n",
    "print(f\"'{most_negative['title']}': {most_negative['review_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QdrDvHaNY2eu"
   },
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Sentiment distribution\n",
    "axes[0].hist(df['sentiment_score'], bins=8, color='skyblue', alpha=0.7)\n",
    "axes[0].set_title('Distribution of Sentiment Scores')\n",
    "axes[0].set_xlabel('Sentiment Score (-1 to 1)')\n",
    "axes[0].set_ylabel('Number of Reviews')\n",
    "axes[0].axvline(0, color='red', linestyle='--', alpha=0.5, label='Neutral')\n",
    "axes[0].legend()\n",
    "\n",
    "# Sentiment vs. Rating scatter plot\n",
    "axes[1].scatter(df['rating'], df['sentiment_score'], alpha=0.7, color='coral')\n",
    "axes[1].set_title('Sentiment Score vs. Numeric Rating')\n",
    "axes[1].set_xlabel('Star Rating (1-5)')\n",
    "axes[1].set_ylabel('Sentiment Score')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä What patterns do you notice?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SuTrns04Y2eu"
   },
   "outputs": [],
   "source": [
    "# Analyze sentiment by category\n",
    "category_sentiment = df.groupby('category')['sentiment_score'].agg(['mean', 'count']).round(3)\n",
    "category_sentiment = category_sentiment.sort_values('mean', ascending=False)\n",
    "\n",
    "print(\"SENTIMENT BY CATEGORY\")\n",
    "print(\"=\" * 25)\n",
    "print(category_sentiment)\n",
    "\n",
    "# Visualize category sentiment\n",
    "plt.figure(figsize=(10, 6))\n",
    "category_sentiment['mean'].plot(kind='bar', color='lightgreen', alpha=0.8)\n",
    "plt.title('Average Sentiment by Broadway Show Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Average Sentiment Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYs5cYJ3Y2ev"
   },
   "source": [
    "## Part 5: Critical Analysis - When VADER Gets It Wrong\n",
    "\n",
    "Let's examine where automated sentiment analysis might struggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I3ydIklWY2ev"
   },
   "outputs": [],
   "source": [
    "# Test VADER on tricky cultural examples\n",
    "tricky_texts = [\n",
    "    \"This show was so bad it was good\",  # Irony\n",
    "    \"The ending was beautifully tragic\",  # Mixed emotions\n",
    "    \"I literally died laughing\",  # Hyperbole\n",
    "    \"It was... fine\",  # Subtle negativity\n",
    "    \"Not the worst thing I've ever seen\"  # Double negative\n",
    "]\n",
    "\n",
    "print(\"ü§î CHALLENGING CASES FOR SENTIMENT ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for text in tricky_texts:\n",
    "    score = analyzer.polarity_scores(text)['compound']\n",
    "    print(f\"Text: '{text}'\")\n",
    "    print(f\"VADER score: {score:.3f}\")\n",
    "    print(f\"Your human judgment: _____\")  # Students fill this in\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJURV_VFY2ev"
   },
   "source": [
    "### üí≠ Notes for Final Reflection:\n",
    "\n",
    "*Space for your thoughts during class - you'll use these for HW4-1:*\n",
    "\n",
    "**Where VADER worked well:**\n",
    "-\n",
    "-\n",
    "\n",
    "**Where VADER struggled:**\n",
    "-\n",
    "-\n",
    "\n",
    "**Questions this raises about cultural texts:**\n",
    "-\n",
    "-\n",
    "\n",
    "**Predictions for my own dataset:**\n",
    "-\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAwOhA2nY2ev"
   },
   "source": [
    "## Part 6: Preparing for HW4-1\n",
    "\n",
    "You now have the skills for HW4-1! Let's review the complete workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pVncS9OPY2ev"
   },
   "outputs": [],
   "source": [
    "# Complete workflow summary\n",
    "print(\"üéØ HW4-1 WORKFLOW CHECKLIST\")\n",
    "print(\"=\" * 30)\n",
    "print(\"‚úÖ 1. Load your scraped CSV data\")\n",
    "print(\"‚úÖ 2. Clean text (but keep punctuation for VADER)\")\n",
    "print(\"‚úÖ 3. Make predictions about sentiment patterns\")\n",
    "print(\"‚úÖ 4. Apply VADER to your dataset\")\n",
    "print(\"‚úÖ 5. Create visualizations of sentiment patterns\")\n",
    "print(\"‚úÖ 6. Compare predictions to actual results\")\n",
    "print(\"‚úÖ 7. Analyze where VADER works/fails with your texts\")\n",
    "print(\"‚úÖ 8. Reflect on insights and limitations\")\n",
    "\n",
    "print(\"\\nüöÄ You're ready for HW4-1!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-KoP35cY2ev"
   },
   "source": [
    "### Looking Ahead: Topic Modeling Preview\n",
    "\n",
    "**After HW4-1, you'll move to HW4-2** where you'll discover **hidden topics** in your text using machine learning.\n",
    "\n",
    "**Quick preview**: While sentiment analysis asks \"What emotions?\", topic modeling asks \"What themes and subjects are hiding in this collection?\"\n",
    "\n",
    "The text preprocessing you're learning now will prepare you for that next step!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEQr7HEGY2ev"
   },
   "source": [
    "## Summary: From Words to Emotions\n",
    "\n",
    "Today you learned to:\n",
    "\n",
    "**Technical Skills:**\n",
    "- ‚úÖ Install and use VADER sentiment analysis\n",
    "- ‚úÖ Process individual texts and entire datasets\n",
    "- ‚úÖ Interpret compound sentiment scores\n",
    "- ‚úÖ Create meaningful visualizations of emotional patterns\n",
    "\n",
    "**Critical Thinking:**\n",
    "- ‚úÖ Compare different sentiment analysis tools\n",
    "- ‚úÖ Recognize where automated analysis succeeds and fails\n",
    "- ‚úÖ Question the objectivity of algorithmic emotion detection\n",
    "- ‚úÖ Connect computational analysis to cultural research questions\n",
    "\n",
    "**Research Skills:**\n",
    "- ‚úÖ Form predictions and test them systematically\n",
    "- ‚úÖ Scale analysis from individual examples to entire datasets\n",
    "- ‚úÖ Document insights for deeper reflection\n",
    "- ‚úÖ Prepare text data for multiple types of analysis\n",
    "\n",
    "### üéØ You're Ready for HW4-1!\n",
    "\n",
    "Apply these skills to your own scraped cultural dataset and discover what emotional patterns emerge from your data. Remember: being surprised by your results is a sign of genuine learning, not failure!\n",
    "\n",
    "**Next**: Use your scraped data to complete the term frequency and sentiment analysis assignment, then get ready for topic modeling in HW4-2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}