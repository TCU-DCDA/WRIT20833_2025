{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/TCU-DCDA/WRIT20833-2025/blob/main/notebooks/codeAlongs/WRIT20833_VADER_Sentiment_Analysis_F25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with VADER\n",
    "## From Words to Emotions in Cultural Data\n",
    "\n",
    "Welcome to sentiment analysis! Today we'll learn to analyze the **emotional tone** of cultural texts using VADER, a tool designed for social media and informal language.\n",
    "\n",
    "### üéØ What You'll Learn:\n",
    "- **Install and use VADER** for sentiment analysis\n",
    "- **Apply sentiment analysis** to your scraped cultural data\n",
    "- **Interpret and visualize** emotional patterns in texts\n",
    "- **Think critically** about automated emotion detection\n",
    "\n",
    "### üîó Connection to Your Work:\n",
    "This prepares you for **HW4-1**, where you'll analyze term frequency AND sentiment in your own dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: From Word Counting to Emotion Analysis\n",
    "\n",
    "### Quick HW1 Refresher\n",
    "In HW1, you counted frequent words and formed **first impressions** about different text types:\n",
    "- Political documents had words like \"shall,\" \"constitution,\" \"rights\"\n",
    "- Novels had character names and descriptive language\n",
    "- You made predictions, then tested them by counting\n",
    "\n",
    "### Today's Evolution\n",
    "**Same prediction-testing process, new question:**\n",
    "- HW1: \"What words appear most often?\"\n",
    "- Today: \"What emotions do these words express?\"\n",
    "\n",
    "Let's start with examples from cultural data like **YouTube comments** and **reviews**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install and import VADER\\n!pip install vaderSentiment  # Download and install the VADER package\\n\\n# Import the sentiment analysis tool\\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\\n\\n# Create our sentiment analyzer object\\nanalyzer = SentimentIntensityAnalyzer()\\n\\nprint(\\\"‚úÖ VADER installed and ready!\\\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Test VADER on our cultural examples\\nprint(\\\"VADER Sentiment Analysis Results:\\\")\\nprint(\\\"=\\\" * 50)\\n\\n# Loop through each text example\\nfor i, text in enumerate(cultural_texts, 1):  # enumerate gives us numbers starting at 1\\n    # Analyze the sentiment of this text\\n    scores = analyzer.polarity_scores(text)\\n    \\n    # Extract the compound score (our main number)\\n    compound = scores['compound']  # This ranges from -1 to 1\\n    \\n    # Print the results\\n    print(f\\\"{i}. Text: {text}\\\")\\n    print(f\\\"   Compound Score: {compound:.3f}\\\")  # .3f means 3 decimal places\\n    print(f\\\"   Breakdown: {scores}\\\")  # Shows all four scores\\n    print()  # Empty line for spacing"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cultural text examples - predict the sentiment first!\n",
    "cultural_texts = [\n",
    "    \"This museum exhibition was absolutely AMAZING!!!\",\n",
    "    \"worst movie ever made, complete waste of time\",\n",
    "    \"The book was okay, nothing special but not terrible either\",\n",
    "    \"I love love LOVE this artist's work! So inspiring ‚ù§Ô∏è\",\n",
    "    \"The concert was good but the sound quality sucked\"\n",
    "]\n",
    "\n",
    "print(\"ü§î Before we run VADER, predict:\")\n",
    "print(\"Which texts are positive? Negative? Neutral?\")\n",
    "print(\"Which will have the STRONGEST emotion?\")\n",
    "print(\"\\nNow let's test your predictions...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install TextBlob for comparison\\n!pip install textblob  # Download TextBlob package\\nfrom textblob import TextBlob  # Import TextBlob tool\\n\\n# Compare on a tricky example\\ntest_text = \\\"This movie is SO good!!! I can't even üòç\\\"\\n\\n# VADER analysis\\nvader_score = analyzer.polarity_scores(test_text)['compound']  # Get compound score\\n\\n# TextBlob analysis\\nblob = TextBlob(test_text)  # Create TextBlob object\\ntextblob_score = blob.sentiment.polarity  # Get polarity score\\n\\n# Print comparison\\nprint(f\\\"Text: {test_text}\\\")\\nprint(f\\\"VADER score: {vader_score:.3f}\\\")     # VADER result\\nprint(f\\\"TextBlob score: {textblob_score:.3f}\\\")  # TextBlob result\\nprint(\\\"\\\\nüí° VADER is better with informal language, caps, and emoticons!\\\")\""
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Create sample cultural data (like what you scraped)\\nsample_reviews = {\\n    # List of Broadway show titles\\n    'title': ['Hamilton', 'Cats', 'The Lion King', 'Phantom of the Opera', 'Chicago', \\n              'Wicked', 'Les Mis√©rables', 'Mamma Mia!', 'Book of Mormon', 'Dear Evan Hansen'],\\n    \\n    # Review text - this is what we'll analyze for sentiment\\n    'review_text': [\\n        \\\"Absolutely brilliant musical! The hip-hop history was incredible and the cast was amazing.\\\",\\n        \\\"I really didn't understand what was happening. Weird costumes and confusing plot.\\\",\\n        \\\"Beautiful production with stunning visuals. The Circle of Life scene gave me chills!\\\",\\n        \\\"Classic for a reason. The phantom's voice was haunting and the staging was magnificent.\\\",\\n        \\\"Great dancing and catchy songs. Entertaining but not life-changing.\\\",\\n        \\\"Mind-blowing! Defying Gravity made me cry. Elphaba was perfect.\\\",\\n        \\\"Long but worth it. The barricade scene was emotionally devastating in the best way.\\\",\\n        \\\"Fun and energetic! ABBA songs are so catchy, left feeling happy and uplifted.\\\",\\n        \\\"Hilarious and inappropriate. Not for everyone but I laughed until my sides hurt.\\\",\\n        \\\"Heartbreaking and beautiful. Dealt with mental health in such a thoughtful way.\\\"\\n    ],\\n    \\n    # Numeric ratings (1-5 stars)\\n    'rating': [5, 2, 4, 5, 3, 5, 4, 4, 4, 5],\\n    \\n    # Show categories\\n    'category': ['Historical', 'Fantasy', 'Family', 'Classic', 'Musical', \\n                'Fantasy', 'Historical', 'Musical', 'Comedy', 'Contemporary']\\n}\\n\\n# Convert dictionary to DataFrame (like loading your CSV)\\ndf = pd.DataFrame(sample_reviews)\\n\\nprint(\\\"üé≠ Sample Broadway Reviews Dataset Loaded\\\")\\nprint(f\\\"Dataset shape: {df.shape}\\\")  # Shows (rows, columns)\\ndf.head()  # Display first 5 rows"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Simple text cleaning (less aggressive than HW1 word counting)\\ndef clean_for_sentiment(text):\\n    \\\"\\\"\\\"Clean text for sentiment analysis\\\"\\\"\\\"\\n    if pd.isna(text):  # Check if text is missing/NaN\\n        return \\\"\\\"       # Return empty string if missing\\n    # Keep punctuation and capitalization - VADER needs them!\\n    return str(text).strip()  # Convert to string and remove extra spaces\\n\\n# Apply cleaning function to the review text column\\ndf['clean_text'] = df['review_text'].apply(clean_for_sentiment)\\n\\nprint(\\\"‚úÖ Text cleaning complete - kept punctuation for VADER\\\")\\nprint(\\\"\\\\nSample cleaned text:\\\")\\nprint(df['clean_text'].iloc[0])  # Show first cleaned text"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Analyze one review first\\nsample_review = df['clean_text'].iloc[0]  # Get the first review\\nsample_scores = analyzer.polarity_scores(sample_review)  # Analyze it\\n\\nprint(\\\"Individual Review Analysis:\\\")\\nprint(f\\\"Review: {sample_review}\\\")\\nprint(f\\\"Compound score: {sample_scores['compound']:.3f}\\\")  # Main score\\nprint(f\\\"Full breakdown: {sample_scores}\\\")  # All four scores\""
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Now process the entire dataset (batch processing)\\ndef get_sentiment_score(text):\\n    \\\"\\\"\\\"Get compound sentiment score for a text\\\"\\\"\\\"\\n    scores = analyzer.polarity_scores(text)  # Analyze the text\\n    return scores['compound']  # Return just the compound score\\n\\n# Apply sentiment analysis to entire dataset\\n# .apply() runs our function on every row in the column\\ndf['sentiment_score'] = df['clean_text'].apply(get_sentiment_score)\\n\\nprint(\\\"‚úÖ Sentiment analysis complete for entire dataset!\\\")\\nprint(\\\"\\\\nFirst few results:\\\")\\n# Show title, sentiment score, and original rating for comparison\\nprint(df[['title', 'sentiment_score', 'rating']].head())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample cultural data (like what you scraped)\n",
    "sample_reviews = {\n",
    "    'title': ['Hamilton', 'Cats', 'The Lion King', 'Phantom of the Opera', 'Chicago', \n",
    "              'Wicked', 'Les Mis√©rables', 'Mamma Mia!', 'Book of Mormon', 'Dear Evan Hansen'],\n",
    "    'review_text': [\n",
    "        \"Absolutely brilliant musical! The hip-hop history was incredible and the cast was amazing.\",\n",
    "        \"I really didn't understand what was happening. Weird costumes and confusing plot.\",\n",
    "        \"Beautiful production with stunning visuals. The Circle of Life scene gave me chills!\",\n",
    "        \"Classic for a reason. The phantom's voice was haunting and the staging was magnificent.\",\n",
    "        \"Great dancing and catchy songs. Entertaining but not life-changing.\",\n",
    "        \"Mind-blowing! Defying Gravity made me cry. Elphaba was perfect.\",\n",
    "        \"Long but worth it. The barricade scene was emotionally devastating in the best way.\",\n",
    "        \"Fun and energetic! ABBA songs are so catchy, left feeling happy and uplifted.\",\n",
    "        \"Hilarious and inappropriate. Not for everyone but I laughed until my sides hurt.\",\n",
    "        \"Heartbreaking and beautiful. Dealt with mental health in such a thoughtful way.\"\n",
    "    ],\n",
    "    'rating': [5, 2, 4, 5, 3, 5, 4, 4, 4, 5],\n",
    "    'category': ['Historical', 'Fantasy', 'Family', 'Classic', 'Musical', \n",
    "                'Fantasy', 'Historical', 'Musical', 'Comedy', 'Contemporary']\n",
    "}\n",
    "\n",
    "# Convert to DataFrame (like loading your CSV)\n",
    "df = pd.DataFrame(sample_reviews)\n",
    "\n",
    "print(\"üé≠ Sample Broadway Reviews Dataset Loaded\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple text cleaning (less aggressive than HW1 word counting)\n",
    "def clean_for_sentiment(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    # Keep punctuation and capitalization - VADER needs them!\n",
    "    return str(text).strip()\n",
    "\n",
    "# Clean the text column\n",
    "df['clean_text'] = df['review_text'].apply(clean_for_sentiment)\n",
    "\n",
    "print(\"‚úÖ Text cleaning complete - kept punctuation for VADER\")\n",
    "print(\"\\nSample cleaned text:\")\n",
    "print(df['clean_text'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Analysis ‚Üí Batch Processing\n",
    "\n",
    "Let's start with one review, then scale up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now process the entire dataset (batch processing)\n",
    "def get_sentiment_score(text):\n",
    "    \"\"\"Get compound sentiment score for a text\"\"\"\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    return scores['compound']\n",
    "\n",
    "# Apply to entire dataset\n",
    "df['sentiment_score'] = df['clean_text'].apply(get_sentiment_score)\n",
    "\n",
    "print(\"‚úÖ Sentiment analysis complete for entire dataset!\")\n",
    "print(\"\\nFirst few results:\")\n",
    "print(df[['title', 'sentiment_score', 'rating']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Interpreting and Visualizing Results\n",
    "\n",
    "Let's explore what our sentiment analysis reveals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Sentiment distribution\n",
    "axes[0].hist(df['sentiment_score'], bins=8, color='skyblue', alpha=0.7)\n",
    "axes[0].set_title('Distribution of Sentiment Scores')\n",
    "axes[0].set_xlabel('Sentiment Score (-1 to 1)')\n",
    "axes[0].set_ylabel('Number of Reviews')\n",
    "axes[0].axvline(0, color='red', linestyle='--', alpha=0.5, label='Neutral')\n",
    "axes[0].legend()\n",
    "\n",
    "# Sentiment vs. Rating scatter plot\n",
    "axes[1].scatter(df['rating'], df['sentiment_score'], alpha=0.7, color='coral')\n",
    "axes[1].set_title('Sentiment Score vs. Numeric Rating')\n",
    "axes[1].set_xlabel('Star Rating (1-5)')\n",
    "axes[1].set_ylabel('Sentiment Score')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä What patterns do you notice?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Critical Analysis - When VADER Gets It Wrong\n",
    "\n",
    "Let's examine where automated sentiment analysis might struggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test VADER on tricky cultural examples\n",
    "tricky_texts = [\n",
    "    \"This show was so bad it was good\",  # Irony\n",
    "    \"The ending was beautifully tragic\",  # Mixed emotions\n",
    "    \"I literally died laughing\",  # Hyperbole\n",
    "    \"It was... fine\",  # Subtle negativity\n",
    "    \"Not the worst thing I've ever seen\"  # Double negative\n",
    "]\n",
    "\n",
    "print(\"ü§î CHALLENGING CASES FOR SENTIMENT ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for text in tricky_texts:\n",
    "    score = analyzer.polarity_scores(text)['compound']\n",
    "    print(f\"Text: '{text}'\")\n",
    "    print(f\"VADER score: {score:.3f}\")\n",
    "    print(f\"Your human judgment: _____\")  # Students fill this in\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí≠ Notes for Final Reflection:\n",
    "\n",
    "*Space for your thoughts during class - you'll use these for HW4-1:*\n",
    "\n",
    "**Where VADER worked well:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Where VADER struggled:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Questions this raises about cultural texts:**\n",
    "- \n",
    "- \n",
    "\n",
    "**Predictions for my own dataset:**\n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Preparing for HW4-1\n",
    "\n",
    "You now have the skills for HW4-1! Let's review the complete workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete workflow summary\n",
    "print(\"üéØ HW4-1 WORKFLOW CHECKLIST\")\n",
    "print(\"=\" * 30)\n",
    "print(\"‚úÖ 1. Load your scraped CSV data\")\n",
    "print(\"‚úÖ 2. Clean text (but keep punctuation for VADER)\")\n",
    "print(\"‚úÖ 3. Make predictions about sentiment patterns\")\n",
    "print(\"‚úÖ 4. Apply VADER to your dataset\")\n",
    "print(\"‚úÖ 5. Create visualizations of sentiment patterns\")\n",
    "print(\"‚úÖ 6. Compare predictions to actual results\")\n",
    "print(\"‚úÖ 7. Analyze where VADER works/fails with your texts\")\n",
    "print(\"‚úÖ 8. Reflect on insights and limitations\")\n",
    "\n",
    "print(\"\\nüöÄ You're ready for HW4-1!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking Ahead: Topic Modeling Preview\n",
    "\n",
    "**After HW4-1, you'll move to HW4-2** where you'll discover **hidden topics** in your text using machine learning. \n",
    "\n",
    "**Quick preview**: While sentiment analysis asks \"What emotions?\", topic modeling asks \"What themes and subjects are hiding in this collection?\"\n",
    "\n",
    "The text preprocessing you're learning now will prepare you for that next step!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: From Words to Emotions\n",
    "\n",
    "Today you learned to:\n",
    "\n",
    "**Technical Skills:**\n",
    "- ‚úÖ Install and use VADER sentiment analysis\n",
    "- ‚úÖ Process individual texts and entire datasets\n",
    "- ‚úÖ Interpret compound sentiment scores\n",
    "- ‚úÖ Create meaningful visualizations of emotional patterns\n",
    "\n",
    "**Critical Thinking:**\n",
    "- ‚úÖ Compare different sentiment analysis tools\n",
    "- ‚úÖ Recognize where automated analysis succeeds and fails\n",
    "- ‚úÖ Question the objectivity of algorithmic emotion detection\n",
    "- ‚úÖ Connect computational analysis to cultural research questions\n",
    "\n",
    "**Research Skills:**\n",
    "- ‚úÖ Form predictions and test them systematically\n",
    "- ‚úÖ Scale analysis from individual examples to entire datasets\n",
    "- ‚úÖ Document insights for deeper reflection\n",
    "- ‚úÖ Prepare text data for multiple types of analysis\n",
    "\n",
    "### üéØ You're Ready for HW4-1!\n",
    "\n",
    "Apply these skills to your own scraped cultural dataset and discover what emotional patterns emerge from your data. Remember: being surprised by your results is a sign of genuine learning, not failure!\n",
    "\n",
    "**Next**: Use your scraped data to complete the term frequency and sentiment analysis assignment, then get ready for topic modeling in HW4-2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}