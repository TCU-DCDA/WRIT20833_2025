{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/TCU-DCDA/WRIT20833-2025/blob/main/notebooks/codeAlongs/WRIT20833_Topic_Modeling_Part1_Introduction_F25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling Part 1: Introduction\n",
    "## Discovering Hidden Themes in Cultural Texts\n",
    "\n",
    "Welcome to topic modeling! Today we'll learn to uncover **hidden themes and topics** in large collections of text using machine learning.\n",
    "\n",
    "### üéØ What You'll Learn:\n",
    "- **Understand topic modeling** as a distant reading technique\n",
    "- **Install and use Gensim LDA** for discovering hidden topics\n",
    "- **Preprocess text** appropriately for topic modeling\n",
    "- **Interpret topic word lists** and assign meaningful labels\n",
    "- **Analyze document-topic assignments**\n",
    "\n",
    "### üîó What's Next:\n",
    "**Part 2 (next notebook)** will cover advanced techniques, larger datasets, and direct preparation for HW4-2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: From Word Counting to Theme Discovery\n",
    "\n",
    "### Your Text Analysis Journey So Far\n",
    "\n",
    "**HW1: Term Frequency**\n",
    "- Question: \"What words appear most often?\"\n",
    "- Output: List of frequent words (\"love\", \"good\", \"time\")\n",
    "- Insight: Surface-level word patterns\n",
    "\n",
    "**HW4-1: Sentiment Analysis**\n",
    "- Question: \"What emotions do these texts express?\"\n",
    "- Output: Positive/negative/neutral scores\n",
    "- Insight: Emotional tone and connotation\n",
    "\n",
    "**Today: Topic Modeling**\n",
    "- Question: \"What hidden themes and subjects are in this collection?\"\n",
    "- Output: Groups of related words that form coherent topics\n",
    "- Insight: Deep thematic structure and subject patterns\n",
    "\n",
    "### ü§î The Critical Question\n",
    "\n",
    "**Can an algorithm truly discover cultural \"themes\"?**\n",
    "\n",
    "Topic modeling doesn't \"understand\" culture‚Äîit finds statistical patterns in word co-occurrence. When you see topics emerge:\n",
    "- The algorithm is clustering words that appear together frequently\n",
    "- **YOU** must interpret whether those clusters represent meaningful cultural themes\n",
    "- This is where humanistic interpretation meets computational analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìñ What is Topic Modeling?\n",
    "\n",
    "**Topic modeling** uses machine learning to discover abstract \"topics\" in a collection of documents.\n",
    "\n",
    "**How it works**:\n",
    "1. Assumes each document contains a mixture of topics\n",
    "2. Assumes each topic is a collection of related words\n",
    "3. Uses statistics to reverse-engineer what those topics might be\n",
    "\n",
    "**Example**: Analyzing 100 movie reviews\n",
    "- **Topic 1**: plot, story, narrative, character, ending (‚Üí *Storytelling*)\n",
    "- **Topic 2**: acting, performance, cast, actor, role (‚Üí *Performance*)\n",
    "- **Topic 3**: visual, effects, cinematography, scene, shot (‚Üí *Visuals*)\n",
    "- **Topic 4**: boring, slow, waste, terrible, disappointing (‚Üí *Negative Critiques*)\n",
    "\n",
    "**Your job as researcher**: Interpret word lists and decide if they form coherent themes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "print(\"üìö Basic libraries imported - ready for topic modeling!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries for topic modeling\n",
    "!pip install gensim\n",
    "!pip install pyLDAvis\n",
    "!pip install nltk\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "print(\"‚úÖ Topic modeling libraries installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Gensim and related libraries\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "print(\"‚úÖ Gensim and topic modeling tools ready!\")\n",
    "print(f\"Gensim version: {gensim.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Topic Modeling with Simple Cultural Examples\n",
    "\n",
    "Let's start with a small, clear example to understand how topic modeling works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample cultural data - museum reviews with clear themes\n",
    "museum_reviews = [\n",
    "    # Art-focused reviews\n",
    "    \"The paintings were incredible. Van Gogh's work was beautifully displayed with excellent lighting.\",\n",
    "    \"Amazing art collection! The modern art gallery featured fantastic paintings and sculptures.\",\n",
    "    \"Loved the impressionist paintings. The colors and brushwork were stunning.\",\n",
    "    \n",
    "    # History-focused reviews\n",
    "    \"The ancient artifacts were fascinating. Egyptian mummies and pottery from thousands of years ago.\",\n",
    "    \"Great historical exhibits! Medieval weapons, armor, and manuscripts were well preserved.\",\n",
    "    \"Incredible history museum. Roman coins, Greek pottery, and ancient tools.\",\n",
    "    \n",
    "    # Family/kids reviews\n",
    "    \"Perfect for families! The kids loved the interactive exhibits and hands-on activities.\",\n",
    "    \"Children had a blast. Interactive dinosaur exhibit kept them engaged for hours.\",\n",
    "    \"Great for kids. Educational activities and fun interactive displays throughout.\",\n",
    "    \n",
    "    # Facility/practical reviews\n",
    "    \"The museum cafe was expensive. Gift shop had limited options. Parking was difficult.\",\n",
    "    \"Long lines to enter. Crowded galleries. Overpriced admission tickets and food.\",\n",
    "    \"Clean facilities and friendly staff. Good accessibility for wheelchairs.\"\n",
    "]\n",
    "\n",
    "print(\"üèõÔ∏è Sample Museum Reviews Dataset\")\n",
    "print(f\"Total reviews: {len(museum_reviews)}\")\n",
    "print(\"\\nü§î PREDICTION TIME:\")\n",
    "print(\"What topics do YOU expect topic modeling to discover?\")\n",
    "print(\"Write down 3-4 topic predictions before we run the analysis...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù Your Predictions:\n",
    "\n",
    "**Topic 1**: _____________________\n",
    "\n",
    "**Topic 2**: _____________________\n",
    "\n",
    "**Topic 3**: _____________________\n",
    "\n",
    "**Topic 4**: _____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Text Preprocessing for Topic Modeling\n",
    "\n",
    "### ‚ö†Ô∏è Different Analysis = Different Preprocessing\n",
    "\n",
    "**For VADER Sentiment Analysis (HW4-1)**:\n",
    "- ‚úÖ Keep punctuation (\"good!!!\" vs \"good\")\n",
    "- ‚úÖ Keep capitalization (\"AMAZING\" vs \"amazing\")\n",
    "- ‚úÖ Keep emojis (üòç, ‚ù§Ô∏è)\n",
    "\n",
    "**For Topic Modeling (Today)**:\n",
    "- ‚ùå Remove punctuation (not meaningful for topics)\n",
    "- ‚ùå Remove capitalization (\"Art\" and \"art\" are same word)\n",
    "- ‚úÖ **Lemmatize** words = reduce to dictionary form\n",
    "  - \"paintings\" ‚Üí \"painting\"\n",
    "  - \"running\" ‚Üí \"run\"\n",
    "  - \"better\" ‚Üí \"good\"\n",
    "  - **Why**: Treats different word forms as the same concept\n",
    "- ‚úÖ Remove short words (\"a\", \"an\", \"the\")\n",
    "- ‚úÖ Remove domain-specific stopwords\n",
    "\n",
    "**Why the difference?** \n",
    "- Sentiment = emotional intensity matters (\"good\" vs \"GOOD!!!\")\n",
    "- Topics = semantic meaning matters (\"painting\", \"paintings\", \"painted\" = same concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced stopwords list for topic modeling\n",
    "stopwords = [\n",
    "    # Basic English stopwords\n",
    "    \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\",\n",
    "    \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\",\n",
    "    \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\",\n",
    "    \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\",\n",
    "    \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\",\n",
    "    \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\",\n",
    "    \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\",\n",
    "    \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\",\n",
    "    \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\",\n",
    "    \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\",\n",
    "    \"how\", \"all\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\",\n",
    "    \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\",\n",
    "    \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\", \"ve\", \"ll\", \"amp\",\n",
    "    \n",
    "    # Additional words that don't help with topics\n",
    "    \"also\", \"would\", \"could\", \"get\", \"go\", \"one\", \"two\", \"see\", \"time\", \"way\",\n",
    "    \"may\", \"said\", \"say\", \"new\", \"first\", \"last\", \"long\", \"little\", \"much\",\n",
    "    \"well\", \"still\", \"even\", \"back\", \"good\", \"many\", \"make\", \"made\", \"us\", \"really\",\n",
    "    \n",
    "    # Museum-specific stopwords (domain-specific)\n",
    "    \"museum\", \"exhibit\", \"exhibition\", \"visit\", \"visited\", \"visitor\", \"review\"\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Stopwords list loaded: {len(stopwords)} words to filter out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_for_topics(text):\n",
    "    \"\"\"\n",
    "    Aggressive text preprocessing for topic modeling\n",
    "    \"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation and split into words\n",
    "    words = re.findall(r'\\b[a-z]+\\b', text)\n",
    "    \n",
    "    # Remove stopwords and short words (< 3 characters)\n",
    "    words = [word for word in words if word not in stopwords and len(word) >= 3]\n",
    "    \n",
    "    # Lemmatize words (reduce to base form)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    return words\n",
    "\n",
    "# Test the preprocessing\n",
    "test_text = \"The paintings were absolutely AMAZING!!! I loved the colorful artworks.\"\n",
    "processed = preprocess_for_topics(test_text)\n",
    "\n",
    "print(\"Text Preprocessing Test:\")\n",
    "print(f\"Original: {test_text}\")\n",
    "print(f\"Processed: {processed}\")\n",
    "print(\"\\nNotice: lowercase, no punctuation, lemmatized, stopwords removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to all museum reviews\n",
    "processed_reviews = [preprocess_for_topics(review) for review in museum_reviews]\n",
    "\n",
    "print(\"‚úÖ Preprocessing complete!\")\n",
    "print(f\"\\nProcessed {len(processed_reviews)} reviews\")\n",
    "print(\"\\nExample processed reviews:\")\n",
    "for i in range(3):\n",
    "    print(f\"{i+1}. {processed_reviews[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Building the Topic Model with Gensim\n",
    "\n",
    "### Converting Text to Numbers\n",
    "\n",
    "Gensim needs text as numbers. We create two things:\n",
    "\n",
    "**Dictionary**: Maps each word to a number\n",
    "- Example: \"painting\" ‚Üí 0, \"art\" ‚Üí 1, \"ancient\" ‚Üí 2\n",
    "- Computers work with numbers, not words\n",
    "\n",
    "**Corpus**: Documents as lists of (word_number, count) pairs\n",
    "- Example: `[(0, 2), (1, 1)]` means word #0 appears 2√ó, word #1 appears 1√ó\n",
    "- This \"bag-of-words\" format captures what words appear and how often\n",
    "- ‚ö†Ô∏è Ignores word order: \"dog bites man\" = \"man bites dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gensim dictionary\n",
    "dictionary = corpora.Dictionary(processed_reviews)\n",
    "\n",
    "print(\"üìñ Dictionary created!\")\n",
    "print(f\"Total unique words: {len(dictionary)}\")\n",
    "print(\"\\nSample word-to-ID mappings:\")\n",
    "for i, (word_id, word) in enumerate(list(dictionary.items())[:10]):\n",
    "    print(f\"  ID {word_id}: {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create corpus (bag-of-words representation)\n",
    "corpus = [dictionary.doc2bow(review) for review in processed_reviews]\n",
    "\n",
    "print(\"üì¶ Corpus created!\")\n",
    "print(f\"Total documents: {len(corpus)}\")\n",
    "print(\"\\nExample document representation (word_id, frequency):\")\n",
    "print(f\"First review: {corpus[0]}\")\n",
    "print(\"\\nHuman-readable version:\")\n",
    "for word_id, freq in corpus[0]:\n",
    "    print(f\"  '{dictionary[word_id]}' appears {freq} time(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the LDA Model\n",
    "\n",
    "**What is LDA?** Latent Dirichlet Allocation - an algorithm that discovers hidden topics\n",
    "\n",
    "**Key Parameters**:\n",
    "- `num_topics`: **How many topics to discover** (we'll try 4)\n",
    "- `passes`: **How many times to analyze the dataset** (10 = good for small data)\n",
    "  - More passes = better results but slower\n",
    "  - Like reading a book multiple times to understand themes better\n",
    "- `random_state=42`: **Makes results reproducible** (same topics every time)\n",
    "- `alpha='auto'`: Let Gensim optimize how topics mix in documents\n",
    "- `eta='auto'`: Let Gensim optimize how words define topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model\n",
    "num_topics = 4\n",
    "\n",
    "print(f\"ü§ñ Training LDA model with {num_topics} topics...\")\n",
    "print(\"This may take a moment...\\n\")\n",
    "\n",
    "lda_model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=num_topics,\n",
    "    random_state=42,\n",
    "    passes=10,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    per_word_topics=True\n",
    ")\n",
    "\n",
    "print(\"‚úÖ LDA model training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Interpreting the Topics\n",
    "\n",
    "### üîç The Critical Task: From Word Lists to Themes\n",
    "\n",
    "The model gives you word lists with probabilities. **YOU** must interpret whether they represent coherent cultural themes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the discovered topics\n",
    "print(\"üéØ DISCOVERED TOPICS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nEach topic shows the top 10 most important words:\\n\")\n",
    "\n",
    "for idx, topic in lda_model.print_topics(num_words=10):\n",
    "    print(f\"Topic {idx}:\")\n",
    "    print(f\"  {topic}\")\n",
    "    print(f\"  Your interpretation: _____________________\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù Topic Labeling Exercise:\n",
    "\n",
    "Look at the word lists above and assign meaningful labels:\n",
    "\n",
    "**Topic 0**: _____________________ (What theme do these words suggest?)\n",
    "\n",
    "**Topic 1**: _____________________ (What theme do these words suggest?)\n",
    "\n",
    "**Topic 2**: _____________________ (What theme do these words suggest?)\n",
    "\n",
    "**Topic 3**: _____________________ (What theme do these words suggest?)\n",
    "\n",
    "**How did your predictions compare to the actual topics discovered?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cleaner topic visualization\n",
    "def display_topics_clean(model, num_words=8):\n",
    "    \"\"\"\n",
    "    Display topics in a more readable format\n",
    "    \"\"\"\n",
    "    for idx in range(model.num_topics):\n",
    "        # Get top words for this topic\n",
    "        words = model.show_topic(idx, num_words)\n",
    "        \n",
    "        print(f\"Topic {idx}:\")\n",
    "        word_list = [word for word, prob in words]\n",
    "        print(f\"  Words: {', '.join(word_list)}\")\n",
    "        print()\n",
    "\n",
    "print(\"üéØ TOPICS IN READABLE FORMAT\")\n",
    "print(\"=\" * 40)\n",
    "display_topics_clean(lda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize topic word weights\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx in range(num_topics):\n",
    "    # Get top words and their weights\n",
    "    words_weights = lda_model.show_topic(idx, 8)\n",
    "    words = [word for word, weight in words_weights]\n",
    "    weights = [weight for word, weight in words_weights]\n",
    "    \n",
    "    # Create bar chart\n",
    "    axes[idx].barh(range(len(words)), weights, color='skyblue')\n",
    "    axes[idx].set_yticks(range(len(words)))\n",
    "    axes[idx].set_yticklabels(words)\n",
    "    axes[idx].set_xlabel('Weight')\n",
    "    axes[idx].set_title(f'Topic {idx}')\n",
    "    axes[idx].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Topic visualizations complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Analyzing Document-Topic Assignments\n",
    "\n",
    "Let's see which topics the model assigns to each document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified function to get dominant topic for each document\n",
    "def get_dominant_topic(ldamodel, corpus, texts):\n",
    "    \"\"\"\n",
    "    Find the dominant topic for each document\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i, doc in enumerate(corpus):\n",
    "        # Get topic distribution for this document\n",
    "        topic_dist = ldamodel.get_document_topics(doc)\n",
    "        \n",
    "        # Find dominant topic (highest probability)\n",
    "        dominant_topic = max(topic_dist, key=lambda x: x[1])\n",
    "        topic_num = dominant_topic[0]\n",
    "        topic_prob = dominant_topic[1]\n",
    "        \n",
    "        # Get top words for this topic\n",
    "        topic_words = [word for word, prob in ldamodel.show_topic(topic_num, 5)]\n",
    "        \n",
    "        results.append({\n",
    "            'Document': i,\n",
    "            'Dominant_Topic': topic_num,\n",
    "            'Topic_Probability': round(topic_prob, 3),\n",
    "            'Topic_Keywords': ', '.join(topic_words),\n",
    "            'Original_Text': texts[i][:80] + '...'\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Analyze documents\n",
    "doc_topics = get_dominant_topic(lda_model, corpus, museum_reviews)\n",
    "\n",
    "print(\"üìÑ DOCUMENT-TOPIC ASSIGNMENTS\")\n",
    "print(\"=\" * 70)\n",
    "doc_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show documents grouped by topic\n",
    "for topic_num in range(num_topics):\n",
    "    print(f\"\\nüìå TOPIC {topic_num}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    topic_docs = doc_topics[doc_topics['Dominant_Topic'] == topic_num]\n",
    "    print(f\"Documents in this topic: {len(topic_docs)}\")\n",
    "    print(f\"Keywords: {topic_docs.iloc[0]['Topic_Keywords']}\")\n",
    "    print(\"\\nExample texts:\")\n",
    "    \n",
    "    for idx, row in topic_docs.head(3).iterrows():\n",
    "        print(f\"  - {museum_reviews[row['Document']]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí≠ Critical Analysis Questions:\n",
    "\n",
    "**Do the topic assignments make sense?**\n",
    "- Look at the documents grouped under each topic\n",
    "- Do they share a coherent theme?\n",
    "- Where would you disagree with the model?\n",
    "\n",
    "**What does this reveal about the algorithm's interpretation?**\n",
    "- Is it detecting cultural themes or just word co-occurrence?\n",
    "- What human knowledge is required to make these topics meaningful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Introduction to Topic Modeling\n",
    "\n",
    "Today you learned:\n",
    "\n",
    "**Technical Skills**:\n",
    "- ‚úÖ Install and use Gensim for topic modeling\n",
    "- ‚úÖ Preprocess text with lemmatization for LDA\n",
    "- ‚úÖ Create dictionaries and corpus representations (bag-of-words)\n",
    "- ‚úÖ Train LDA models with basic parameters\n",
    "- ‚úÖ Interpret topic word distributions\n",
    "- ‚úÖ Analyze document-topic assignments\n",
    "\n",
    "**Critical Thinking**:\n",
    "- ‚úÖ Distinguish statistical patterns from cultural meanings\n",
    "- ‚úÖ Recognize that YOU must interpret word clusters as themes\n",
    "- ‚úÖ Question what counts as a \"topic\" or \"theme\"\n",
    "- ‚úÖ Validate computational results with close reading\n",
    "\n",
    "### üéØ Next Steps:\n",
    "\n",
    "**Part 2 (next notebook)** will cover:\n",
    "- Working with larger, more realistic datasets\n",
    "- Experimenting with different numbers of topics\n",
    "- Understanding when topic modeling fails\n",
    "- Direct preparation for HW4-2\n",
    "\n",
    "---\n",
    "\n",
    "### üîó Critical Framework Connection: Classification Logic\n",
    "\n",
    "Topic modeling raises fundamental questions about **how code categorizes culture**:\n",
    "- Who decides what counts as a coherent \"topic\"?\n",
    "- What cultural knowledge is embedded in stopword lists and preprocessing choices?\n",
    "- How do algorithmic categories relate to human cultural understanding?\n",
    "- What gets lost when we reduce texts to bags of words?\n",
    "\n",
    "These aren't just technical questions‚Äîthey're about **power, interpretation, and how computational tools shape our understanding of culture**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
