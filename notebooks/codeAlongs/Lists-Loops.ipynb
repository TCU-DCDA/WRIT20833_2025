{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "974f65ab",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/TCU-DCDA/WRIT20833-2025/blob/main/notebooks/codeAlongs/Lists-Loops-Colab.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb68012",
   "metadata": {},
   "source": [
    "# The Ways We Count and Are Counted\n",
    "## Lists, List Methods, and Loops in Digital Humanities\n",
    "\n",
    "Welcome to our exploration of how we organize, count, and analyze information in the digital age. Today we'll learn about Python lists - one of the fundamental ways computers help us make sense of collections of data.\n",
    "\n",
    "In digital humanities, we're constantly working with collections: books in a library, words in a text, people in a census, artifacts in a museum. Lists help us organize and analyze these collections systematically.\n",
    "\n",
    "But our title hints at something deeper: **the ways we count AND the ways we are counted**. As we learn to organize and analyze cultural data, we must also consider how people, communities, and ideas are represented, categorized, and quantified in digital collections. Who gets counted? What gets measured? How do our analytical choices shape what we discover about culture and society?\n",
    "\n",
    "### Understanding Data Organization: From Spreadsheets to Code\n",
    "\n",
    "Before we dive into lists, let's connect Python data structures to something familiar - spreadsheets and tables:\n",
    "\n",
    "- **Variables** = **Individual table cells**: Just like a single cell holds one piece of information (a name, date, or number), a variable stores one value\n",
    "- **Lists** = **Table rows or columns**: Just as a row might contain all information about one person, or a column might contain all the ages in a dataset, a list stores multiple related items in order\n",
    "- **Dictionaries** *(coming later)* = **Complete tables**: Like a spreadsheet with both rows and columns, dictionaries can store complex, structured information\n",
    "\n",
    "Think of today's lesson as learning to work with a single row or column from a research spreadsheet - but with the power to analyze thousands of items automatically!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152be4d9",
   "metadata": {},
   "source": [
    "## Part 1: What Are Lists?\n",
    "\n",
    "Think of a list as a digital filing cabinet or a library catalog. Just like physical collections, our digital lists maintain order and allow us to access, organize, and analyze items systematically.\n",
    "\n",
    "Let's start with a simple example from literary studies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be83ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of Shakespeare's major tragedies\n",
    "shakespeare_tragedies = [\"Hamlet\", \"Othello\", \"King Lear\", \"Macbeth\"]\n",
    "\n",
    "print(\"Shakespeare's Major Tragedies:\")\n",
    "print(shakespeare_tragedies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ac7602",
   "metadata": {},
   "source": [
    "### Try it yourself:\n",
    "Create a list of your favorite books, historical periods, or research topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf004f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your turn: create a list related to your interests\n",
    "my_list = []  # Replace with your own list\n",
    "\n",
    "print(my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3e9dad",
   "metadata": {},
   "source": [
    "## Part 2: Accessing Information - How We Find What We're Looking For\n",
    "\n",
    "Just like finding a book on a library shelf, we can locate specific items in our lists. Python uses \"indexing\" - think of it like seat numbers or page numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83dc440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historical periods\n",
    "time_periods = [\"Ancient\", \"Medieval\", \"Renaissance\", \"Modern\", \"Contemporary\"]\n",
    "\n",
    "# Remember: Python starts counting from 0 (like ground floor = 0 in some countries)\n",
    "print(f\"First period: {time_periods[0]}\")\n",
    "print(f\"Third period: {time_periods[2]}\")\n",
    "print(f\"Last period: {time_periods[-1]}\")  # -1 gives us the last item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1a9f45",
   "metadata": {},
   "source": [
    "### Discussion Question:\n",
    "Why might it matter that computers start counting from 0? How does this relate to how humans typically count and organize information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5647070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try accessing different items from your list above\n",
    "# What happens if you try to access an index that doesn't exist?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0637e63",
   "metadata": {},
   "source": [
    "## Part 2.5: List Slicing - Extracting Portions of Collections\n",
    "\n",
    "Just as scholars might focus on specific chapters of a book, decades in a timeline, or particular regions in a geographic study, we often need to work with portions of our data collections rather than entire lists. List slicing is like creating focused excerpts from larger datasets.\n",
    "\n",
    "Think of slicing as creating targeted subcollections - perhaps you want to analyze only the first half of a century's literature, or examine the last few entries in a historical record, or study every third artifact in a museum collection.\n",
    "\n",
    "### The Anatomy of Slicing: [start:stop:step]\n",
    "\n",
    "List slicing uses the pattern `[start:stop:step]` where:\n",
    "- **start**: where to begin (included)\n",
    "- **stop**: where to end (excluded - like \"until\" rather than \"through\")\n",
    "- **step**: how many items to skip (default is 1)\n",
    "\n",
    "This flexible system allows us to extract exactly the data we need for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaf2150",
   "metadata": {},
   "source": [
    "## Part 3: List Methods - Tools for Digital Scholarship\n",
    "\n",
    "Just as scholars have developed methods for analyzing texts and historical sources, Python provides us with methods for working with lists. These are like specialized tools in a researcher's toolkit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5b7fa7",
   "metadata": {},
   "source": [
    "## Part 3.5: Conditional Logic with Lists - Making Decisions About Data\n",
    "\n",
    "In humanities research, we constantly make decisions about our sources: Is this document from the right time period? Does this text contain the themes we're studying? Is this artifact from the culture we're examining?\n",
    "\n",
    "Conditional logic - using `if`, `elif`, and `else` statements - allows us to program these kinds of scholarly decisions. Combined with comparison and logical operators, we can systematically filter, categorize, and analyze our collections based on specific criteria.\n",
    "\n",
    "### The Building Blocks of Digital Decision-Making\n",
    "\n",
    "**Comparison Operators** - for evaluating relationships:\n",
    "- `==` (equal to), `!=` (not equal to)\n",
    "- `>`, `<`, `>=`, `<=` (greater than, less than, etc.)\n",
    "\n",
    "**Logical Operators** - for combining conditions:\n",
    "- `and` (both conditions must be true)\n",
    "- `or` (either condition can be true)  \n",
    "- `not` (reverses the condition)\n",
    "- `in`, `not in` (checking membership in collections)\n",
    "\n",
    "**String Methods for Text Analysis**:\n",
    "- `.startswith()`, `.endswith()` - for pattern matching\n",
    "- `.replace()` - for cleaning and standardizing data\n",
    "- `.strip()` - for removing unwanted whitespace\n",
    "\n",
    "These tools let us ask complex questions of our data: \"Show me all authors from the 20th century whose names start with 'V'\" or \"Find all documents that contain both 'democracy' and 'freedom' but not 'war'.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0c3207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's work with a list of authors we're studying\n",
    "authors = [\"Virginia Woolf\", \"James Joyce\", \"T.S. Eliot\"]\n",
    "\n",
    "print(\"Original list:\", authors)\n",
    "print(f\"Number of authors: {len(authors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f52491",
   "metadata": {},
   "source": [
    "### Adding to Our Collection - .append() and .extend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e50ba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding one author to our collection\n",
    "authors.append(\"Ezra Pound\")\n",
    "print(\"After adding Ezra Pound:\", authors)\n",
    "\n",
    "# Adding multiple authors at once\n",
    "new_authors = [\"Gertrude Stein\", \"William Faulkner\"]\n",
    "authors.extend(new_authors)\n",
    "print(\"After extending with new authors:\", authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102222ef",
   "metadata": {},
   "source": [
    "### Finding Information - .index() and .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aadcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where in our list is a specific author?\n",
    "woolf_position = authors.index(\"Virginia Woolf\")\n",
    "print(f\"Virginia Woolf is at position: {woolf_position}\")\n",
    "\n",
    "# Let's create a list with some repeated words from a text analysis\n",
    "words_in_text = [\"love\", \"death\", \"time\", \"love\", \"memory\", \"death\", \"love\"]\n",
    "love_count = words_in_text.count(\"love\")\n",
    "print(f\"The word 'love' appears {love_count} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7831434e",
   "metadata": {},
   "source": [
    "### Organizing Our Data - .sort() and .reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48601496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's organize our authors alphabetically\n",
    "print(\"Before sorting:\", authors)\n",
    "authors.sort()\n",
    "print(\"After sorting:\", authors)\n",
    "\n",
    "# Or in reverse order\n",
    "authors.reverse()\n",
    "print(\"After reversing:\", authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81b6183",
   "metadata": {},
   "source": [
    "### Try It Yourself: Building a Research Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98be76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of research topics, historical events, or literary works\n",
    "research_topics = []\n",
    "\n",
    "# Add some initial topics\n",
    "\n",
    "\n",
    "# Add more topics using extend()\n",
    "\n",
    "\n",
    "# Sort your topics\n",
    "\n",
    "\n",
    "# Print the final organized list\n",
    "print(\"My research topics:\", research_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893b64ff",
   "metadata": {},
   "source": [
    "## Part 4: Loops - Systematic Analysis\n",
    "\n",
    "In traditional scholarship, we might read through a stack of documents one by one, taking notes on each. Loops let us do this systematically with digital collections. This is where \"counting\" becomes powerful analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac390d9",
   "metadata": {},
   "source": [
    "### The Simple For Loop - Processing Each Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa107109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's analyze a collection of historical documents\n",
    "documents = [\"Letter to John Adams\", \"Diary Entry March 1776\", \"Speech to Continental Congress\"]\n",
    "\n",
    "print(\"Analyzing documents:\")\n",
    "for document in documents:\n",
    "    print(f\"- Processing: {document}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83393ab3",
   "metadata": {},
   "source": [
    "### Loops with Enumeration - Keeping Track of Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9bcf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes we need to know both the item and its position\n",
    "manuscript_pages = [\"Title Page\", \"Preface\", \"Chapter 1\", \"Chapter 2\", \"Bibliography\"]\n",
    "\n",
    "print(\"Manuscript Structure:\")\n",
    "for position, page in enumerate(manuscript_pages, 1):  # Start counting from 1\n",
    "    print(f\"Page {position}: {page}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0aaf03",
   "metadata": {},
   "source": [
    "### Conditional Analysis - Filtering Our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ade8375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find all the long titles in our collection\n",
    "book_titles = [\n",
    "    \"1984\",\n",
    "    \"To Kill a Mockingbird\", \n",
    "    \"One Hundred Years of Solitude\",\n",
    "    \"Pride and Prejudice\",\n",
    "    \"The Great Gatsby\"\n",
    "]\n",
    "\n",
    "print(\"Books with titles longer than 15 characters:\")\n",
    "for title in book_titles:\n",
    "    if len(title) > 15:\n",
    "        print(f\"- {title} ({len(title)} characters)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4abed2",
   "metadata": {},
   "source": [
    "## Part 4.5: Building and Filtering Lists - Constructing New Collections\n",
    "\n",
    "One of the most powerful aspects of digital humanities work is the ability to create new collections from existing ones based on specific criteria. This is like a scholar going through a library's entire collection and creating a specialized bibliography of works that meet certain requirements.\n",
    "\n",
    "### The Pattern: Empty List + Loop + Conditional Append\n",
    "\n",
    "This fundamental pattern appears constantly in digital humanities research:\n",
    "1. Start with an empty list to hold our results\n",
    "2. Loop through our source collection\n",
    "3. Check each item against our criteria\n",
    "4. Add items that match to our new collection\n",
    "\n",
    "This approach allows us to:\n",
    "- Extract all works by female authors from a general literature list\n",
    "- Find all historical events from a specific century\n",
    "- Identify all artworks from a particular cultural movement\n",
    "- Clean datasets by removing incomplete or problematic entries\n",
    "\n",
    "### Data Cleaning in Digital Humanities\n",
    "\n",
    "Real-world cultural data is often messy. Historical records might have uncertain attributions marked with \"(?)\", incomplete information, or inconsistent formatting. Learning to systematically clean and standardize data is crucial for reliable analysis.\n",
    "\n",
    "This involves:\n",
    "- Removing unwanted characters or markers\n",
    "- Standardizing spelling and formatting\n",
    "- Handling missing or uncertain information\n",
    "- Creating consistent categories for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037cf224",
   "metadata": {},
   "source": [
    "## Part 5: Counting and Being Counted - Digital Humanities Applications\n",
    "\n",
    "Now let's explore how these tools help us understand how people and ideas are represented in digital collections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba884e9b",
   "metadata": {},
   "source": [
    "### Word Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b2a838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple text analysis - let's look at word frequency\n",
    "# This could be from a historical speech, poem, or document\n",
    "sample_text = [\"freedom\", \"liberty\", \"justice\", \"freedom\", \"equality\", \"justice\", \"freedom\", \"democracy\"]\n",
    "\n",
    "print(\"Word Frequency Analysis:\")\n",
    "unique_words = []\n",
    "\n",
    "for word in sample_text:\n",
    "    if word not in unique_words:\n",
    "        unique_words.append(word)\n",
    "        count = sample_text.count(word)\n",
    "        print(f\"'{word}' appears {count} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5a49f2",
   "metadata": {},
   "source": [
    "## Part 5.5: Advanced List Tools - Professional Digital Humanities Techniques\n",
    "\n",
    "As digital humanities projects grow in complexity, we need more sophisticated tools for managing and analyzing our collections. Python provides several advanced functions that make common research tasks more efficient and elegant.\n",
    "\n",
    "### enumerate() - Keeping Track of Position and Content\n",
    "\n",
    "When analyzing collections, we often need to know both what something is and where it appears. Think of a scholar who needs to cite not just a quotation, but its page number; or a curator who must track both an artifact and its catalog number.\n",
    "\n",
    "The `enumerate()` function provides a systematic way to track position alongside content, essential for:\n",
    "- Creating numbered bibliographies or catalogs\n",
    "- Tracking line numbers in text analysis\n",
    "- Maintaining source citations with positional references\n",
    "- Creating structured reports with sequential numbering\n",
    "\n",
    "### zip() - Combining Related Collections\n",
    "\n",
    "In digital humanities, we often work with related but separate datasets - like having lists of authors, publication dates, and genres that all correspond to the same books. The `zip()` function allows us to work with these parallel collections simultaneously.\n",
    "\n",
    "This is particularly valuable for:\n",
    "- Combining biographical data (names, birth years, nationalities)\n",
    "- Linking texts with their metadata (titles, authors, publication info)\n",
    "- Connecting artifacts with their provenance information\n",
    "- Merging historical events with their dates and locations\n",
    "\n",
    "### Counter - Systematic Frequency Analysis\n",
    "\n",
    "The `Counter` tool from Python's collections library automates one of the most common tasks in digital humanities: counting how often things appear. Instead of manually tallying occurrences, `Counter` provides professional-grade frequency analysis.\n",
    "\n",
    "This is essential for:\n",
    "- Word frequency studies in literary analysis\n",
    "- Tracking recurring themes across collections\n",
    "- Analyzing demographic patterns in historical data\n",
    "- Identifying the most and least common elements in any dataset\n",
    "\n",
    "### List Comprehensions - Elegant Filtering and Transformation\n",
    "\n",
    "List comprehensions provide a concise, readable way to create new collections from existing ones. They're like writing a mathematical set notation for data processing - expressing complex filtering or transformation operations in a single, clear statement.\n",
    "\n",
    "This advanced technique allows experienced practitioners to:\n",
    "- Create filtered collections more efficiently\n",
    "- Transform data while applying conditions\n",
    "- Write more readable and maintainable code\n",
    "- Combine multiple operations into elegant one-liners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a47a4b",
   "metadata": {},
   "source": [
    "### Analyzing Representation in Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a387c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's analyze gender representation in a literary syllabus\n",
    "syllabus_authors = [\n",
    "    (\"Virginia Woolf\", \"female\"),\n",
    "    (\"James Joyce\", \"male\"),\n",
    "    (\"Zora Neale Hurston\", \"female\"),\n",
    "    (\"William Faulkner\", \"male\"),\n",
    "    (\"Toni Morrison\", \"female\"),\n",
    "    (\"Ernest Hemingway\", \"male\")\n",
    "]\n",
    "\n",
    "male_count = 0\n",
    "female_count = 0\n",
    "\n",
    "print(\"Analyzing representation in our syllabus:\")\n",
    "for author, gender in syllabus_authors:\n",
    "    print(f\"- {author} ({gender})\")\n",
    "    if gender == \"male\":\n",
    "        male_count += 1\n",
    "    elif gender == \"female\":\n",
    "        female_count += 1\n",
    "\n",
    "total_authors = len(syllabus_authors)\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"Total authors: {total_authors}\")\n",
    "print(f\"Male authors: {male_count} ({male_count/total_authors*100:.1f}%)\")\n",
    "print(f\"Female authors: {female_count} ({female_count/total_authors*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ec8b92",
   "metadata": {},
   "source": [
    "## Part 6: Your Turn - A Mini Research Project\n",
    "\n",
    "Now it's time to apply what you've learned. Choose one of these mini-projects or create your own:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4787cfa9",
   "metadata": {},
   "source": [
    "## Part 6.5: Walsh Textbook-Style Practice Exercises\n",
    "\n",
    "These exercises mirror the style and requirements of the Walsh \"Intro to Cultural Analytics\" textbook chapters 8, 9, and 10. They focus on practical data manipulation tasks commonly encountered in digital humanities research, particularly working with historical and demographic data.\n",
    "\n",
    "### Data Cleaning and Filtering Exercises\n",
    "\n",
    "These exercises practice the essential skill of preparing messy, real-world data for analysis - a constant challenge in digital humanities work.\n",
    "\n",
    "**Exercise Focus Areas:**\n",
    "- Removing uncertainty markers (like \"(?)\" from historical records)\n",
    "- Filtering collections based on specific criteria\n",
    "- Creating new collections from existing ones using conditional logic\n",
    "- Cleaning and standardizing text data for analysis\n",
    "\n",
    "### Indexing and Enumeration Exercises\n",
    "\n",
    "These exercises develop skills for systematic data organization and presentation, crucial for creating professional research outputs.\n",
    "\n",
    "**Exercise Focus Areas:**\n",
    "- Using `enumerate()` to create numbered lists and catalogs\n",
    "- Combining position information with content analysis\n",
    "- Creating structured reports with sequential numbering\n",
    "- Managing both content and positional metadata\n",
    "\n",
    "### Multi-List Analysis Exercises\n",
    "\n",
    "These exercises practice working with complex, related datasets - reflecting the reality that humanities data often comes in interconnected pieces.\n",
    "\n",
    "**Exercise Focus Areas:**\n",
    "- Using `zip()` to combine related information from multiple sources\n",
    "- Analyzing parallel collections (names, dates, locations, etc.)\n",
    "- Creating comprehensive reports from distributed data\n",
    "- Managing relationships between different data categories\n",
    "\n",
    "### Frequency Analysis and Pattern Recognition\n",
    "\n",
    "These exercises develop skills for identifying patterns and trends in cultural collections - fundamental to many digital humanities research questions.\n",
    "\n",
    "**Exercise Focus Areas:**\n",
    "- Using `Counter` for systematic frequency analysis\n",
    "- Identifying most and least common patterns\n",
    "- Comparing frequency distributions across different collections\n",
    "- Drawing research conclusions from quantitative patterns\n",
    "\n",
    "### Historical Demographic Analysis\n",
    "\n",
    "Following the Walsh textbook's approach using historical immigration data, these exercises work with demographic and social data to understand how people were categorized and counted in historical contexts.\n",
    "\n",
    "**Exercise Focus Areas:**\n",
    "- Analyzing historical population data\n",
    "- Understanding categorization systems in historical records\n",
    "- Examining representation and bias in historical datasets\n",
    "- Connecting quantitative analysis to broader historical questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82305380",
   "metadata": {},
   "source": [
    "### Option 1: Analyze a Historical Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b678f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of historical events with dates\n",
    "historical_events = [\n",
    "    (1776, \"Declaration of Independence\"),\n",
    "    (1789, \"French Revolution begins\"),\n",
    "    (1865, \"End of American Civil War\"),\n",
    "    (1914, \"World War I begins\"),\n",
    "    (1969, \"Moon landing\")\n",
    "]\n",
    "\n",
    "# Your task: \n",
    "# 1. Add 3 more historical events\n",
    "# 2. Sort the events chronologically\n",
    "# 3. Print them in a formatted way\n",
    "# 4. Find events from a specific century\n",
    "\n",
    "# Write your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177e9784",
   "metadata": {},
   "source": [
    "### Option 2: Literary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf037b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the length and characteristics of book titles\n",
    "classic_novels = [\n",
    "    \"Pride and Prejudice\",\n",
    "    \"1984\",\n",
    "    \"To Kill a Mockingbird\",\n",
    "    \"The Great Gatsby\",\n",
    "    \"One Hundred Years of Solitude\"\n",
    "]\n",
    "\n",
    "# Your task:\n",
    "# 1. Add 5 more book titles\n",
    "# 2. Calculate the average title length\n",
    "# 3. Find the longest and shortest titles\n",
    "# 4. Count how many titles contain specific words (like \"The\" or \"and\")\n",
    "\n",
    "# Write your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5642d0f2",
   "metadata": {},
   "source": [
    "### Option 3: Museum Collection Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5606308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze a museum collection\n",
    "artifacts = [\n",
    "    (\"Ancient Greek Vase\", \"Ancient Greece\", \"Pottery\"),\n",
    "    (\"Medieval Manuscript\", \"Medieval Europe\", \"Document\"),\n",
    "    (\"Renaissance Painting\", \"Renaissance Italy\", \"Artwork\"),\n",
    "    (\"Egyptian Papyrus\", \"Ancient Egypt\", \"Document\")\n",
    "]\n",
    "\n",
    "# Your task:\n",
    "# 1. Add more artifacts with (name, origin, type)\n",
    "# 2. Count artifacts by type\n",
    "# 3. List all artifacts from a specific time period\n",
    "# 4. Create a summary report\n",
    "\n",
    "# Write your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e6270f",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "\n",
    "As we wrap up our exploration of lists and loops, consider these questions:\n",
    "\n",
    "1. **Power of Counting**: How does systematic counting change the way we understand collections of cultural materials?\n",
    "\n",
    "2. **Representation**: When we organize and count cultural data, what might we be missing? What biases might be built into our categories?\n",
    "\n",
    "3. **Scale**: How does computational analysis allow us to work with collections that would be impossible to analyze manually?\n",
    "\n",
    "4. **Human vs. Machine**: What kinds of insights can we gain from computational counting that human reading might miss? What might human analysis reveal that counting cannot?\n",
    "\n",
    "Write your thoughts in the cell below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8edd7b8",
   "metadata": {},
   "source": [
    "### Your Reflections:\n",
    "\n",
    "(Double-click this cell to edit and write your thoughts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50048ff4",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "Today we've learned:\n",
    "\n",
    "- **Lists** help us organize collections of data systematically\n",
    "- **List indexing and slicing** allow us to extract specific portions of our collections for focused analysis\n",
    "- **List methods** provide tools for adding, organizing, and analyzing our collections\n",
    "- **Conditional logic** enables us to make systematic decisions about our data using comparison and logical operators\n",
    "- **Loops** allow us to process each item in a collection systematically\n",
    "- **Building and filtering lists** lets us create new collections based on specific research criteria\n",
    "- **Advanced tools** like `enumerate()`, `zip()`, and `Counter` provide professional-grade data analysis capabilities\n",
    "- **List comprehensions** offer elegant ways to filter and transform collections\n",
    "- **Data cleaning techniques** prepare messy real-world cultural data for reliable analysis\n",
    "- **Counting and analysis** can reveal patterns in cultural and historical data\n",
    "- **Critical thinking** about data representation is essential in digital humanities\n",
    "\n",
    "These are fundamental building blocks for digital humanities research. As you continue your studies, you'll use these concepts to analyze texts, examine historical patterns, and explore cultural collections in new ways.\n",
    "\n",
    "Remember: every time we count, we're making choices about what matters and how to categorize the world. In digital humanities, being conscious of these choices is just as important as the technical skills themselves. The tools we've learned today will prepare you for the specific exercises in Walsh's \"Intro to Cultural Analytics\" textbook, while maintaining the critical perspective essential to humanities scholarship."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
